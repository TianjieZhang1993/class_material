{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 533 Assignment 0\n",
    "\n",
    "This is the 0th assignment for CS 533, *Introduction to Data Science*.  It is due **Sunday, Aug. 29, at 11:59 pm**.\n",
    "To download this notebook from its view in the course web site, hover over the *Download* menu (the down arrow in the upper right), and choose `.ipynb`.\n",
    "\n",
    "The purpose of this lab is to make sure that you can run Python notebooks and successfully submit an assignment.\n",
    "\n",
    "Keep the following in mind for **all** notebooks you develop:\n",
    "\n",
    "1. Structure your notebook. Use headings with meaningful levels in Markdown cells, and explain the questions each piece of code is to answer or the reason it is there.\n",
    "2. Make sure your notebook can always be rerun from top to bottom.\n",
    "\n",
    "For this notebook, I am actually giving you the answers - the PDF accompanying this assignment contains the code to enter in each of the cells below.  I want you to work through the process of entering, running, and submitting code before you need to worry about how to write it, so we can focus on learning one thing at a time. For the next assignment, when you need to write your own code, you've already been through the mechanics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission Instructions\n",
    "\n",
    "To submit this lab, submit your `.ipynb` file along with a PDF version to Canvas.  Create the PDF version by using your browser's Print feature and printing to a PDF.\n",
    "\n",
    "Your submitted notebook **must include results**.  I recommend that you submit after a clean run: select the 'Kernel' menu and choose 'Restart and Run All'.  This will also help you test requirement (2) above: that the notebook can be rerun from top to bottom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "I usually start my notebooks with a *Setup* section that loads the relevant Python modules and does any configuration needed for the notebook to work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all projects will need basic data analysis packages - Pandas and Seaborn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For other projects, you will need some more imports:\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "```\n",
    "\n",
    "These are not necessary for this lab."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "\n",
    "After initializing the Python database, we load the data.\n",
    "\n",
    "### Obtaining the Data File\n",
    "\n",
    "Note that I did not provide the data file for you.  I want you to get used to downloading data files, so you learn where they come from.\n",
    "\n",
    "**Download the Capital Bike Share data set** from <https://archive.ics.uci.edu/ml/datasets/bike+sharing+dataset>.  Click 'Data Folder', download the zip file, and extract the `day.csv` file.\n",
    "\n",
    "### Reading the Data File\n",
    "\n",
    "We will use the Pandas [read_csv][] function.  Our data file does not have column headers, so we need to specify the names.\n",
    "\n",
    "[read_csv]: https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Immediately after loading a data frame, I usually include a command to provide a brief preview of the data.  There are two good ways to do this.  The first is to use `head` to show the first few rows of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other good way is to use `info` to show a description of the columns, along with the shape and memory use of the data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:**  I usually include the `.info()` or `.head()` call in the same cell as the data load. I separate them out in this notebook so that I can discuss them in the markdown cells, but future notebooks will include them together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting the Data\n",
    "\n",
    "Let's make a bar plot showing the mean number of riders per weekday:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, the X-axis labels isn't very helpful.  Which day is 0?\n",
    "\n",
    "This is a question about how the data is _coded_. We'll talk more about data encoding next week. Unfortunately, the data documentation doesn't actually say how weekdays are coded!  But we can infer from the data in this case: first data point is January 1, 2011, which was a Saturday, coded as weekday 6; it then resets to 0 for the next day, and starts counting up.\n",
    "\n",
    "**Always *look* at your data.**\n",
    "\n",
    "Often, we will not be able to infer the data encoding from the data itself - we need to consult the codebook or data set description. We got lucky this time.  But looking at the data can help us make sense of the codebook.\n",
    "\n",
    "Let's turn these weekday numbers into a _categorical_ variable so Pandas knows how to label them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we plot again, Seaborn will use the names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congrats! We have now plotted the average rides per day.  When we do not tell [`catplot`](https://seaborn.pydata.org/generated/seaborn.catplot.html) what to do with multiple points for the same value (in this case the weekday name), it computes the mean and a bootstrapped 95% confidence interval.  We'll learn what those are in a couple weeks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Viewing over Time\n",
    "\n",
    "We can also try to view what happens to the data over time.  How did rides-per-day change over the course of the data set?\n",
    "\n",
    "This kind of data - a sequence of data points associated with times - is called a *time series*.  Helpfully, the data set gives us an `instant` column that records the data number since the start of the data set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But we can deal with this as actual times by converting the `dteday` column, which records the date, to a Pandas datetime object, and using that:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot the _weekly_ rides by resampling.  Right now, our `bikes` data is indexed by row number in the CSV file.  We can change its index to another column, such as our `dt` column with the date, which then lets us do things like resample by week:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What that code did, in one line, is:\n",
    "\n",
    "1. Set the data frame's index to `dt` (`bikes.set_index('dt')`), returning a new DF\n",
    "2. Select the count column (`['cnt']`), returning a series\n",
    "3. Resample the series by week (`.resample('1W')`)\n",
    "4. Combine measurements within each sample by summing them (`.sum()`)\n",
    "5. Plotting the results using Pandas' defaults (`.plot()`)\n",
    "\n",
    "Pandas default plotting functions are useful for quick plots to see what's in a data frame or series. They often are difficult to use to turn in to publication-ready charts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finished\n",
    "\n",
    "That's it, submit your final notebook in Canvas!"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "35837ef908ea9a487812f2c2b7a2faff0eaf2f169c08cc4139a89e69dc68f7b6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
