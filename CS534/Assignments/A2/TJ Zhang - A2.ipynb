{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15ed8245",
   "metadata": {},
   "source": [
    "### collaborator: Steven"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8805a69b",
   "metadata": {},
   "source": [
    "# Question 1 (15 pts)\n",
    "Implement the fit and predict procedures for the logistic regression (scikit is not allowed) with norm 2 regularization function (and Lambda parameter).\n",
    "\n",
    "Use as the input parameters of the gradient ascent the maximum number of iterations (just a constant e.g 100) and the learning factor (e.g. 0.01)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f59359",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def sigmoid(z):\n",
    "#     print(z)\n",
    "    a = 1/(1+np.exp(-z))\n",
    "    return a\n",
    "\n",
    "def initialize_with_zeros(dim):\n",
    "    w = np.zeros((dim,1))\n",
    "    b = 0\n",
    "#     print(w.shape)\n",
    "    return w,b\n",
    "    \n",
    "def propagate(w, b, X, Y):\n",
    "    \n",
    "    \"\"\"\n",
    "    parameters:\n",
    "    w -- \n",
    "    b -- \n",
    "    X -- dataset\n",
    "    Y -- label\n",
    "    lambda -- L2 regularization parameter\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    m = X.shape[1]\n",
    "#     print('w.t=',w.T)\n",
    "#     print('np.dot(w.T,X)=',np.dot(w.T,X))\n",
    "#     print(w.shape)\n",
    "#     print(np.dot(w.T,X))\n",
    "    A = sigmoid(np.dot(w.T,X)+b) \n",
    "    \n",
    "#     print('A=',A)\n",
    "    \n",
    "#     print('Y=',Y)\n",
    "#     print(type(Y))\n",
    "    \n",
    "#     print('np.log(A)=',np.log(A))\n",
    "\n",
    "    Lambda = 10 # you can choose your lambda for the L2 regurazation\n",
    "    \n",
    "    cost = -(np.sum(Y*np.log(A)+(1-Y)*np.log(1-A)))/m + Lambda*np.dot(w.T,w)             \n",
    "    \n",
    "    dZ = A-Y\n",
    "    \n",
    "    dw = (np.dot(X,dZ.T))/m\n",
    "    \n",
    "    db = (np.sum(dZ))/m\n",
    "\n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "\n",
    "    return grads, cost\n",
    "\n",
    "\n",
    "\n",
    "def optimize(w, b, X, Y, num_iterations, learning_rate, print_cost = False):\n",
    "    \n",
    "    costs = []\n",
    "    \n",
    "    for i in range(num_iterations):\n",
    "        \n",
    "        grads, cost = propagate(w,b,X,Y)\n",
    "        \n",
    "        dw = grads[\"dw\"]\n",
    "        \n",
    "        db = grads[\"db\"]\n",
    "\n",
    "        w = w - learning_rate*dw\n",
    "        \n",
    "        b = b - learning_rate*db\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        if print_cost and i % 100 == 0:\n",
    "            \n",
    "            print (\"Cost after iteration %i: %f\" %(i, cost))\n",
    "   \n",
    "    params = {\"w\": w,\n",
    "              \"b\": b}\n",
    "    \n",
    "    grads = {\"dw\": dw,\n",
    "             \"db\": db}\n",
    "    \n",
    "    return params, grads, costs\n",
    "\n",
    "def predict(w,b,X):\n",
    "    \n",
    "    m = X.shape[1]\n",
    "    \n",
    "    Y_prediction = np.zeros((1,m))\n",
    "\n",
    "    A = sigmoid(np.dot(w.T,X)+b)\n",
    "    \n",
    "    for  i in range(m):\n",
    "        \n",
    "        if A[0,i]>0.5:\n",
    "            \n",
    "            Y_prediction[0,i] = 1\n",
    "            \n",
    "        else:\n",
    "            \n",
    "            Y_prediction[0,i] = 0\n",
    "\n",
    "    return Y_prediction   \n",
    "\n",
    "def logistic_model(X_train,Y_train,X_test,Y_test,learning_rate=0.1,num_iterations=2000,print_cost=False):\n",
    "    \n",
    "    dim = X_train.shape[0]\n",
    "#     print('dim=',dim)\n",
    "    \n",
    "    W,b = initialize_with_zeros(dim)\n",
    "    \n",
    "#     print(W)\n",
    "\n",
    "    params,grads,costs = optimize(W,b,X_train,Y_train,num_iterations,learning_rate,print_cost)\n",
    "    \n",
    "    W = params['w']\n",
    "    b = params['b']\n",
    "\n",
    "    prediction_train = predict(W,b,X_train)\n",
    "    \n",
    "    print('prediction_train',prediction_train)\n",
    "    \n",
    "    print('Y_train',Y_train)\n",
    "    \n",
    "    # The test result using the W,b\n",
    "    \n",
    "    prediction_test = predict(W,b,X_test)\n",
    "\n",
    "    accuracy_train = 1 - np.mean(np.abs(prediction_train - Y_train))\n",
    "    \n",
    "    accuracy_test = 1 - np.mean(np.abs(prediction_test - Y_test))\n",
    "#     print(\"Accuracy on train set:\",accuracy_train )\n",
    "#     print(\"Accuracy on test set:\",accuracy_test )\n",
    "\n",
    "   \n",
    "    d = {\"costs:\": costs,\n",
    "         \"Y_prediction_test:\": prediction_test , \n",
    "         \"Y_prediction_train:\" : prediction_train , \n",
    "         \"w:\" : W, \n",
    "         \"b:\" : b,\n",
    "         \"learning_rate:\" : learning_rate,\n",
    "         \"num_iterations:\": num_iterations,\n",
    "         \"train_acy:\":accuracy_train,\n",
    "         \"test_acy:\":accuracy_test\n",
    "        }\n",
    "    return d "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b538742",
   "metadata": {},
   "source": [
    "##### Because the Logistic Regression is only for binary clsaa. Thus, in this Assignment, I just use the 'Iris Setosa' vs others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33081268",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 99)\n",
      "(4, 50)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv',sep=',').values\n",
    "X=data[:,0:4]\n",
    "y=data[:,4]\n",
    "\n",
    "def val(s):\n",
    "    if s=='Iris-setosa':\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "y=np.array([val(x) for x in y])\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "#print(X_train, X_test, y_train, y_test)\n",
    "\n",
    "#scaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "# reshape\n",
    "X_train = X_train.reshape(X_train.shape[0], -1).T\n",
    "X_test = X_test.reshape(X_test.shape[0], -1).T\n",
    "# y_train = y_train.reshape(y_train.shape[0], -1).T\n",
    "# y_test = y_test.reshape(y_test.shape[0], -1).T\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f878fe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w2 = np.zeros((4,1))\n",
    "# X_train \n",
    "\n",
    "# sigmoid(np.dot(w2.T,X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "19d48dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost after iteration 0: 0.693147\n",
      "prediction_train [[0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      "  0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0.\n",
      "  0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.\n",
      "  0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
      "  1. 0. 0.]]\n",
      "Y_train [0 0 0 1 0 0 1 1 1 0 0 1 1 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 1 0 0 0 1 0 0 1 0\n",
      " 1 1 0 0 0 0 0 0 1 1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 1\n",
      " 0 0 0 1 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "d = logistic_model(X_train, y_train, X_test, y_test, num_iterations = 100, learning_rate = 0.01, print_cost = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dd0de492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'costs:': [array([[0.69314718]])],\n",
       " 'Y_prediction_test:': array([[0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1., 0.,\n",
       "         0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 1.,\n",
       "         0., 1., 1., 0., 0., 1., 1., 1., 0., 0., 0., 1., 1., 0., 0., 0.,\n",
       "         0., 0.]]),\n",
       " 'Y_prediction_train:': array([[0., 0., 0., 1., 0., 0., 1., 1., 1., 0., 0., 1., 1., 1., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         1., 0., 0., 1., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0.,\n",
       "         0., 1., 1., 1., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0., 0.,\n",
       "         0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
       "         1., 0., 0.]]),\n",
       " 'w:': array([[-0.22699992],\n",
       "        [ 0.19565767],\n",
       "        [-0.30765931],\n",
       "        [-0.29500343]]),\n",
       " 'b:': -0.17497151725051963,\n",
       " 'learning_rate:': 0.01,\n",
       " 'num_iterations:': 100,\n",
       " 'train_acy:': 1.0,\n",
       " 'test_acy:': 1.0}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c2b9f7",
   "metadata": {},
   "source": [
    "# Question 2 (20 pts)\n",
    "Use the iris dataset (just the binary class Iris Setosa vs others), the K-fold cross validation, metrics(accuracy, precision, recall, F1-score) and the logistic regression with L2 regularization.\n",
    "You can use scikit.\n",
    "Please estimate the best parameter C(the inverse of lambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a739cb63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adddf0b6",
   "metadata": {},
   "source": [
    "#### Read the iris.csv in python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad41c7a0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.9, 3.0, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.1, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.6, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [5.4, 3.9, 1.7, 0.4, 'Iris-setosa'],\n",
       "       [4.6, 3.4, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [5.0, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [4.4, 2.9, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [5.4, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [4.8, 3.4, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [4.8, 3.0, 1.4, 0.1, 'Iris-setosa'],\n",
       "       [4.3, 3.0, 1.1, 0.1, 'Iris-setosa'],\n",
       "       [5.8, 4.0, 1.2, 0.2, 'Iris-setosa'],\n",
       "       [5.7, 4.4, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [5.4, 3.9, 1.3, 0.4, 'Iris-setosa'],\n",
       "       [5.1, 3.5, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [5.7, 3.8, 1.7, 0.3, 'Iris-setosa'],\n",
       "       [5.1, 3.8, 1.5, 0.3, 'Iris-setosa'],\n",
       "       [5.4, 3.4, 1.7, 0.2, 'Iris-setosa'],\n",
       "       [5.1, 3.7, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [4.6, 3.6, 1.0, 0.2, 'Iris-setosa'],\n",
       "       [5.1, 3.3, 1.7, 0.5, 'Iris-setosa'],\n",
       "       [4.8, 3.4, 1.9, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.0, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.4, 1.6, 0.4, 'Iris-setosa'],\n",
       "       [5.2, 3.5, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.2, 3.4, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.7, 3.2, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [4.8, 3.1, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [5.4, 3.4, 1.5, 0.4, 'Iris-setosa'],\n",
       "       [5.2, 4.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [5.5, 4.2, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [5.0, 3.2, 1.2, 0.2, 'Iris-setosa'],\n",
       "       [5.5, 3.5, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [4.9, 3.1, 1.5, 0.1, 'Iris-setosa'],\n",
       "       [4.4, 3.0, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [5.1, 3.4, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.5, 1.3, 0.3, 'Iris-setosa'],\n",
       "       [4.5, 2.3, 1.3, 0.3, 'Iris-setosa'],\n",
       "       [4.4, 3.2, 1.3, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.5, 1.6, 0.6, 'Iris-setosa'],\n",
       "       [5.1, 3.8, 1.9, 0.4, 'Iris-setosa'],\n",
       "       [4.8, 3.0, 1.4, 0.3, 'Iris-setosa'],\n",
       "       [5.1, 3.8, 1.6, 0.2, 'Iris-setosa'],\n",
       "       [4.6, 3.2, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [5.3, 3.7, 1.5, 0.2, 'Iris-setosa'],\n",
       "       [5.0, 3.3, 1.4, 0.2, 'Iris-setosa'],\n",
       "       [7.0, 3.2, 4.7, 1.4, 'Iris-versicolor'],\n",
       "       [6.4, 3.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [6.9, 3.1, 4.9, 1.5, 'Iris-versicolor'],\n",
       "       [5.5, 2.3, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [6.5, 2.8, 4.6, 1.5, 'Iris-versicolor'],\n",
       "       [5.7, 2.8, 4.5, 1.3, 'Iris-versicolor'],\n",
       "       [6.3, 3.3, 4.7, 1.6, 'Iris-versicolor'],\n",
       "       [4.9, 2.4, 3.3, 1.0, 'Iris-versicolor'],\n",
       "       [6.6, 2.9, 4.6, 1.3, 'Iris-versicolor'],\n",
       "       [5.2, 2.7, 3.9, 1.4, 'Iris-versicolor'],\n",
       "       [5.0, 2.0, 3.5, 1.0, 'Iris-versicolor'],\n",
       "       [5.9, 3.0, 4.2, 1.5, 'Iris-versicolor'],\n",
       "       [6.0, 2.2, 4.0, 1.0, 'Iris-versicolor'],\n",
       "       [6.1, 2.9, 4.7, 1.4, 'Iris-versicolor'],\n",
       "       [5.6, 2.9, 3.6, 1.3, 'Iris-versicolor'],\n",
       "       [6.7, 3.1, 4.4, 1.4, 'Iris-versicolor'],\n",
       "       [5.6, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [5.8, 2.7, 4.1, 1.0, 'Iris-versicolor'],\n",
       "       [6.2, 2.2, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [5.6, 2.5, 3.9, 1.1, 'Iris-versicolor'],\n",
       "       [5.9, 3.2, 4.8, 1.8, 'Iris-versicolor'],\n",
       "       [6.1, 2.8, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [6.3, 2.5, 4.9, 1.5, 'Iris-versicolor'],\n",
       "       [6.1, 2.8, 4.7, 1.2, 'Iris-versicolor'],\n",
       "       [6.4, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       "       [6.6, 3.0, 4.4, 1.4, 'Iris-versicolor'],\n",
       "       [6.8, 2.8, 4.8, 1.4, 'Iris-versicolor'],\n",
       "       [6.7, 3.0, 5.0, 1.7, 'Iris-versicolor'],\n",
       "       [6.0, 2.9, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [5.7, 2.6, 3.5, 1.0, 'Iris-versicolor'],\n",
       "       [5.5, 2.4, 3.8, 1.1, 'Iris-versicolor'],\n",
       "       [5.5, 2.4, 3.7, 1.0, 'Iris-versicolor'],\n",
       "       [5.8, 2.7, 3.9, 1.2, 'Iris-versicolor'],\n",
       "       [6.0, 2.7, 5.1, 1.6, 'Iris-versicolor'],\n",
       "       [5.4, 3.0, 4.5, 1.5, 'Iris-versicolor'],\n",
       "       [6.0, 3.4, 4.5, 1.6, 'Iris-versicolor'],\n",
       "       [6.7, 3.1, 4.7, 1.5, 'Iris-versicolor'],\n",
       "       [6.3, 2.3, 4.4, 1.3, 'Iris-versicolor'],\n",
       "       [5.6, 3.0, 4.1, 1.3, 'Iris-versicolor'],\n",
       "       [5.5, 2.5, 4.0, 1.3, 'Iris-versicolor'],\n",
       "       [5.5, 2.6, 4.4, 1.2, 'Iris-versicolor'],\n",
       "       [6.1, 3.0, 4.6, 1.4, 'Iris-versicolor'],\n",
       "       [5.8, 2.6, 4.0, 1.2, 'Iris-versicolor'],\n",
       "       [5.0, 2.3, 3.3, 1.0, 'Iris-versicolor'],\n",
       "       [5.6, 2.7, 4.2, 1.3, 'Iris-versicolor'],\n",
       "       [5.7, 3.0, 4.2, 1.2, 'Iris-versicolor'],\n",
       "       [5.7, 2.9, 4.2, 1.3, 'Iris-versicolor'],\n",
       "       [6.2, 2.9, 4.3, 1.3, 'Iris-versicolor'],\n",
       "       [5.1, 2.5, 3.0, 1.1, 'Iris-versicolor'],\n",
       "       [5.7, 2.8, 4.1, 1.3, 'Iris-versicolor'],\n",
       "       [6.3, 3.3, 6.0, 2.5, 'Iris-virginica'],\n",
       "       [5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       "       [7.1, 3.0, 5.9, 2.1, 'Iris-virginica'],\n",
       "       [6.3, 2.9, 5.6, 1.8, 'Iris-virginica'],\n",
       "       [6.5, 3.0, 5.8, 2.2, 'Iris-virginica'],\n",
       "       [7.6, 3.0, 6.6, 2.1, 'Iris-virginica'],\n",
       "       [4.9, 2.5, 4.5, 1.7, 'Iris-virginica'],\n",
       "       [7.3, 2.9, 6.3, 1.8, 'Iris-virginica'],\n",
       "       [6.7, 2.5, 5.8, 1.8, 'Iris-virginica'],\n",
       "       [7.2, 3.6, 6.1, 2.5, 'Iris-virginica'],\n",
       "       [6.5, 3.2, 5.1, 2.0, 'Iris-virginica'],\n",
       "       [6.4, 2.7, 5.3, 1.9, 'Iris-virginica'],\n",
       "       [6.8, 3.0, 5.5, 2.1, 'Iris-virginica'],\n",
       "       [5.7, 2.5, 5.0, 2.0, 'Iris-virginica'],\n",
       "       [5.8, 2.8, 5.1, 2.4, 'Iris-virginica'],\n",
       "       [6.4, 3.2, 5.3, 2.3, 'Iris-virginica'],\n",
       "       [6.5, 3.0, 5.5, 1.8, 'Iris-virginica'],\n",
       "       [7.7, 3.8, 6.7, 2.2, 'Iris-virginica'],\n",
       "       [7.7, 2.6, 6.9, 2.3, 'Iris-virginica'],\n",
       "       [6.0, 2.2, 5.0, 1.5, 'Iris-virginica'],\n",
       "       [6.9, 3.2, 5.7, 2.3, 'Iris-virginica'],\n",
       "       [5.6, 2.8, 4.9, 2.0, 'Iris-virginica'],\n",
       "       [7.7, 2.8, 6.7, 2.0, 'Iris-virginica'],\n",
       "       [6.3, 2.7, 4.9, 1.8, 'Iris-virginica'],\n",
       "       [6.7, 3.3, 5.7, 2.1, 'Iris-virginica'],\n",
       "       [7.2, 3.2, 6.0, 1.8, 'Iris-virginica'],\n",
       "       [6.2, 2.8, 4.8, 1.8, 'Iris-virginica'],\n",
       "       [6.1, 3.0, 4.9, 1.8, 'Iris-virginica'],\n",
       "       [6.4, 2.8, 5.6, 2.1, 'Iris-virginica'],\n",
       "       [7.2, 3.0, 5.8, 1.6, 'Iris-virginica'],\n",
       "       [7.4, 2.8, 6.1, 1.9, 'Iris-virginica'],\n",
       "       [7.9, 3.8, 6.4, 2.0, 'Iris-virginica'],\n",
       "       [6.4, 2.8, 5.6, 2.2, 'Iris-virginica'],\n",
       "       [6.3, 2.8, 5.1, 1.5, 'Iris-virginica'],\n",
       "       [6.1, 2.6, 5.6, 1.4, 'Iris-virginica'],\n",
       "       [7.7, 3.0, 6.1, 2.3, 'Iris-virginica'],\n",
       "       [6.3, 3.4, 5.6, 2.4, 'Iris-virginica'],\n",
       "       [6.4, 3.1, 5.5, 1.8, 'Iris-virginica'],\n",
       "       [6.0, 3.0, 4.8, 1.8, 'Iris-virginica'],\n",
       "       [6.9, 3.1, 5.4, 2.1, 'Iris-virginica'],\n",
       "       [6.7, 3.1, 5.6, 2.4, 'Iris-virginica'],\n",
       "       [6.9, 3.1, 5.1, 2.3, 'Iris-virginica'],\n",
       "       [5.8, 2.7, 5.1, 1.9, 'Iris-virginica'],\n",
       "       [6.8, 3.2, 5.9, 2.3, 'Iris-virginica'],\n",
       "       [6.7, 3.3, 5.7, 2.5, 'Iris-virginica'],\n",
       "       [6.7, 3.0, 5.2, 2.3, 'Iris-virginica'],\n",
       "       [6.3, 2.5, 5.0, 1.9, 'Iris-virginica'],\n",
       "       [6.5, 3.0, 5.2, 2.0, 'Iris-virginica'],\n",
       "       [6.2, 3.4, 5.4, 2.3, 'Iris-virginica'],\n",
       "       [5.9, 3.0, 5.1, 1.8, 'Iris-virginica']], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv',sep=',').values\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3063fd4f",
   "metadata": {},
   "source": [
    "#### The binary class Iris Setosa vs others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32f8a947",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data[:,0:4]\n",
    "y=data[:,4]\n",
    "def val(s):\n",
    "    if s=='Iris-setosa':\n",
    "        return 1\n",
    "    return 0\n",
    "y=np.array([val(x) for x in y])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e282c019",
   "metadata": {},
   "source": [
    "#### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fefe1920",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f82e36",
   "metadata": {},
   "source": [
    "#### use standardscaler in scikit to standarize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ca26dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697c27dd",
   "metadata": {},
   "source": [
    "#### k-fold cross validation + logisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0beb893d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best C:  0.001\n",
      "best F1:  1.0\n",
      "[0 1 0 0 0 1 0 0 0 0 0 1 1 1 1 0 0 0 0 0 1 0 1 0 0 0 0 0 1 1 1 1 0 1 1 0 0\n",
      " 1 1 1 0 0 0 1 1 0 0 0 0 0]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        31\n",
      "           1       1.00      1.00      1.00        19\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C=[0.001,0.005,0.01,0.05,0.1,0.5,1,5,10,50,100,500,1000,1000,10000000]\n",
    "bestclassifier=LogisticRegression(random_state=0, class_weight='balanced',penalty='l2')\n",
    "bestC=0\n",
    "bestValue=-1\n",
    "cv=10\n",
    "for c in C:\n",
    "    avgF1=0\n",
    "    skf = StratifiedKFold(n_splits=cv,random_state=10,shuffle=True )\n",
    "    for train_index, val_index in skf.split(X_train, y_train):\n",
    "        X_train1=X_train[train_index]\n",
    "        X_val=X_train[val_index]\n",
    "        y_train1=y_train[train_index]\n",
    "        y_val=y_train[val_index]\n",
    "        clf=LogisticRegression(random_state=0, class_weight='balanced',C=c,penalty='l2')\n",
    "        clf.fit(X_train1,y_train1)\n",
    "        y_pred_val=clf.predict(X_val)\n",
    "        avgF1+=f1_score(y_val, y_pred_val, average='macro')\n",
    "    #print(avgF1)\n",
    "    avgF1=avgF1/cv\n",
    "    if bestValue<avgF1:\n",
    "        bestValue=avgF1\n",
    "        bestC=c\n",
    "        bestclassifier=clf\n",
    "print('best C: ',bestC)\n",
    "print('best F1: ',bestValue)\n",
    "#testing\n",
    "y_pred=bestclassifier.predict(X_test)\n",
    "print(y_pred)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4038a6bf",
   "metadata": {},
   "source": [
    "#### The best parameter C is 0.001"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
