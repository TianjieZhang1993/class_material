{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collabrator: Steven Kim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nxrObr5C3su"
   },
   "source": [
    "# Question 1\n",
    "\n",
    "(20 points) Design and implement an iterative Power Method approach to\n",
    "determine the first principal component of the PCA transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh7wi_GODN6c"
   },
   "source": [
    "# Question 2\n",
    "\n",
    "(20 points) Design and implement an iterative Power Method\n",
    "approach to determine the second principal component of the PCA\n",
    "transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agqZlERPDUyE"
   },
   "source": [
    "# Problem Number 3\n",
    "\n",
    " (10 points) Describe the benefit of a gradient approach w.r.t.\n",
    "the SVD approach for the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are some reasons:\n",
    "\n",
    "1. PCA wants to do the eigen-decomposition of X.T * X to get the d's biggest eigen vectors, and SVD can calculate these. In scikit-learn, SVD is a part in PCA process.\n",
    "2. When the dataset is large, it is computing-comsuming to calculate the covariance matrix in PCA. Using SVD would be much faster than simply calculate the eigrn-decomposition of X.T * X.\n",
    "3. SVD is more accurate than eigenvalue Decomposition of covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-_Ep_p4Dw2x"
   },
   "source": [
    "# Question 4\n",
    "\n",
    "(20 points) Using a binary classifier (logistic regression or\n",
    "SVM) please implement in python both of the 2 different approaches\n",
    "(one vs. one, one vs. all) to handle the problem of more\n",
    "than two different classes (use the iris dataset). For\n",
    "reference use the following link\n",
    "https://en.wikipedia.org/wiki/Multiclass_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length  sepal width  petal length  petal width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "irisdata=pd.read_csv('iris.csv',header=0)\n",
    "irisdata.columns=['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "#irisdata=irisdata.drop(columns=['class'])\n",
    "\n",
    "irisdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# one vs one\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "y_dense = LabelBinarizer().fit_transform(irisdata['class'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZe4oSzXFfAh"
   },
   "source": [
    "# Question 5\n",
    "\n",
    "(20 points) Extensively describe the overfitting and\n",
    "underfitting problem. Use execution examples with a decision\n",
    "tree and SVM (with or without kernel). Use the scikit\n",
    "implementations. Show underfitting, good behavior, and overfitting examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: \n",
    "\n",
    "**Overfitting** occurs when a model is too closely aligned to a limited set of data points. As a result, the model is useful in reference only to its initial data set, and not applicable to any other data sets.\n",
    "\n",
    "**Underfitting** occurs when a model is unable to learn much from the training data. Therefore, the results of the application of the model in the training data or any other data sets are both not good.\n",
    "\n",
    "Because iris dataset is too small, I use the titanic data set to show the examples of overfitting, good behavior and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>FamilySize</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Pclass  FamilySize Fare Age\n",
       "0      0       3           1    0   2\n",
       "1      1       1           1    8   7\n",
       "2      1       3           0    2   4\n",
       "3      1       1           1    8   6\n",
       "4      0       3           0    2   6\n",
       "..   ...     ...         ...  ...  ..\n",
       "886    0       2           0    4   4\n",
       "887    1       1           0    7   1\n",
       "888    1       3           3    6   2\n",
       "889    0       1           0    7   4\n",
       "890    0       3           0    1   6\n",
       "\n",
       "[891 rows x 5 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_comb = df_train\n",
    "X = pd.DataFrame()\n",
    "\n",
    "def encode_sex(x):\n",
    "    return 1 if x == 'female' else 0\n",
    "\n",
    "def family_size(x):\n",
    "    size = x.SibSp + x.Parch \n",
    "    return 4 if size > 3 else size\n",
    "\n",
    "X['Sex'] = df_comb.Sex.map(encode_sex)\n",
    "X['Pclass'] = df_comb.Pclass\n",
    "X['FamilySize'] = df_comb.apply(family_size, axis=1)\n",
    "fare_median = df_train.groupby(['Sex', 'Pclass']).Fare.median()\n",
    "fare_median.name = 'FareMedian'\n",
    "\n",
    "age_mean = df_train.groupby(['Sex', 'Pclass']).Age.mean()\n",
    "age_mean.name = 'AgeMean'\n",
    "\n",
    "def join(df, stat):\n",
    "    return pd.merge(df, stat.to_frame(), left_on=['Sex', 'Pclass'], right_index=True, how='left')\n",
    "\n",
    "X['Fare'] = df_comb.Fare.fillna(join(df_comb, fare_median).FareMedian)\n",
    "X['Age'] = df_comb.Age.fillna(join(df_comb, age_mean).AgeMean)\n",
    "def quantiles(series, num):\n",
    "    return pd.qcut(series, num, retbins=True)[1]\n",
    "\n",
    "def discretize(series, bins):\n",
    "    return pd.cut(series, bins, labels=range(len(bins)-1), include_lowest=True)\n",
    "    \n",
    "X['Fare'] = discretize(X.Fare, quantiles(df_comb.Fare, 10))\n",
    "X['Age'] = discretize(X.Age, quantiles(df_comb.Age, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The underfitting situation:\n",
      "The accuracy in Training data set is: 0.6067415730337079\n",
      "The accuracy in Testing data set is: 0.6302521008403361\n",
      "The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting\n",
      "The overfitting situation:\n",
      "The accuracy in Training data set is: 0.8857677902621723\n",
      "The accuracy in Testing data set is: 0.8179271708683473\n",
      "The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting\n",
      "The good behavior situation:\n",
      "The accuracy in Training data set is: 0.8295880149812734\n",
      "The accuracy in Testing data set is: 0.7815126050420168\n",
      "The result show that the accuracy in Training data is similar to test data, that means the model is in good behavior\n"
     ]
    }
   ],
   "source": [
    "y=df_train.Survived\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=424)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,precision_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "clf=svm.SVC( C=0.00000001)\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat=clf.predict(X_test)\n",
    "X_hat=clf.predict(X_train)\n",
    "print('The underfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting')\n",
    "\n",
    "\n",
    "clf=svm.SVC( C=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat=clf.predict(X_test)\n",
    "X_hat=clf.predict(X_train)\n",
    "print('The overfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting')\n",
    "\n",
    "\n",
    "clf=svm.SVC( C=1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat=clf.predict(X_test)\n",
    "X_hat=clf.predict(X_train)\n",
    "print('The good behavior situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is similar to test data, that means the model is in good behavior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overfitting situation:\n",
      "The accuracy in Training data set is: 0.9176029962546817\n",
      "The accuracy in Testing data set is: 0.7843137254901961\n",
      "The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting\n",
      "The underfitting situation:\n",
      "The accuracy in Training data set is: 0.7921348314606742\n",
      "The accuracy in Testing data set is: 0.7787114845938375\n",
      "The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf1 = DecisionTreeClassifier(random_state=0,max_depth=100,max_leaf_nodes=100)\n",
    "clf1.fit(X_train,y_train)\n",
    "y_hat=clf1.predict(X_test)\n",
    "X_hat=clf1.predict(X_train)\n",
    "print('The overfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting')\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=0,max_depth=1,max_leaf_nodes=3)\n",
    "clf1.fit(X_train,y_train)\n",
    "y_hat=clf1.predict(X_test)\n",
    "X_hat=clf1.predict(X_train)\n",
    "print('The underfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wri4R6v6F52n"
   },
   "source": [
    "# Question 6\n",
    "(10 points) Show examples when the use of\n",
    "kernel procedure is more efficient in terms of training and\n",
    "prediction computational time w.r.t. polynomial features\n",
    "transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.001415252685546875\n",
      "0.002007007598876953\n",
      "0.001425027847290039\n",
      "0.001538991928100586\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('iris.csv',sep=',').values\n",
    "X=data[:,0:4]\n",
    "y=data[:,4]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=424)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf1=svm.SVC(kernel='poly')\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)\n",
    "end = time.time()\n",
    "print('Time needed for Poly Kernel',end-start)\n",
    "\n",
    "start = time.time()\n",
    "clf1=svm.SVC(kernel='rbf')\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "start = time.time()\n",
    "clf1=svm.SVC(kernel='linear')\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "\n",
    "start = time.time()\n",
    "clf1=svm.SVC()\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)\n",
    "end = time.time()\n",
    "print(end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OtA1JWGGL9C"
   },
   "source": [
    "# Question 7\n",
    "\n",
    "(10 points) Write a procedure to estimate in the SVC\n",
    "classifier (in Scikit) the best kernel (RBF, Polynomial,\n",
    "sigmoid), the best gamma & degree, and the best C. Use the\n",
    "grid search without implement it. Use the following\n",
    "reference:\n",
    "\n",
    "    a. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "    \n",
    "    b. https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'degree': [1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "                         'gamma': ('scale', 'auto'),\n",
       "                         'kernel': ('rbf', 'poly', 'sigmoid')})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':( 'rbf','poly','sigmoid'), \n",
    "              'C':[1,2,3,4,5,6,7,8,9,10],\n",
    "              'gamma':('scale', 'auto'),\n",
    "              'degree':[1,2,3,4,5,6,7,8,9]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'degree': 2, 'gamma': 'scale', 'kernel': 'poly'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(clf.cv_results_.keys())\n",
    "clf.best_params_\n",
    "#help(svm.SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLFt2gbhGXqD"
   },
   "source": [
    " # Question 8\n",
    " (20 points) Create examples to explain the property and the\n",
    "importance of the following kernels:\n",
    "    \n",
    "    a. https://en.wikipedia.org/wiki/Graph_kernel\n",
    "    \n",
    "    b. https://en.wikipedia.org/wiki/String_kernel\n",
    "\n",
    "    c. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.sigmoid_kernel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MidtermExam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
