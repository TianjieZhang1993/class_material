{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0nxrObr5C3su"
   },
   "source": [
    "# Question 1\n",
    "\n",
    "(20 points) Design and implement an iterative Power Method approach to\n",
    "determine the first principal component of the PCA transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power method is a iterative method that will converge to the largest eigenvalue. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, it is the first principal component:\n",
      "The  Eigenvalue: 2.9303514956384378\n",
      "And its Eigenvector: [ 0.8987037  -0.45306463  1.          0.97308834]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numpy import array\n",
    "from numpy import mean\n",
    "from numpy import cov\n",
    "from numpy.linalg import eig\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def converge(x):\n",
    "    highest_comp = abs(x).max()\n",
    "    x_n = x / x.max()\n",
    "    highest_index = np.where(x==highest_comp)\n",
    "    return highest_comp, highest_index, x_n\n",
    "\n",
    "\n",
    "def power_method(a):\n",
    "    \n",
    "    x = np.ones(len(a))\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        x = np.dot(a, x)\n",
    "        \n",
    "        highest_value, highest_index, x = converge(x)\n",
    "        #highest_value = Eigenvalue; x = Eigenvector\n",
    "        retX = x\n",
    "\n",
    "    return highest_value, highest_index, retX\n",
    "\n",
    "\n",
    "def customPCA(A, debug=False):\n",
    "    \n",
    "    V = cov(A.T)\n",
    "\n",
    "    highest_value, highest_index, vectors = power_method(V)\n",
    "\n",
    "    P = vectors.T.dot(A.T)\n",
    "\n",
    "    \n",
    "    return highest_value, highest_index[0][0], vectors\n",
    "\n",
    "\n",
    "columns_list = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "iris=pd.read_csv('iris.csv',header=0)\n",
    "iris.columns=columns_list\n",
    "iris=iris.drop(columns=['class'])\n",
    "\n",
    "iris_scaled = preprocessing.scale(iris)\n",
    "iris_scaled = pd.DataFrame(iris_scaled,columns=['sepal length', 'sepal width', 'petal length', 'petal width'])\n",
    "highest_value, highest_index, vectors = customPCA(iris_scaled)\n",
    "\n",
    "\n",
    "\n",
    "print('Thus, it is the first principal component:')\n",
    "print('The  Eigenvalue:', highest_value)\n",
    "print('And its Eigenvector:',vectors)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Eh7wi_GODN6c"
   },
   "source": [
    "# Question 2\n",
    "\n",
    "(20 points) Design and implement an iterative Power Method\n",
    "approach to determine the second principal component of the PCA\n",
    "transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thus, it is the second principal component:\n",
      "The  Eigenvalue: 0.9274036215173421\n",
      "And its Eigenvector: [-0.26335492 -0.92555649  0.24203288 -0.12413481]\n"
     ]
    }
   ],
   "source": [
    "def converge1(x):\n",
    "    \n",
    "    highest_comp = abs(x).max()\n",
    "    \n",
    "    x_n = x / x.max()\n",
    "    \n",
    "    \n",
    "    return highest_comp, x_n\n",
    "\n",
    "\n",
    "def power_method(a):\n",
    "\n",
    "    #a = a- highest_value*np.ones(len(a))\n",
    "    #print(a)\n",
    "    \n",
    "    x = np.ones(len(a))\n",
    "    \n",
    "    w,v=eig(a)\n",
    "\n",
    "    for i in range(10):\n",
    "\n",
    "        x = np.dot(a, x)\n",
    "        \n",
    "        second_value, x = converge1(x)\n",
    "        #second_value = Eigenvalue; x = Eigenvector\n",
    "        \n",
    "        retX = x\n",
    "\n",
    "    return second_value,  retX,w,v\n",
    "\n",
    "\n",
    "def customPCA(A, debug=False):\n",
    "    \n",
    "    V = cov(A.T)\n",
    "\n",
    "    second_value,  vectors,w,v = power_method(V)\n",
    "\n",
    "    P = vectors.T.dot(A.T)\n",
    "\n",
    "    \n",
    "    return second_value, vectors,w,v\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "columns_list = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "iris=pd.read_csv('iris.csv',header=0)\n",
    "iris.columns=columns_list\n",
    "iris=iris.drop(columns=['class'])\n",
    "\n",
    "iris_scaled = preprocessing.scale(iris)\n",
    "iris_scaled = pd.DataFrame(iris_scaled,columns=['sepal length', 'sepal width', 'petal length', 'petal width'])\n",
    "\n",
    "second_value,  vectors,w,v = customPCA(iris_scaled)\n",
    "\n",
    "print('Thus, it is the second principal component:')\n",
    "print('The  Eigenvalue:', w[1])\n",
    "print('And its Eigenvector:',v[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "agqZlERPDUyE"
   },
   "source": [
    "# Problem Number 3\n",
    "\n",
    " (10 points) Describe the benefit of a gradient approach w.r.t.\n",
    "the SVD approach for the PCA transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### There are some reasons:\n",
    "\n",
    "1. PCA wants to do the eigen-decomposition of X.T * X to get the d's biggest eigen vectors, and SVD can calculate these. In scikit-learn, SVD is a part in PCA process.\n",
    "2. When the dataset is large, it is computing-comsuming to calculate the covariance matrix in PCA. Using SVD would be much faster than simply calculate the eigrn-decomposition of X.T * X.\n",
    "3. SVD is more accurate than eigenvalue Decomposition of covariance matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q-_Ep_p4Dw2x"
   },
   "source": [
    "# Question 4\n",
    "\n",
    "(20 points) Using a binary classifier (logistic regression or\n",
    "SVM) please implement in python both of the 2 different approaches\n",
    "(one vs. one, one vs. all) to handle the problem of more\n",
    "than two different classes (use the iris dataset). For\n",
    "reference use the following link\n",
    "https://en.wikipedia.org/wiki/Multiclass_classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length</th>\n",
       "      <th>sepal width</th>\n",
       "      <th>petal length</th>\n",
       "      <th>petal width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.900681</td>\n",
       "      <td>1.032057</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.143017</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.385353</td>\n",
       "      <td>0.337848</td>\n",
       "      <td>-1.398138</td>\n",
       "      <td>-1.312977</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.506521</td>\n",
       "      <td>0.106445</td>\n",
       "      <td>-1.284407</td>\n",
       "      <td>-1.312977</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.021849</td>\n",
       "      <td>1.263460</td>\n",
       "      <td>-1.341272</td>\n",
       "      <td>-1.312977</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>1.038005</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.819624</td>\n",
       "      <td>1.447956</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.553333</td>\n",
       "      <td>-1.281972</td>\n",
       "      <td>0.705893</td>\n",
       "      <td>0.922064</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.795669</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.819624</td>\n",
       "      <td>1.053537</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.432165</td>\n",
       "      <td>0.800654</td>\n",
       "      <td>0.933356</td>\n",
       "      <td>1.447956</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.068662</td>\n",
       "      <td>-0.124958</td>\n",
       "      <td>0.762759</td>\n",
       "      <td>0.790591</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal length  sepal width  petal length  petal width           class\n",
       "0       -0.900681     1.032057     -1.341272    -1.312977     Iris-setosa\n",
       "1       -1.143017    -0.124958     -1.341272    -1.312977     Iris-setosa\n",
       "2       -1.385353     0.337848     -1.398138    -1.312977     Iris-setosa\n",
       "3       -1.506521     0.106445     -1.284407    -1.312977     Iris-setosa\n",
       "4       -1.021849     1.263460     -1.341272    -1.312977     Iris-setosa\n",
       "..            ...          ...           ...          ...             ...\n",
       "145      1.038005    -0.124958      0.819624     1.447956  Iris-virginica\n",
       "146      0.553333    -1.281972      0.705893     0.922064  Iris-virginica\n",
       "147      0.795669    -0.124958      0.819624     1.053537  Iris-virginica\n",
       "148      0.432165     0.800654      0.933356     1.447956  Iris-virginica\n",
       "149      0.068662    -0.124958      0.762759     0.790591  Iris-virginica\n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns_list = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "iris=pd.read_csv('iris.csv',header=0)\n",
    "iris.columns=columns_list\n",
    "y = iris['class']\n",
    "iris=iris.drop(columns=['class'])\n",
    "\n",
    "scaled = preprocessing.scale(iris)\n",
    "iris_scaled = pd.DataFrame(scaled,columns=['sepal length', 'sepal width', 'petal length', 'petal width'])\n",
    "iris_scaled['class'] = y\n",
    "iris_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. all (Rest)\n",
    "\n",
    "The One-vs-Rest strategy splits a multi-class classification into multiple binary classification problem per class. \n",
    "\n",
    "- Binary Classification Problem 1: class1 vs rest\n",
    "- Binary Classification Problem 2: class2 vs rest\n",
    "- Binary Classification Problem 3: class3 vs rest\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Iris-versicolor': array([[9.97171744e-01, 2.82825634e-03],\n",
      "       [9.92112407e-01, 7.88759347e-03],\n",
      "       [9.97293845e-01, 2.70615510e-03],\n",
      "       [9.95686390e-01, 4.31361033e-03],\n",
      "       [9.97569119e-01, 2.43088091e-03],\n",
      "       [9.91307238e-01, 8.69276171e-03],\n",
      "       [9.97449827e-01, 2.55017256e-03],\n",
      "       [9.96806610e-01, 3.19338998e-03],\n",
      "       [9.94018414e-01, 5.98158613e-03],\n",
      "       [9.95046929e-01, 4.95307052e-03],\n",
      "       [9.95159410e-01, 4.84059015e-03],\n",
      "       [9.97062175e-01, 2.93782538e-03],\n",
      "       [9.94848312e-01, 5.15168812e-03],\n",
      "       [9.97070110e-01, 2.92988958e-03],\n",
      "       [9.91494142e-01, 8.50585828e-03],\n",
      "       [9.85442124e-01, 1.45578762e-02],\n",
      "       [9.94145269e-01, 5.85473076e-03],\n",
      "       [9.96525408e-01, 3.47459225e-03],\n",
      "       [9.86141714e-01, 1.38582864e-02],\n",
      "       [9.96155797e-01, 3.84420255e-03],\n",
      "       [9.88942239e-01, 1.10577607e-02],\n",
      "       [9.95613676e-01, 4.38632398e-03],\n",
      "       [9.98156080e-01, 1.84391967e-03],\n",
      "       [9.80140616e-01, 1.98593837e-02],\n",
      "       [9.95391316e-01, 4.60868372e-03],\n",
      "       [9.85437714e-01, 1.45622862e-02],\n",
      "       [9.93651128e-01, 6.34887242e-03],\n",
      "       [9.96165322e-01, 3.83467826e-03],\n",
      "       [9.96059482e-01, 3.94051835e-03],\n",
      "       [9.95897402e-01, 4.10259792e-03],\n",
      "       [9.93595975e-01, 6.40402503e-03],\n",
      "       [9.85439627e-01, 1.45603732e-02],\n",
      "       [9.94044343e-01, 5.95565746e-03],\n",
      "       [9.91589216e-01, 8.41078437e-03],\n",
      "       [9.95046929e-01, 4.95307052e-03],\n",
      "       [9.96640193e-01, 3.35980724e-03],\n",
      "       [9.94238186e-01, 5.76181393e-03],\n",
      "       [9.95046929e-01, 4.95307052e-03],\n",
      "       [9.95991683e-01, 4.00831733e-03],\n",
      "       [9.96234889e-01, 3.76511086e-03],\n",
      "       [9.97343940e-01, 2.65605960e-03],\n",
      "       [9.56060012e-01, 4.39399883e-02],\n",
      "       [9.97361119e-01, 2.63888099e-03],\n",
      "       [9.90313930e-01, 9.68607029e-03],\n",
      "       [9.92734029e-01, 7.26597073e-03],\n",
      "       [9.91223342e-01, 8.77665796e-03],\n",
      "       [9.96293115e-01, 3.70688452e-03],\n",
      "       [9.97085819e-01, 2.91418059e-03],\n",
      "       [9.95958333e-01, 4.04166708e-03],\n",
      "       [9.96588680e-01, 3.41131964e-03],\n",
      "       [2.98429970e-02, 9.70157003e-01],\n",
      "       [1.29019104e-02, 9.87098090e-01],\n",
      "       [1.04417830e-01, 8.95582170e-01],\n",
      "       [2.00975323e-02, 9.79902468e-01],\n",
      "       [6.76457228e-02, 9.32354277e-01],\n",
      "       [1.29554008e-02, 9.87044599e-01],\n",
      "       [4.26567852e-02, 9.57343215e-01],\n",
      "       [2.54675413e-02, 9.74532459e-01],\n",
      "       [8.36075901e-03, 9.91639241e-01],\n",
      "       [3.05737578e-02, 9.69426242e-01],\n",
      "       [3.93106862e-02, 9.60689314e-01],\n",
      "       [1.23592415e-02, 9.87640758e-01],\n",
      "       [5.79932220e-03, 9.94200678e-01],\n",
      "       [2.54543615e-02, 9.74545638e-01],\n",
      "       [3.27133356e-03, 9.96728666e-01],\n",
      "       [6.98461666e-03, 9.93015383e-01],\n",
      "       [4.09326132e-02, 9.59067387e-01],\n",
      "       [4.31196187e-06, 9.99995688e-01],\n",
      "       [1.94444734e-01, 8.05555266e-01],\n",
      "       [3.24870784e-03, 9.96751292e-01],\n",
      "       [3.52700789e-01, 6.47299211e-01],\n",
      "       [1.50467670e-05, 9.99984953e-01],\n",
      "       [3.58169725e-01, 6.41830275e-01],\n",
      "       [6.95993487e-03, 9.93040065e-01],\n",
      "       [2.95445545e-03, 9.97045545e-01],\n",
      "       [7.48243247e-03, 9.92517568e-01],\n",
      "       [6.64739365e-02, 9.33526064e-01],\n",
      "       [5.78345842e-01, 4.21654158e-01],\n",
      "       [3.64838714e-02, 9.63516129e-01],\n",
      "       [4.67316848e-06, 9.99995327e-01],\n",
      "       [4.70782999e-03, 9.95292170e-01],\n",
      "       [3.37586553e-03, 9.96624134e-01],\n",
      "       [1.28204235e-05, 9.99987180e-01],\n",
      "       [7.09579817e-01, 2.90420183e-01],\n",
      "       [5.86271962e-02, 9.41372804e-01],\n",
      "       [2.54427985e-02, 9.74557201e-01],\n",
      "       [3.97871927e-02, 9.60212807e-01],\n",
      "       [3.42484826e-02, 9.65751517e-01],\n",
      "       [4.66575714e-03, 9.95334243e-01],\n",
      "       [1.29264315e-02, 9.87073569e-01],\n",
      "       [1.25507938e-02, 9.87449206e-01],\n",
      "       [1.26218718e-02, 9.87378128e-01],\n",
      "       [3.17333820e-03, 9.96826662e-01],\n",
      "       [1.91213392e-02, 9.80878661e-01],\n",
      "       [9.89566357e-03, 9.90104336e-01],\n",
      "       [1.82989600e-05, 9.99981701e-01],\n",
      "       [4.92584077e-03, 9.95074159e-01],\n",
      "       [3.01191519e-03, 9.96988085e-01],\n",
      "       [1.54267518e-02, 9.84573248e-01],\n",
      "       [5.10881427e-03, 9.94891186e-01],\n",
      "       [9.99439303e-01, 5.60696703e-04],\n",
      "       [9.85440046e-01, 1.45599536e-02],\n",
      "       [9.98901917e-01, 1.09808275e-03],\n",
      "       [9.86654375e-01, 1.33456252e-02],\n",
      "       [9.99675025e-01, 3.24974808e-04],\n",
      "       [9.99049029e-01, 9.50970585e-04],\n",
      "       [6.28012665e-01, 3.71987335e-01],\n",
      "       [9.96697517e-01, 3.30248340e-03],\n",
      "       [9.94216406e-01, 5.78359389e-03],\n",
      "       [9.95970232e-01, 4.02976795e-03],\n",
      "       [9.34187550e-01, 6.58124500e-02],\n",
      "       [9.92637074e-01, 7.36292578e-03],\n",
      "       [9.97725169e-01, 2.27483146e-03],\n",
      "       [9.92781940e-01, 7.21806024e-03],\n",
      "       [9.99718752e-01, 2.81247853e-04],\n",
      "       [9.96997306e-01, 3.00269400e-03],\n",
      "       [9.65911204e-01, 3.40887956e-02],\n",
      "       [9.91017502e-01, 8.98249785e-03],\n",
      "       [9.98633171e-01, 1.36682935e-03],\n",
      "       [4.90900757e-01, 5.09099243e-01],\n",
      "       [9.98840322e-01, 1.15967829e-03],\n",
      "       [9.82769269e-01, 1.72307308e-02],\n",
      "       [9.98304466e-01, 1.69553387e-03],\n",
      "       [9.10697299e-01, 8.93027010e-02],\n",
      "       [9.92352654e-01, 7.64734630e-03],\n",
      "       [9.85398496e-01, 1.46015043e-02],\n",
      "       [8.33965885e-01, 1.66034115e-01],\n",
      "       [7.22303046e-01, 2.77696954e-01],\n",
      "       [9.99521041e-01, 4.78958862e-04],\n",
      "       [9.34310680e-01, 6.56893201e-02],\n",
      "       [9.96710563e-01, 3.28943663e-03],\n",
      "       [9.85440051e-01, 1.45599492e-02],\n",
      "       [9.99781354e-01, 2.18645948e-04],\n",
      "       [3.40688675e-01, 6.59311325e-01],\n",
      "       [7.28675328e-01, 2.71324672e-01],\n",
      "       [9.98635263e-01, 1.36473702e-03],\n",
      "       [9.95393923e-01, 4.60607711e-03],\n",
      "       [9.39529818e-01, 6.04701825e-02],\n",
      "       [6.39329671e-01, 3.60670329e-01],\n",
      "       [9.94264868e-01, 5.73513180e-03],\n",
      "       [9.99617440e-01, 3.82559577e-04],\n",
      "       [9.96550856e-01, 3.44914385e-03],\n",
      "       [9.85440046e-01, 1.45599536e-02],\n",
      "       [9.99338819e-01, 6.61181210e-04],\n",
      "       [9.99112520e-01, 8.87480156e-04],\n",
      "       [9.98829371e-01, 1.17062873e-03],\n",
      "       [9.80679413e-01, 1.93205871e-02],\n",
      "       [9.86591445e-01, 1.34085550e-02],\n",
      "       [9.85706855e-01, 1.42931450e-02],\n",
      "       [8.43469967e-01, 1.56530033e-01]]), 'Iris-virginica': array([[9.92505978e-01, 7.49402156e-03],\n",
      "       [9.94437931e-01, 5.56206893e-03],\n",
      "       [9.90246647e-01, 9.75335277e-03],\n",
      "       [9.90679356e-01, 9.32064427e-03],\n",
      "       [9.89735274e-01, 1.02647262e-02],\n",
      "       [9.92123955e-01, 7.87604541e-03],\n",
      "       [9.88089298e-01, 1.19107018e-02],\n",
      "       [9.93444966e-01, 6.55503355e-03],\n",
      "       [9.85805008e-01, 1.41949919e-02],\n",
      "       [9.93394316e-01, 6.60568355e-03],\n",
      "       [9.92358345e-01, 7.64165533e-03],\n",
      "       [9.91604361e-01, 8.39563855e-03],\n",
      "       [9.91871478e-01, 8.12852166e-03],\n",
      "       [9.77438250e-01, 2.25617504e-02],\n",
      "       [9.85125412e-01, 1.48745885e-02],\n",
      "       [9.77462403e-01, 2.25375974e-02],\n",
      "       [9.89785456e-01, 1.02145435e-02],\n",
      "       [9.93785839e-01, 6.21416062e-03],\n",
      "       [9.94183052e-01, 5.81694826e-03],\n",
      "       [9.89166271e-01, 1.08337292e-02],\n",
      "       [9.96923152e-01, 3.07684808e-03],\n",
      "       [9.92344852e-01, 7.65514817e-03],\n",
      "       [9.77407020e-01, 2.25929796e-02],\n",
      "       [9.97949160e-01, 2.05083960e-03],\n",
      "       [9.93147440e-01, 6.85256014e-03],\n",
      "       [9.96229495e-01, 3.77050458e-03],\n",
      "       [9.95907317e-01, 4.09268305e-03],\n",
      "       [9.93967126e-01, 6.03287391e-03],\n",
      "       [9.94518169e-01, 5.48183074e-03],\n",
      "       [9.92295196e-01, 7.70480395e-03],\n",
      "       [9.94188325e-01, 5.81167529e-03],\n",
      "       [9.97606665e-01, 2.39333541e-03],\n",
      "       [9.79162501e-01, 2.08374988e-02],\n",
      "       [9.81052282e-01, 1.89477183e-02],\n",
      "       [9.93394316e-01, 6.60568355e-03],\n",
      "       [9.93308772e-01, 6.69122760e-03],\n",
      "       [9.94405438e-01, 5.59456231e-03],\n",
      "       [9.93394316e-01, 6.60568355e-03],\n",
      "       [9.84933298e-01, 1.50667022e-02],\n",
      "       [9.94344953e-01, 5.65504686e-03],\n",
      "       [9.92127889e-01, 7.87211074e-03],\n",
      "       [9.77423138e-01, 2.25768618e-02],\n",
      "       [9.83462686e-01, 1.65373138e-02],\n",
      "       [9.95997821e-01, 4.00217907e-03],\n",
      "       [9.92383243e-01, 7.61675651e-03],\n",
      "       [9.94438661e-01, 5.56133851e-03],\n",
      "       [9.88232506e-01, 1.17674938e-02],\n",
      "       [9.89218628e-01, 1.07813721e-02],\n",
      "       [9.91683253e-01, 8.31674669e-03],\n",
      "       [9.93862344e-01, 6.13765562e-03],\n",
      "       [9.77455152e-01, 2.25448479e-02],\n",
      "       [9.86910190e-01, 1.30898099e-02],\n",
      "       [9.02699160e-01, 9.73008400e-02],\n",
      "       [9.75229927e-01, 2.47700733e-02],\n",
      "       [9.36955581e-01, 6.30444195e-02],\n",
      "       [9.87315524e-01, 1.26844761e-02],\n",
      "       [9.47344848e-01, 5.26551521e-02],\n",
      "       [9.92514596e-01, 7.48540426e-03],\n",
      "       [9.93839129e-01, 6.16087091e-03],\n",
      "       [9.77399190e-01, 2.26008103e-02],\n",
      "       [9.77456694e-01, 2.25433060e-02],\n",
      "       [9.89377632e-01, 1.06223681e-02],\n",
      "       [9.96475261e-01, 3.52473928e-03],\n",
      "       [9.70893167e-01, 2.91068330e-02],\n",
      "       [9.99028777e-01, 9.71223307e-04],\n",
      "       [9.94796481e-01, 5.20351861e-03],\n",
      "       [9.62787850e-01, 3.72121500e-02],\n",
      "       [9.99431492e-01, 5.68507547e-04],\n",
      "       [8.76252112e-01, 1.23747888e-01],\n",
      "       [9.97486869e-01, 2.51313141e-03],\n",
      "       [5.89910911e-01, 4.10089089e-01],\n",
      "       [9.98496046e-01, 1.50395389e-03],\n",
      "       [6.79816610e-01, 3.20183390e-01],\n",
      "       [9.93907732e-01, 6.09226831e-03],\n",
      "       [9.97909096e-01, 2.09090369e-03],\n",
      "       [9.94140928e-01, 5.85907208e-03],\n",
      "       [9.53099630e-01, 4.69003703e-02],\n",
      "       [3.90181043e-01, 6.09818957e-01],\n",
      "       [9.56492692e-01, 4.35073080e-02],\n",
      "       [9.99607837e-01, 3.92163331e-04],\n",
      "       [9.96040732e-01, 3.95926814e-03],\n",
      "       [9.97857666e-01, 2.14233429e-03],\n",
      "       [9.98709992e-01, 1.29000791e-03],\n",
      "       [2.54686644e-01, 7.45313356e-01],\n",
      "       [9.55454292e-01, 4.45457077e-02],\n",
      "       [9.81257985e-01, 1.87420153e-02],\n",
      "       [9.58499974e-01, 4.15000258e-02],\n",
      "       [9.77434293e-01, 2.25657066e-02],\n",
      "       [9.98032658e-01, 1.96734235e-03],\n",
      "       [9.85382652e-01, 1.46173479e-02],\n",
      "       [9.86541380e-01, 1.34586199e-02],\n",
      "       [9.87011581e-01, 1.29884193e-02],\n",
      "       [9.97426693e-01, 2.57330711e-03],\n",
      "       [9.92245078e-01, 7.75492156e-03],\n",
      "       [9.90564871e-01, 9.43512890e-03],\n",
      "       [9.99030443e-01, 9.69556808e-04],\n",
      "       [9.96791444e-01, 3.20855555e-03],\n",
      "       [9.97706659e-01, 2.29334127e-03],\n",
      "       [9.96779353e-01, 3.22064723e-03],\n",
      "       [9.96221939e-01, 3.77806061e-03],\n",
      "       [3.18481045e-06, 9.99996815e-01],\n",
      "       [1.51044039e-02, 9.84895596e-01],\n",
      "       [1.04063133e-05, 9.99989594e-01],\n",
      "       [1.21657222e-02, 9.87834278e-01],\n",
      "       [6.05249353e-07, 9.99999395e-01],\n",
      "       [3.20084721e-03, 9.96799153e-01],\n",
      "       [3.78295953e-01, 6.21704047e-01],\n",
      "       [8.26697676e-03, 9.91733023e-01],\n",
      "       [1.50919807e-02, 9.84908019e-01],\n",
      "       [5.23285602e-03, 9.94767144e-01],\n",
      "       [4.65640342e-02, 9.53435966e-01],\n",
      "       [9.71166677e-03, 9.90288333e-01],\n",
      "       [2.80248578e-03, 9.97197514e-01],\n",
      "       [1.12061473e-02, 9.88793853e-01],\n",
      "       [1.42744623e-06, 9.99998573e-01],\n",
      "       [3.14555107e-03, 9.96854449e-01],\n",
      "       [2.72165654e-02, 9.72783435e-01],\n",
      "       [1.05004051e-02, 9.89499595e-01],\n",
      "       [1.51136923e-02, 9.84886308e-01],\n",
      "       [6.16964256e-01, 3.83035744e-01],\n",
      "       [5.94107796e-06, 9.99994059e-01],\n",
      "       [1.86861640e-02, 9.81313836e-01],\n",
      "       [1.00568334e-02, 9.89943167e-01],\n",
      "       [9.35709343e-02, 9.06429066e-01],\n",
      "       [5.78307189e-03, 9.94216928e-01],\n",
      "       [1.51052161e-02, 9.84894784e-01],\n",
      "       [1.47462564e-01, 8.52537436e-01],\n",
      "       [2.13897547e-01, 7.86102453e-01],\n",
      "       [1.72850334e-06, 9.99998271e-01],\n",
      "       [1.00630406e-01, 8.99369594e-01],\n",
      "       [1.10204301e-02, 9.88979570e-01],\n",
      "       [1.61262564e-02, 9.83873744e-01],\n",
      "       [5.00124181e-07, 9.99999500e-01],\n",
      "       [6.28975173e-01, 3.71024827e-01],\n",
      "       [3.05175425e-01, 6.94824575e-01],\n",
      "       [5.24782710e-03, 9.94752173e-01],\n",
      "       [5.76671044e-03, 9.94233290e-01],\n",
      "       [4.29776898e-02, 9.57022310e-01],\n",
      "       [2.88738851e-01, 7.11261149e-01],\n",
      "       [6.09137828e-03, 9.93908622e-01],\n",
      "       [1.12326205e-06, 9.99998877e-01],\n",
      "       [4.89784138e-03, 9.95102159e-01],\n",
      "       [1.51044039e-02, 9.84895596e-01],\n",
      "       [2.01547642e-06, 9.99997985e-01],\n",
      "       [5.19537849e-06, 9.99994805e-01],\n",
      "       [9.64257363e-06, 9.99990357e-01],\n",
      "       [3.17740870e-02, 9.68225913e-01],\n",
      "       [1.18711534e-02, 9.88128847e-01],\n",
      "       [1.51018640e-02, 9.84898136e-01],\n",
      "       [1.20916737e-01, 8.79083263e-01]]), 'Iris-setosa': array([[0.01006656, 0.98993344],\n",
      "       [0.01528714, 0.98471286],\n",
      "       [0.0101059 , 0.9898941 ],\n",
      "       [0.01284494, 0.98715506],\n",
      "       [0.01090662, 0.98909338],\n",
      "       [0.01536761, 0.98463239],\n",
      "       [0.01258226, 0.98741774],\n",
      "       [0.0099201 , 0.9900799 ],\n",
      "       [0.01959609, 0.98040391],\n",
      "       [0.01187297, 0.98812703],\n",
      "       [0.01302795, 0.98697205],\n",
      "       [0.01076104, 0.98923896],\n",
      "       [0.0131211 , 0.9868789 ],\n",
      "       [0.01544425, 0.98455575],\n",
      "       [0.01950659, 0.98049341],\n",
      "       [0.02395076, 0.97604924],\n",
      "       [0.01409548, 0.98590452],\n",
      "       [0.01047445, 0.98952555],\n",
      "       [0.01961769, 0.98038231],\n",
      "       [0.01333845, 0.98666155],\n",
      "       [0.01575843, 0.98424157],\n",
      "       [0.01286656, 0.98713344],\n",
      "       [0.01680069, 0.98319931],\n",
      "       [0.01957665, 0.98042335],\n",
      "       [0.01298558, 0.98701442],\n",
      "       [0.0195952 , 0.9804048 ],\n",
      "       [0.01256431, 0.98743569],\n",
      "       [0.01085381, 0.98914619],\n",
      "       [0.01064964, 0.98935036],\n",
      "       [0.01168345, 0.98831655],\n",
      "       [0.01329121, 0.98670879],\n",
      "       [0.01724777, 0.98275223],\n",
      "       [0.01942577, 0.98057423],\n",
      "       [0.01774959, 0.98225041],\n",
      "       [0.01187297, 0.98812703],\n",
      "       [0.01004697, 0.98995303],\n",
      "       [0.01451259, 0.98548741],\n",
      "       [0.01187297, 0.98812703],\n",
      "       [0.01548673, 0.98451327],\n",
      "       [0.01028341, 0.98971659],\n",
      "       [0.01014123, 0.98985877],\n",
      "       [0.14702331, 0.85297669],\n",
      "       [0.01363377, 0.98636623],\n",
      "       [0.01760829, 0.98239171],\n",
      "       [0.01649118, 0.98350882],\n",
      "       [0.01684254, 0.98315746],\n",
      "       [0.01369856, 0.98630144],\n",
      "       [0.01118338, 0.98881662],\n",
      "       [0.01224137, 0.98775863],\n",
      "       [0.00979944, 0.99020056],\n",
      "       [0.98345551, 0.01654449],\n",
      "       [0.98765389, 0.01234611],\n",
      "       [0.98775472, 0.01224528],\n",
      "       [0.99490281, 0.00509719],\n",
      "       [0.98997463, 0.01002537],\n",
      "       [0.99253409, 0.00746591],\n",
      "       [0.98825267, 0.01174733],\n",
      "       [0.98064868, 0.01935132],\n",
      "       [0.98613126, 0.01386874],\n",
      "       [0.99253529, 0.00746471],\n",
      "       [0.98063655, 0.01936345],\n",
      "       [0.9899019 , 0.0100981 ],\n",
      "       [0.98569038, 0.01430962],\n",
      "       [0.99167765, 0.00832235],\n",
      "       [0.98189115, 0.01810885],\n",
      "       [0.98478393, 0.01521607],\n",
      "       [0.98999793, 0.01000207],\n",
      "       [0.98727018, 0.01272982],\n",
      "       [0.98463425, 0.01536575],\n",
      "       [0.99298803, 0.00701197],\n",
      "       [0.98991503, 0.01008497],\n",
      "       [0.98946006, 0.01053994],\n",
      "       [0.98969485, 0.01030515],\n",
      "       [0.99003318, 0.00996682],\n",
      "       [0.98696632, 0.01303368],\n",
      "       [0.9865743 , 0.0134257 ],\n",
      "       [0.9853972 , 0.0146028 ],\n",
      "       [0.9910004 , 0.0089996 ],\n",
      "       [0.99248822, 0.00751178],\n",
      "       [0.98527018, 0.01472982],\n",
      "       [0.99341576, 0.00658424],\n",
      "       [0.99137799, 0.00862201],\n",
      "       [0.99095241, 0.00904759],\n",
      "       [0.99314336, 0.00685664],\n",
      "       [0.98815523, 0.01184477],\n",
      "       [0.98062935, 0.01937065],\n",
      "       [0.98846332, 0.01153668],\n",
      "       [0.9855082 , 0.0144918 ],\n",
      "       [0.98292272, 0.01707728],\n",
      "       [0.99519582, 0.00480418],\n",
      "       [0.99418397, 0.00581603],\n",
      "       [0.99026854, 0.00973146],\n",
      "       [0.99284002, 0.00715998],\n",
      "       [0.9848508 , 0.0151492 ],\n",
      "       [0.99365627, 0.00634373],\n",
      "       [0.98129693, 0.01870307],\n",
      "       [0.98918184, 0.01081816],\n",
      "       [0.98867145, 0.01132855],\n",
      "       [0.98004004, 0.01995996],\n",
      "       [0.99148241, 0.00851759],\n",
      "       [0.98058155, 0.01941845],\n",
      "       [0.9922558 , 0.0077442 ],\n",
      "       [0.99026428, 0.00973572],\n",
      "       [0.99149479, 0.00850521],\n",
      "       [0.9892401 , 0.0107599 ],\n",
      "       [0.98796104, 0.01203896],\n",
      "       [0.99322499, 0.00677501],\n",
      "       [0.98784206, 0.01215794],\n",
      "       [0.98219594, 0.01780406],\n",
      "       [0.98280459, 0.01719541],\n",
      "       [0.99152481, 0.00847519],\n",
      "       [0.98996994, 0.01003006],\n",
      "       [0.99067077, 0.00932923],\n",
      "       [0.99011926, 0.00988074],\n",
      "       [0.98242443, 0.01757557],\n",
      "       [0.98852444, 0.01147556],\n",
      "       [0.9918975 , 0.0081025 ],\n",
      "       [0.98058836, 0.01941164],\n",
      "       [0.98063989, 0.01936011],\n",
      "       [0.98608668, 0.01391332],\n",
      "       [0.98956863, 0.01043137],\n",
      "       [0.99153079, 0.00846921],\n",
      "       [0.98485671, 0.01514329],\n",
      "       [0.99159652, 0.00840348],\n",
      "       [0.9908691 , 0.0091309 ],\n",
      "       [0.99053665, 0.00946335],\n",
      "       [0.99266959, 0.00733041],\n",
      "       [0.99265454, 0.00734546],\n",
      "       [0.98886707, 0.01113293],\n",
      "       [0.98777599, 0.01222401],\n",
      "       [0.98683327, 0.01316673],\n",
      "       [0.98062123, 0.01937877],\n",
      "       [0.98756683, 0.01243317],\n",
      "       [0.99166893, 0.00833107],\n",
      "       [0.9893782 , 0.0106218 ],\n",
      "       [0.98654165, 0.01345835],\n",
      "       [0.98355876, 0.01644124],\n",
      "       [0.9920296 , 0.0079704 ],\n",
      "       [0.99260289, 0.00739711],\n",
      "       [0.99090052, 0.00909948],\n",
      "       [0.98763059, 0.01236941],\n",
      "       [0.98839196, 0.01160804],\n",
      "       [0.9922558 , 0.0077442 ],\n",
      "       [0.98927855, 0.01072145],\n",
      "       [0.98521386, 0.01478614],\n",
      "       [0.98845468, 0.01154532],\n",
      "       [0.98780816, 0.01219184],\n",
      "       [0.99160835, 0.00839165],\n",
      "       [0.98502158, 0.01497842],\n",
      "       [0.99228625, 0.00771375]])}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Iris-versicolor': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n",
       " 'Iris-virginica': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]),\n",
       " 'Iris-setosa': array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app_df = iris_scaled.copy()\n",
    "probb={}\n",
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def oneVSAll(df, debug = False):\n",
    "#     X_list = []\n",
    "#     y_list = []\n",
    "    list_class = {}\n",
    "    for i_class in set(y): # Loop through all class\n",
    "        \n",
    "        app_df = df.copy()\n",
    "        app_df.loc[app_df['class']!=i_class,'class'] = 0\n",
    "        app_df.loc[app_df['class']==i_class,'class'] = 1\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "        clf = svm.SVC(C=1,probability=True)\n",
    "        X = app_df.drop(columns=['class'])\n",
    "        Y = app_df['class'].astype('int')\n",
    "        clf.fit(X, Y)\n",
    "        y_hat = clf.predict(X)\n",
    "        \n",
    "        prob=clf.predict_proba(X)\n",
    "        probb[i_class]=prob\n",
    "        \n",
    "        list_class[i_class]=y_hat\n",
    "    print(probb)    \n",
    "    return list_class\n",
    "\n",
    "result = oneVSAll(iris_scaled)\n",
    "result\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Thus, combining the three classifiers, we can get the predictied result of multi-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_hat\n",
       "0       Iris-setosa\n",
       "1       Iris-setosa\n",
       "2       Iris-setosa\n",
       "3       Iris-setosa\n",
       "4       Iris-setosa\n",
       "..              ...\n",
       "145  Iris-virginica\n",
       "146  Iris-virginica\n",
       "147  Iris-virginica\n",
       "148  Iris-virginica\n",
       "149  Iris-virginica\n",
       "\n",
       "[150 rows x 1 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=[]\n",
    "for i in range(len(y)):\n",
    "\n",
    "    if result['Iris-versicolor'][i]==1:\n",
    "        \n",
    "        y_hat.append('Iris-versicolor')\n",
    "\n",
    "    elif result['Iris-virginica'][i]==1:\n",
    "        y_hat.append('Iris-virginica')\n",
    "\n",
    "    elif result['Iris-setosa'][i]==1:\n",
    "        y_hat.append('Iris-setosa')\n",
    "\n",
    "pd.DataFrame(y_hat,columns={'y_hat'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One vs. One\n",
    "\n",
    "The One-vs-One strategy splits a multi-class classification into one binary classification problem per each pair of classes.\n",
    "\n",
    "Unlike one-vs-rest that splits it into one binary dataset for each class, the one-vs-one approach splits the dataset into one dataset for each class versus every other class.\n",
    "\n",
    "- Binary Classification Problem 1: class 1 vs. class 2\n",
    "- Binary Classification Problem 2: class 1 vs. class 3\n",
    "\n",
    "...\n",
    "\n",
    "- Binary Classification Problem k-1: class 1 vs. class k\n",
    "- Binary Classification Problem k: class 2 vs. class 3\n",
    "\n",
    "...\n",
    "\n",
    "- Binary Classification Problem k(k-1)/2: class k-1 vs. class k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The class chosed of One vs. One in each binary classifier: \n",
      "{1: {'Iris-versicolor', 'Iris-virginica'}, 2: {'Iris-versicolor', 'Iris-setosa'}, 3: {'Iris-setosa', 'Iris-virginica'}}\n",
      "=============================\n",
      "The index chosed of One vs. One in each binary classifier: \n",
      "{1: Int64Index([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
      "             63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
      "             76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
      "             89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
      "            102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
      "            115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
      "            128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
      "            141, 142, 143, 144, 145, 146, 147, 148, 149],\n",
      "           dtype='int64'), 2: Int64Index([50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66,\n",
      "            67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83,\n",
      "            84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99,  0,\n",
      "             1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
      "            18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34,\n",
      "            35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49],\n",
      "           dtype='int64'), 3: Int64Index([100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
      "            113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125,\n",
      "            126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138,\n",
      "            139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149,   0,   1,\n",
      "              2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
      "             15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,\n",
      "             28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,\n",
      "             41,  42,  43,  44,  45,  46,  47,  48,  49],\n",
      "           dtype='int64')}\n",
      "=============================\n",
      "The probability of each class of One vs. One in each binary classifier: \n",
      "{1: array([[9.48446604e-01, 5.15533959e-02],\n",
      "       [9.69564945e-01, 3.04350546e-02],\n",
      "       [8.70794819e-01, 1.29205181e-01],\n",
      "       [9.48377382e-01, 5.16226185e-02],\n",
      "       [9.03468861e-01, 9.65311388e-02],\n",
      "       [9.72940260e-01, 2.70597397e-02],\n",
      "       [9.11048446e-01, 8.89515543e-02],\n",
      "       [9.53972732e-01, 4.60272684e-02],\n",
      "       [9.84053104e-01, 1.59468956e-02],\n",
      "       [9.48506328e-01, 5.14936720e-02],\n",
      "       [9.48407448e-01, 5.15925522e-02],\n",
      "       [9.77416733e-01, 2.25832673e-02],\n",
      "       [9.81814368e-01, 1.81856316e-02],\n",
      "       [9.48478148e-01, 5.15218518e-02],\n",
      "       [9.94673490e-01, 5.32650955e-03],\n",
      "       [9.85238245e-01, 1.47617548e-02],\n",
      "       [9.48390654e-01, 5.16093456e-02],\n",
      "       [9.95672042e-01, 4.32795810e-03],\n",
      "       [8.40792539e-01, 1.59207461e-01],\n",
      "       [9.87698010e-01, 1.23019900e-02],\n",
      "       [6.05974856e-01, 3.94025144e-01],\n",
      "       [9.94001870e-01, 5.99812955e-03],\n",
      "       [6.50223600e-01, 3.49776400e-01],\n",
      "       [9.82794995e-01, 1.72050051e-02],\n",
      "       [9.92945851e-01, 7.05414887e-03],\n",
      "       [9.84873210e-01, 1.51267899e-02],\n",
      "       [9.26019770e-01, 7.39802299e-02],\n",
      "       [4.24124700e-01, 5.75875300e-01],\n",
      "       [9.33899221e-01, 6.61007788e-02],\n",
      "       [9.95339702e-01, 4.66029825e-03],\n",
      "       [9.82654267e-01, 1.73457334e-02],\n",
      "       [9.86801604e-01, 1.31983961e-02],\n",
      "       [9.93741460e-01, 6.25853965e-03],\n",
      "       [2.81588561e-01, 7.18411439e-01],\n",
      "       [9.43141426e-01, 5.68585737e-02],\n",
      "       [9.48483470e-01, 5.15165304e-02],\n",
      "       [9.34611328e-01, 6.53886722e-02],\n",
      "       [9.48452676e-01, 5.15473238e-02],\n",
      "       [9.93148011e-01, 6.85198856e-03],\n",
      "       [9.62886822e-01, 3.71131785e-02],\n",
      "       [9.65039100e-01, 3.49609002e-02],\n",
      "       [9.73420290e-01, 2.65797104e-02],\n",
      "       [9.89523006e-01, 1.04769937e-02],\n",
      "       [9.61713548e-01, 3.82864516e-02],\n",
      "       [9.76324114e-01, 2.36758861e-02],\n",
      "       [9.95630548e-01, 4.36945177e-03],\n",
      "       [9.90580449e-01, 9.41955094e-03],\n",
      "       [9.92557149e-01, 7.44285135e-03],\n",
      "       [9.71869989e-01, 2.81300106e-02],\n",
      "       [9.88603157e-01, 1.13968427e-02],\n",
      "       [8.91890940e-03, 9.91081091e-01],\n",
      "       [3.19857164e-02, 9.68014284e-01],\n",
      "       [9.15072125e-03, 9.90849279e-01],\n",
      "       [2.23600838e-02, 9.77639916e-01],\n",
      "       [1.38583626e-05, 9.99986142e-01],\n",
      "       [1.89002112e-02, 9.81099789e-01],\n",
      "       [4.29206790e-01, 5.70793210e-01],\n",
      "       [2.73099991e-02, 9.72690001e-01],\n",
      "       [3.85690598e-02, 9.61430940e-01],\n",
      "       [3.86599630e-02, 9.61340037e-01],\n",
      "       [8.01747545e-02, 9.19825245e-01],\n",
      "       [1.90460193e-02, 9.80953981e-01],\n",
      "       [9.35775109e-03, 9.90642249e-01],\n",
      "       [3.07767058e-02, 9.69223294e-01],\n",
      "       [3.99238033e-03, 9.96007620e-01],\n",
      "       [1.12143265e-02, 9.88785673e-01],\n",
      "       [4.68688506e-02, 9.53131149e-01],\n",
      "       [4.44421347e-02, 9.55557865e-01],\n",
      "       [4.69436883e-02, 9.53056312e-01],\n",
      "       [6.30399726e-01, 3.69600274e-01],\n",
      "       [8.61877404e-03, 9.91381226e-01],\n",
      "       [4.69516963e-02, 9.53048304e-01],\n",
      "       [3.43252379e-02, 9.65674762e-01],\n",
      "       [1.18064636e-01, 8.81935364e-01],\n",
      "       [2.15803530e-02, 9.78419647e-01],\n",
      "       [4.69602128e-02, 9.53039787e-01],\n",
      "       [1.68581817e-01, 8.31418183e-01],\n",
      "       [2.47290151e-01, 7.52709849e-01],\n",
      "       [2.58537281e-03, 9.97414627e-01],\n",
      "       [1.65347929e-01, 8.34652071e-01],\n",
      "       [3.30121339e-02, 9.66987866e-01],\n",
      "       [4.69174384e-02, 9.53082562e-01],\n",
      "       [9.09214079e-06, 9.99990908e-01],\n",
      "       [5.97432062e-01, 4.02567938e-01],\n",
      "       [3.13396813e-01, 6.86603187e-01],\n",
      "       [2.80579850e-02, 9.71942015e-01],\n",
      "       [2.65674838e-02, 9.73432516e-01],\n",
      "       [7.08697979e-02, 9.29130202e-01],\n",
      "       [3.25599091e-01, 6.74400909e-01],\n",
      "       [1.96874189e-02, 9.80312581e-01],\n",
      "       [3.95048255e-03, 9.96049517e-01],\n",
      "       [1.78450655e-02, 9.82154934e-01],\n",
      "       [3.19857164e-02, 9.68014284e-01],\n",
      "       [5.76793132e-03, 9.94232069e-01],\n",
      "       [1.02989476e-02, 9.89701052e-01],\n",
      "       [6.66939258e-03, 9.93330607e-01],\n",
      "       [5.87723075e-02, 9.41227693e-01],\n",
      "       [2.31496474e-02, 9.76850353e-01],\n",
      "       [4.69407895e-02, 9.53059211e-01],\n",
      "       [1.73943432e-01, 8.26056568e-01]]), 2: array([[0.96628342, 0.03371658],\n",
      "       [0.98134654, 0.01865346],\n",
      "       [0.97159051, 0.02840949],\n",
      "       [0.99104797, 0.00895203],\n",
      "       [0.97922505, 0.02077495],\n",
      "       [0.98494899, 0.01505101],\n",
      "       [0.97907722, 0.02092278],\n",
      "       [0.9663129 , 0.0336871 ],\n",
      "       [0.9770779 , 0.0229221 ],\n",
      "       [0.9825658 , 0.0174342 ],\n",
      "       [0.96627586, 0.03372414],\n",
      "       [0.98224156, 0.01775844],\n",
      "       [0.97601486, 0.02398514],\n",
      "       [0.98464815, 0.01535185],\n",
      "       [0.96889289, 0.03110711],\n",
      "       [0.97734609, 0.02265391],\n",
      "       [0.97766692, 0.02233308],\n",
      "       [0.97942493, 0.02057507],\n",
      "       [0.96625925, 0.03374075],\n",
      "       [0.98843052, 0.01156948],\n",
      "       [0.97538701, 0.02461299],\n",
      "       [0.98346671, 0.01653329],\n",
      "       [0.97342248, 0.02657752],\n",
      "       [0.98235892, 0.01764108],\n",
      "       [0.98076503, 0.01923497],\n",
      "       [0.97947934, 0.02052066],\n",
      "       [0.96622746, 0.03377254],\n",
      "       [0.97427637, 0.02572363],\n",
      "       [0.98549897, 0.01450103],\n",
      "       [0.97758476, 0.02241524],\n",
      "       [0.98938593, 0.01061407],\n",
      "       [0.98659119, 0.01340881],\n",
      "       [0.98502293, 0.01497707],\n",
      "       [0.98065793, 0.01934207],\n",
      "       [0.97010778, 0.02989222],\n",
      "       [0.96632755, 0.03367245],\n",
      "       [0.97877197, 0.02122803],\n",
      "       [0.97061384, 0.02938616],\n",
      "       [0.96951208, 0.03048792],\n",
      "       [0.9910006 , 0.0089994 ],\n",
      "       [0.98825722, 0.01174278],\n",
      "       [0.98381806, 0.01618194],\n",
      "       [0.98781799, 0.01218201],\n",
      "       [0.97481887, 0.02518113],\n",
      "       [0.98748994, 0.01251006],\n",
      "       [0.96939738, 0.03060262],\n",
      "       [0.98048652, 0.01951348],\n",
      "       [0.9829016 , 0.0170984 ],\n",
      "       [0.96627857, 0.03372143],\n",
      "       [0.98442445, 0.01557555],\n",
      "       [0.01147163, 0.98852837],\n",
      "       [0.01571319, 0.98428681],\n",
      "       [0.01173546, 0.98826454],\n",
      "       [0.01414866, 0.98585134],\n",
      "       [0.01242679, 0.98757321],\n",
      "       [0.0152678 , 0.9847322 ],\n",
      "       [0.01443258, 0.98556742],\n",
      "       [0.01129179, 0.98870821],\n",
      "       [0.01937602, 0.98062398],\n",
      "       [0.01306917, 0.98693083],\n",
      "       [0.01396018, 0.98603982],\n",
      "       [0.01231616, 0.98768384],\n",
      "       [0.01405436, 0.98594564],\n",
      "       [0.01742347, 0.98257653],\n",
      "       [0.01806947, 0.98193053],\n",
      "       [0.01935189, 0.98064811],\n",
      "       [0.0142431 , 0.9857569 ],\n",
      "       [0.01171312, 0.98828688],\n",
      "       [0.0193882 , 0.9806118 ],\n",
      "       [0.01425081, 0.98574919],\n",
      "       [0.01672198, 0.98327802],\n",
      "       [0.01384119, 0.98615881],\n",
      "       [0.01940071, 0.98059929],\n",
      "       [0.01940288, 0.98059712],\n",
      "       [0.01429951, 0.98570049],\n",
      "       [0.01941655, 0.98058345],\n",
      "       [0.01342362, 0.98657638],\n",
      "       [0.0121297 , 0.9878703 ],\n",
      "       [0.01194092, 0.98805908],\n",
      "       [0.01306368, 0.98693632],\n",
      "       [0.0141946 , 0.9858054 ],\n",
      "       [0.0178985 , 0.9821015 ],\n",
      "       [0.01848109, 0.98151891],\n",
      "       [0.01584933, 0.98415067],\n",
      "       [0.01306917, 0.98693083],\n",
      "       [0.01138843, 0.98861157],\n",
      "       [0.01572225, 0.98427775],\n",
      "       [0.01306917, 0.98693083],\n",
      "       [0.01668836, 0.98331164],\n",
      "       [0.01157329, 0.98842671],\n",
      "       [0.01153452, 0.98846548],\n",
      "       [0.07965551, 0.92034449],\n",
      "       [0.01594694, 0.98405306],\n",
      "       [0.01791044, 0.98208956],\n",
      "       [0.01692692, 0.98307308],\n",
      "       [0.01693073, 0.98306927],\n",
      "       [0.01466937, 0.98533063],\n",
      "       [0.0129163 , 0.9870837 ],\n",
      "       [0.01328162, 0.98671838],\n",
      "       [0.01113375, 0.98886625]]), 3: array([[0.97875423, 0.02124577],\n",
      "       [0.98773891, 0.01226109],\n",
      "       [0.98754915, 0.01245085],\n",
      "       [0.98621254, 0.01378746],\n",
      "       [0.98789651, 0.01210349],\n",
      "       [0.98424825, 0.01575175],\n",
      "       [0.97118982, 0.02881018],\n",
      "       [0.98398301, 0.01601699],\n",
      "       [0.98346175, 0.01653825],\n",
      "       [0.97879863, 0.02120137],\n",
      "       [0.98018782, 0.01981218],\n",
      "       [0.98742744, 0.01257256],\n",
      "       [0.9872277 , 0.0127723 ],\n",
      "       [0.98815279, 0.01184721],\n",
      "       [0.98584458, 0.01415542],\n",
      "       [0.98249077, 0.01750923],\n",
      "       [0.98461179, 0.01538821],\n",
      "       [0.97384276, 0.02615724],\n",
      "       [0.97226641, 0.02773359],\n",
      "       [0.97222036, 0.02777964],\n",
      "       [0.98629557, 0.01370443],\n",
      "       [0.98527575, 0.01472425],\n",
      "       [0.97919407, 0.02080593],\n",
      "       [0.98464019, 0.01535981],\n",
      "       [0.9839433 , 0.0160567 ],\n",
      "       [0.98444239, 0.01555761],\n",
      "       [0.98305821, 0.01694179],\n",
      "       [0.97841632, 0.02158368],\n",
      "       [0.98877245, 0.01122755],\n",
      "       [0.98023174, 0.01976826],\n",
      "       [0.98303582, 0.01696418],\n",
      "       [0.97219165, 0.02780835],\n",
      "       [0.9886275 , 0.0113725 ],\n",
      "       [0.97748253, 0.02251747],\n",
      "       [0.97999655, 0.02000345],\n",
      "       [0.98272809, 0.01727191],\n",
      "       [0.97514607, 0.02485393],\n",
      "       [0.98214063, 0.01785937],\n",
      "       [0.97630468, 0.02369532],\n",
      "       [0.98603059, 0.01396941],\n",
      "       [0.98602409, 0.01397591],\n",
      "       [0.9840475 , 0.0159525 ],\n",
      "       [0.98773891, 0.01226109],\n",
      "       [0.98651489, 0.01348511],\n",
      "       [0.98240233, 0.01759767],\n",
      "       [0.98575824, 0.01424176],\n",
      "       [0.98548194, 0.01451806],\n",
      "       [0.98543222, 0.01456778],\n",
      "       [0.97223695, 0.02776305],\n",
      "       [0.97916   , 0.02084   ],\n",
      "       [0.01470968, 0.98529032],\n",
      "       [0.01709962, 0.98290038],\n",
      "       [0.01628301, 0.98371699],\n",
      "       [0.01788652, 0.98211348],\n",
      "       [0.01480267, 0.98519733],\n",
      "       [0.01437364, 0.98562636],\n",
      "       [0.0186036 , 0.9813964 ],\n",
      "       [0.01536529, 0.98463471],\n",
      "       [0.01961429, 0.98038571],\n",
      "       [0.01682361, 0.98317639],\n",
      "       [0.01479556, 0.98520444],\n",
      "       [0.0166821 , 0.9833179 ],\n",
      "       [0.01666977, 0.98333023],\n",
      "       [0.02059523, 0.97940477],\n",
      "       [0.01742756, 0.98257244],\n",
      "       [0.02056814, 0.97943186],\n",
      "       [0.0137269 , 0.9862731 ],\n",
      "       [0.01467706, 0.98532294],\n",
      "       [0.0176663 , 0.9823337 ],\n",
      "       [0.01427866, 0.98572134],\n",
      "       [0.01901245, 0.98098755],\n",
      "       [0.01452861, 0.98547139],\n",
      "       [0.02061966, 0.97938034],\n",
      "       [0.02062889, 0.97937111],\n",
      "       [0.01859571, 0.98140429],\n",
      "       [0.01920339, 0.98079661],\n",
      "       [0.01667302, 0.98332698],\n",
      "       [0.01513139, 0.98486861],\n",
      "       [0.01558407, 0.98441593],\n",
      "       [0.01756688, 0.98243312],\n",
      "       [0.01744998, 0.98255002],\n",
      "       [0.01900368, 0.98099632],\n",
      "       [0.01682605, 0.98317395],\n",
      "       [0.01594499, 0.98405501],\n",
      "       [0.01682361, 0.98317639],\n",
      "       [0.01550925, 0.98449075],\n",
      "       [0.01757157, 0.98242843],\n",
      "       [0.01682361, 0.98317639],\n",
      "       [0.0192508 , 0.9807492 ],\n",
      "       [0.01544306, 0.98455694],\n",
      "       [0.01466707, 0.98533293],\n",
      "       [0.03223252, 0.96776748],\n",
      "       [0.02053407, 0.97946593],\n",
      "       [0.01902644, 0.98097356],\n",
      "       [0.01596475, 0.98403525],\n",
      "       [0.01760576, 0.98239424],\n",
      "       [0.01476905, 0.98523095],\n",
      "       [0.01755171, 0.98244829],\n",
      "       [0.01434991, 0.98565009],\n",
      "       [0.01547272, 0.98452728]])}\n"
     ]
    }
   ],
   "source": [
    "columns_list = ['sepal length', 'sepal width', 'petal length', 'petal width', 'class']\n",
    "iris=pd.read_csv('iris.csv',header=0)\n",
    "iris.columns=columns_list\n",
    "y = iris['class']\n",
    "iris=iris.drop(columns=['class'])\n",
    "\n",
    "scaled = preprocessing.scale(iris)\n",
    "iris_scaled = pd.DataFrame(scaled,columns=['sepal length', 'sepal width', 'petal length', 'petal width'])\n",
    "iris_scaled['class'] = y\n",
    "iris_scaled\n",
    "\n",
    "\n",
    "#print(len(set(y)))\n",
    "y_hat=[]\n",
    "indexdic={}\n",
    "kinddic={}\n",
    "app_df = iris_scaled.copy()\n",
    "#print(list(set(y))[0])\n",
    "list_class={}\n",
    "\n",
    "for i in range(len(set(y))-1):\n",
    "#     print('i=',i)\n",
    "    for j in range(i+1,len(set(y))):\n",
    "#         print('j=',j)\n",
    "        \n",
    "        index_i=app_df.loc[app_df['class']==list(set(y))[i]].index\n",
    "#         print(index_i)\n",
    "        index_j=app_df.loc[app_df['class']==list(set(y))[j]].index\n",
    "#         print(index_j)\n",
    "     #print(index_i.append(index_j))\n",
    "        \n",
    "        class1=app_df.loc[index_i]\n",
    "        class1.loc[class1['class']==list(set(y))[i],'class']=0\n",
    "        #print(list(set(y))[i],list(set(y))[j])\n",
    "        class2=app_df.loc[index_j]\n",
    "        class2.loc[class2['class']==list(set(y))[j],'class']=1\n",
    "#         print(class1)\n",
    "#         print(class2)\n",
    "        \n",
    "        clf = svm.SVC(C=1,probability=True)\n",
    "        \n",
    "        data=pd.concat([class1,class2])\n",
    "        \n",
    "        #data=class1.append(class2)\n",
    "#         print(data)\n",
    "        \n",
    "        X = data.drop(columns=['class'])\n",
    "        \n",
    "        Y = data['class'].astype('int')\n",
    "        #print(data)\n",
    "        clf.fit(X, Y)\n",
    "        \n",
    "        #print(index_i.append(index_j))\n",
    "        y_proba = clf.predict_proba(X)\n",
    "        \n",
    "#         X['y_hat']=y_hat\n",
    "#         testdf = pd.DataFrame(index_i.append(index_j))\n",
    "#         print(testdf)\n",
    "#         print(y_hat)\n",
    "#         testdf[\"yhat\"] = y_hat\n",
    "#         print(testdf)\n",
    "        \n",
    "#         pd.merge(app_df,y_hat,how='left',on=)\n",
    "        \n",
    "        list_class[i+j]=y_proba\n",
    "        indexdic[i+j]=index_i.append(index_j)\n",
    "        kinddic[i+j]={list(set(y))[i],list(set(y))[j]}\n",
    "        \n",
    "\n",
    "print('The class chosed of One vs. One in each binary classifier: ')\n",
    "\n",
    "print(kinddic)\n",
    "print('=============================')\n",
    "print('The index chosed of One vs. One in each binary classifier: ')\n",
    "print(indexdic)\n",
    "\n",
    "print('=============================')\n",
    "print('The probability of each class of One vs. One in each binary classifier: ') \n",
    "print(list_class)\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For this iris case, we combine the results from one vs. one together ( add the probability together) and get the final result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([ 50,  51,  52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,\n",
       "             63,  64,  65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,\n",
       "             76,  77,  78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,\n",
       "             89,  90,  91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101,\n",
       "            102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114,\n",
       "            115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127,\n",
       "            128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "            141, 142, 143, 144, 145, 146, 147, 148, 149],\n",
       "           dtype='int64')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indexdic[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-versicolor_x</th>\n",
       "      <th>Iris-virginica_x</th>\n",
       "      <th>Iris-versicolor_y</th>\n",
       "      <th>Iris-setosa_x</th>\n",
       "      <th>Iris-setosa_y</th>\n",
       "      <th>Iris-virginica_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.988528</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.985290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.988265</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.983717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.985851</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.982113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.985197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.006669</td>\n",
       "      <td>0.993331</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.014242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.941228</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985482</td>\n",
       "      <td>0.014518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.023150</td>\n",
       "      <td>0.976850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.985432</td>\n",
       "      <td>0.014568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.953059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.972237</td>\n",
       "      <td>0.027763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.173943</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.020840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-versicolor_x  Iris-virginica_x  Iris-versicolor_y  Iris-setosa_x  \\\n",
       "0                  NaN               NaN           0.011472       0.988528   \n",
       "1                  NaN               NaN           0.015713       0.984287   \n",
       "2                  NaN               NaN           0.011735       0.988265   \n",
       "3                  NaN               NaN           0.014149       0.985851   \n",
       "4                  NaN               NaN           0.012427       0.987573   \n",
       "..                 ...               ...                ...            ...   \n",
       "145           0.006669          0.993331                NaN            NaN   \n",
       "146           0.058772          0.941228                NaN            NaN   \n",
       "147           0.023150          0.976850                NaN            NaN   \n",
       "148           0.046941          0.953059                NaN            NaN   \n",
       "149           0.173943          0.826057                NaN            NaN   \n",
       "\n",
       "     Iris-setosa_y  Iris-virginica_y  \n",
       "0         0.014710          0.985290  \n",
       "1         0.017100          0.982900  \n",
       "2         0.016283          0.983717  \n",
       "3         0.017887          0.982113  \n",
       "4         0.014803          0.985197  \n",
       "..             ...               ...  \n",
       "145       0.985758          0.014242  \n",
       "146       0.985482          0.014518  \n",
       "147       0.985432          0.014568  \n",
       "148       0.972237          0.027763  \n",
       "149       0.979160          0.020840  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1=pd.DataFrame(list_class[1],columns=kinddic[1],index=indexdic[1])\n",
    "clf2=pd.DataFrame(list_class[2],columns=kinddic[2],index=indexdic[2])\n",
    "clf3=pd.DataFrame(list_class[3],columns=kinddic[3],index=indexdic[3])\n",
    "\n",
    "clf12=pd.merge(clf1,clf2,how='outer',left_index=True,right_index=True)\n",
    "clf123=pd.merge(clf12,clf3,how='outer',left_index=True, right_index=True)\n",
    "\n",
    "\n",
    "clf123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-versicolor_x</th>\n",
       "      <th>Iris-virginica_x</th>\n",
       "      <th>Iris-versicolor_y</th>\n",
       "      <th>Iris-setosa_x</th>\n",
       "      <th>Iris-setosa_y</th>\n",
       "      <th>Iris-virginica_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.988528</td>\n",
       "      <td>0.014710</td>\n",
       "      <td>0.985290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.984287</td>\n",
       "      <td>0.017100</td>\n",
       "      <td>0.982900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.988265</td>\n",
       "      <td>0.016283</td>\n",
       "      <td>0.983717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.985851</td>\n",
       "      <td>0.017887</td>\n",
       "      <td>0.982113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.987573</td>\n",
       "      <td>0.014803</td>\n",
       "      <td>0.985197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.006669</td>\n",
       "      <td>0.993331</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>0.014242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.941228</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985482</td>\n",
       "      <td>0.014518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.023150</td>\n",
       "      <td>0.976850</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.985432</td>\n",
       "      <td>0.014568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.953059</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.972237</td>\n",
       "      <td>0.027763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.173943</td>\n",
       "      <td>0.826057</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>0.020840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-versicolor_x  Iris-virginica_x  Iris-versicolor_y  Iris-setosa_x  \\\n",
       "0             0.000000          0.000000           0.011472       0.988528   \n",
       "1             0.000000          0.000000           0.015713       0.984287   \n",
       "2             0.000000          0.000000           0.011735       0.988265   \n",
       "3             0.000000          0.000000           0.014149       0.985851   \n",
       "4             0.000000          0.000000           0.012427       0.987573   \n",
       "..                 ...               ...                ...            ...   \n",
       "145           0.006669          0.993331           0.000000       0.000000   \n",
       "146           0.058772          0.941228           0.000000       0.000000   \n",
       "147           0.023150          0.976850           0.000000       0.000000   \n",
       "148           0.046941          0.953059           0.000000       0.000000   \n",
       "149           0.173943          0.826057           0.000000       0.000000   \n",
       "\n",
       "     Iris-setosa_y  Iris-virginica_y  \n",
       "0         0.014710          0.985290  \n",
       "1         0.017100          0.982900  \n",
       "2         0.016283          0.983717  \n",
       "3         0.017887          0.982113  \n",
       "4         0.014803          0.985197  \n",
       "..             ...               ...  \n",
       "145       0.985758          0.014242  \n",
       "146       0.985482          0.014518  \n",
       "147       0.985432          0.014568  \n",
       "148       0.972237          0.027763  \n",
       "149       0.979160          0.020840  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf123.loc[ pd.isnull(clf123['Iris-versicolor_x'] ),'Iris-versicolor_x']=0\n",
    "clf123.loc[ pd.isnull(clf123['Iris-virginica_x'] ),'Iris-virginica_x']=0\n",
    "clf123.loc[ pd.isnull(clf123['Iris-setosa_x'] ),'Iris-setosa_x']=0\n",
    "clf123.loc[ pd.isnull(clf123['Iris-versicolor_y'] ),'Iris-versicolor_y']=0\n",
    "clf123.loc[ pd.isnull(clf123['Iris-virginica_y'] ),'Iris-virginica_y']=0\n",
    "clf123.loc[ pd.isnull(clf123['Iris-setosa_y'] ),'Iris-setosa_y']=0\n",
    "\n",
    "clf123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "      <th>Iris-setosa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.985290</td>\n",
       "      <td>1.003238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>1.001386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.983717</td>\n",
       "      <td>1.004548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.982113</td>\n",
       "      <td>1.003738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.985197</td>\n",
       "      <td>1.002376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.006669</td>\n",
       "      <td>1.007572</td>\n",
       "      <td>0.985758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.955746</td>\n",
       "      <td>0.985482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.023150</td>\n",
       "      <td>0.991418</td>\n",
       "      <td>0.985432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.980822</td>\n",
       "      <td>0.972237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.173943</td>\n",
       "      <td>0.846897</td>\n",
       "      <td>0.979160</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-versicolor  Iris-virginica  Iris-setosa\n",
       "0           0.011472        0.985290     1.003238\n",
       "1           0.015713        0.982900     1.001386\n",
       "2           0.011735        0.983717     1.004548\n",
       "3           0.014149        0.982113     1.003738\n",
       "4           0.012427        0.985197     1.002376\n",
       "..               ...             ...          ...\n",
       "145         0.006669        1.007572     0.985758\n",
       "146         0.058772        0.955746     0.985482\n",
       "147         0.023150        0.991418     0.985432\n",
       "148         0.046941        0.980822     0.972237\n",
       "149         0.173943        0.846897     0.979160\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf123['Iris-versicolor']=clf123['Iris-versicolor_x']+clf123['Iris-versicolor_y']\n",
    "clf123['Iris-virginica']=clf123['Iris-virginica_x']+clf123['Iris-virginica_y']\n",
    "clf123['Iris-setosa']=clf123['Iris-setosa_x']+clf123['Iris-setosa_y']\n",
    "multiclf=clf123.drop(columns={'Iris-versicolor_x','Iris-versicolor_y','Iris-virginica_x',\n",
    "                              'Iris-virginica_y','Iris-setosa_x','Iris-setosa_y'})\n",
    "\n",
    "\n",
    "multiclf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiclf.loc[ pd.isnull(multiclf['Iris-versicolor'] ),'Iris-versicolor']=0\n",
    "# multiclf.loc[ pd.isnull(multiclf['Iris-virginica'] ),'Iris-virginica']=0\n",
    "# multiclf.loc[ pd.isnull(multiclf['Iris-setosa'] ),'Iris-setosa']=0\n",
    "\n",
    "# multiclf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "multiclf['y_hat']=multiclf.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The multiclassifer results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>y_hat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.011472</td>\n",
       "      <td>0.985290</td>\n",
       "      <td>1.003238</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.015713</td>\n",
       "      <td>0.982900</td>\n",
       "      <td>1.001386</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011735</td>\n",
       "      <td>0.983717</td>\n",
       "      <td>1.004548</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.014149</td>\n",
       "      <td>0.982113</td>\n",
       "      <td>1.003738</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012427</td>\n",
       "      <td>0.985197</td>\n",
       "      <td>1.002376</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.006669</td>\n",
       "      <td>1.007572</td>\n",
       "      <td>0.985758</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.058772</td>\n",
       "      <td>0.955746</td>\n",
       "      <td>0.985482</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.023150</td>\n",
       "      <td>0.991418</td>\n",
       "      <td>0.985432</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.046941</td>\n",
       "      <td>0.980822</td>\n",
       "      <td>0.972237</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.173943</td>\n",
       "      <td>0.846897</td>\n",
       "      <td>0.979160</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-versicolor  Iris-virginica  Iris-setosa           y_hat\n",
       "0           0.011472        0.985290     1.003238     Iris-setosa\n",
       "1           0.015713        0.982900     1.001386     Iris-setosa\n",
       "2           0.011735        0.983717     1.004548     Iris-setosa\n",
       "3           0.014149        0.982113     1.003738     Iris-setosa\n",
       "4           0.012427        0.985197     1.002376     Iris-setosa\n",
       "..               ...             ...          ...             ...\n",
       "145         0.006669        1.007572     0.985758  Iris-virginica\n",
       "146         0.058772        0.955746     0.985482     Iris-setosa\n",
       "147         0.023150        0.991418     0.985432  Iris-virginica\n",
       "148         0.046941        0.980822     0.972237  Iris-virginica\n",
       "149         0.173943        0.846897     0.979160     Iris-setosa\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multiclf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fZe4oSzXFfAh"
   },
   "source": [
    "# Question 5\n",
    "\n",
    "(20 points) Extensively describe the overfitting and\n",
    "underfitting problem. Use execution examples with a decision\n",
    "tree and SVM (with or without kernel). Use the scikit\n",
    "implementations. Show underfitting, good behavior, and overfitting examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: \n",
    "\n",
    "**Overfitting** occurs when a model is too closely aligned to a limited set of data points. As a result, the model is useful in reference only to its initial data set, and not applicable to any other data sets.\n",
    "\n",
    "**Underfitting** occurs when a model is unable to learn much from the training data. Therefore, the results of the application of the model in the training data or any other data sets are both not good.\n",
    "\n",
    "Because iris dataset is too small, I use the titanic data set to show the examples of overfitting, good behavior and underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_comb = df_train\n",
    "X = pd.DataFrame()\n",
    "\n",
    "def encode_sex(x):\n",
    "    return 1 if x == 'female' else 0\n",
    "\n",
    "def family_size(x):\n",
    "    size = x.SibSp + x.Parch \n",
    "    return 4 if size > 3 else size\n",
    "\n",
    "X['Sex'] = df_comb.Sex.map(encode_sex)\n",
    "X['Pclass'] = df_comb.Pclass\n",
    "X['FamilySize'] = df_comb.apply(family_size, axis=1)\n",
    "fare_median = df_train.groupby(['Sex', 'Pclass']).Fare.median()\n",
    "fare_median.name = 'FareMedian'\n",
    "\n",
    "age_mean = df_train.groupby(['Sex', 'Pclass']).Age.mean()\n",
    "age_mean.name = 'AgeMean'\n",
    "\n",
    "def join(df, stat):\n",
    "    return pd.merge(df, stat.to_frame(), left_on=['Sex', 'Pclass'], right_index=True, how='left')\n",
    "\n",
    "X['Fare'] = df_comb.Fare.fillna(join(df_comb, fare_median).FareMedian)\n",
    "X['Age'] = df_comb.Age.fillna(join(df_comb, age_mean).AgeMean)\n",
    "def quantiles(series, num):\n",
    "    return pd.qcut(series, num, retbins=True)[1]\n",
    "\n",
    "def discretize(series, bins):\n",
    "    return pd.cut(series, bins, labels=range(len(bins)-1), include_lowest=True)\n",
    "    \n",
    "X['Fare'] = discretize(X.Fare, quantiles(df_comb.Fare, 10))\n",
    "X['Age'] = discretize(X.Age, quantiles(df_comb.Age, 10))\n",
    "y=df_train.Survived"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The underfitting situation:\n",
      "The accuracy in Training data set is: 0.6067415730337079\n",
      "The accuracy in Testing data set is: 0.6302521008403361\n",
      "The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting\n",
      "The overfitting situation:\n",
      "The accuracy in Training data set is: 0.8857677902621723\n",
      "The accuracy in Testing data set is: 0.8179271708683473\n",
      "The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting\n",
      "The good behavior situation:\n",
      "The accuracy in Training data set is: 0.8295880149812734\n",
      "The accuracy in Testing data set is: 0.7815126050420168\n",
      "The result show that the accuracy in Training data is similar to test data, that means the model is in good behavior\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=424)\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import mean_squared_error,accuracy_score,precision_score,classification_report,confusion_matrix\n",
    "\n",
    "\n",
    "clf=svm.SVC( C=0.00000001)\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat=clf.predict(X_test)\n",
    "X_hat=clf.predict(X_train)\n",
    "print('The underfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting')\n",
    "\n",
    "\n",
    "clf=svm.SVC( C=1000)\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat=clf.predict(X_test)\n",
    "X_hat=clf.predict(X_train)\n",
    "print('The overfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting')\n",
    "\n",
    "\n",
    "clf=svm.SVC( C=1)\n",
    "clf.fit(X_train,y_train)\n",
    "y_hat=clf.predict(X_test)\n",
    "X_hat=clf.predict(X_train)\n",
    "print('The good behavior situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is similar to test data, that means the model is in good behavior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The overfitting situation:\n",
      "The accuracy in Training data set is: 0.9194756554307116\n",
      "The accuracy in Testing data set is: 0.7675070028011205\n",
      "The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting\n",
      "The underfitting situation:\n",
      "The accuracy in Training data set is: 0.7921348314606742\n",
      "The accuracy in Testing data set is: 0.7787114845938375\n",
      "The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting\n",
      "The good behavior situation:\n",
      "The accuracy in Training data set is: 0.8838951310861424\n",
      "The accuracy in Testing data set is: 0.8319327731092437\n",
      "The result show that the accuracy in Training data is similar to test data, that means the model is in good behavior\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "clf1 = DecisionTreeClassifier(random_state=0,max_depth=1000,max_leaf_nodes=1000)\n",
    "clf1.fit(X_train,y_train)\n",
    "y_hat=clf1.predict(X_test)\n",
    "X_hat=clf1.predict(X_train)\n",
    "print('The overfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is much higher than in test data, that means the model is overfitting')\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=0,max_depth=1,max_leaf_nodes=2)\n",
    "clf1.fit(X_train,y_train)\n",
    "y_hat=clf1.predict(X_test)\n",
    "X_hat=clf1.predict(X_train)\n",
    "print('The underfitting situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in both Training data and Testing data are both low, shows the model is underfitting')\n",
    "\n",
    "\n",
    "clf1 = DecisionTreeClassifier(random_state=0,max_depth=10,max_leaf_nodes=25)\n",
    "clf1.fit(X_train,y_train)\n",
    "y_hat=clf1.predict(X_test)\n",
    "X_hat=clf1.predict(X_train)\n",
    "print('The good behavior situation:')\n",
    "print('The accuracy in Training data set is:',accuracy_score(y_train,X_hat))\n",
    "print('The accuracy in Testing data set is:',accuracy_score(y_test,y_hat))\n",
    "print('The result show that the accuracy in Training data is similar to test data, that means the model is in good behavior')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wri4R6v6F52n"
   },
   "source": [
    "# Question 6\n",
    "(10 points) Show examples when the use of\n",
    "kernel procedure is more efficient in terms of training and\n",
    "prediction computational time w.r.t. polynomial features\n",
    "transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time needed for Poly Kernel: 0.007203102111816406\n",
      "Time needed for none Kernel: 0.012806177139282227\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "df_train = pd.read_csv('train.csv')\n",
    "df_comb = df_train\n",
    "X = pd.DataFrame()\n",
    "\n",
    "def encode_sex(x):\n",
    "    return 1 if x == 'female' else 0\n",
    "\n",
    "def family_size(x):\n",
    "    size = x.SibSp + x.Parch \n",
    "    return 4 if size > 3 else size\n",
    "\n",
    "X['Sex'] = df_comb.Sex.map(encode_sex)\n",
    "X['Pclass'] = df_comb.Pclass\n",
    "X['FamilySize'] = df_comb.apply(family_size, axis=1)\n",
    "fare_median = df_train.groupby(['Sex', 'Pclass']).Fare.median()\n",
    "fare_median.name = 'FareMedian'\n",
    "\n",
    "age_mean = df_train.groupby(['Sex', 'Pclass']).Age.mean()\n",
    "age_mean.name = 'AgeMean'\n",
    "\n",
    "def join(df, stat):\n",
    "    return pd.merge(df, stat.to_frame(), left_on=['Sex', 'Pclass'], right_index=True, how='left')\n",
    "\n",
    "X['Fare'] = df_comb.Fare.fillna(join(df_comb, fare_median).FareMedian)\n",
    "X['Age'] = df_comb.Age.fillna(join(df_comb, age_mean).AgeMean)\n",
    "def quantiles(series, num):\n",
    "    return pd.qcut(series, num, retbins=True)[1]\n",
    "\n",
    "def discretize(series, bins):\n",
    "    return pd.cut(series, bins, labels=range(len(bins)-1), include_lowest=True)\n",
    "    \n",
    "X['Fare'] = discretize(X.Fare, quantiles(df_comb.Fare, 10))\n",
    "X['Age'] = discretize(X.Age, quantiles(df_comb.Age, 10))\n",
    "y=df_train.Survived\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=424)\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)\n",
    "\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "clf1=svm.SVC(kernel='poly')\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)\n",
    "end = time.time()\n",
    "print('Time needed for Poly Kernel:',end-start)\n",
    "\n",
    "# start = time.time()\n",
    "# clf1=svm.SVC(kernel='rbf')\n",
    "# clf1.fit(X_train,y_train)\n",
    "# clf1.predict(X_test)\n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "\n",
    "# start = time.time()\n",
    "# clf1=svm.SVC(kernel='linear')\n",
    "# clf1.fit(X_train,y_train)\n",
    "# clf1.predict(X_test)\n",
    "# end = time.time()\n",
    "# print(end-start)\n",
    "\n",
    "start = time.time()\n",
    "clf1=svm.SVC()\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)\n",
    "end = time.time()\n",
    "print('Time needed for none Kernel:',end-start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It shows that the use of kernel procedure is more efficient in terms of training and prediction computational time w.r.t. polynomial features transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2OtA1JWGGL9C"
   },
   "source": [
    "# Question 7\n",
    "\n",
    "(10 points) Write a procedure to estimate in the SVC\n",
    "classifier (in Scikit) the best kernel (RBF, Polynomial,\n",
    "sigmoid), the best gamma & degree, and the best C. Use the\n",
    "grid search without implement it. Use the following\n",
    "reference:\n",
    "\n",
    "    a. https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "    \n",
    "    b. https://scikit-learn.org/stable/modules/grid_search.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(),\n",
       "             param_grid={'C': [0.1, 1, 10, 100], 'degree': [1, 5, 10],\n",
       "                         'gamma': ('scale', 'auto'),\n",
       "                         'kernel': ('rbf', 'poly', 'sigmoid')})"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "iris = datasets.load_iris()\n",
    "parameters = {'kernel':( 'rbf','poly','sigmoid'), \n",
    "              'C':[0.1,1,10,100],\n",
    "              'gamma':('scale', 'auto'),\n",
    "              'degree':[1,5,10]}\n",
    "svc = svm.SVC()\n",
    "clf = GridSearchCV(svc, parameters)\n",
    "clf.fit(iris.data, iris.target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'degree': 1, 'gamma': 'scale', 'kernel': 'poly'}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sorted(clf.cv_results_.keys())\n",
    "clf.best_params_\n",
    "#help(svm.SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WLFt2gbhGXqD"
   },
   "source": [
    " # Question 8\n",
    " (20 points) Create examples to explain the property and the\n",
    "importance of the following kernels:\n",
    "    \n",
    "    a. https://en.wikipedia.org/wiki/Graph_kernel\n",
    "    \n",
    "    b. https://en.wikipedia.org/wiki/String_kernel\n",
    "\n",
    "    c. https://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.sigmoid_kernel.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Kernel\n",
    "\n",
    "A graph kernel is a kernel function that computes the inner function of graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String_kernel\n",
    "\n",
    "A string kernel is a kernel function that operates on strings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sigmoid_kernel\n",
    "\n",
    " The sigmoid kernel is also known as hyperbolic tangent, or Multilayer Perceptron, Because it always be used as an activation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0,\n",
       "       1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#X_train and y_train are from titanic dataset.\n",
    "clf1=svm.SVC(kernel='sigmoid')\n",
    "clf1.fit(X_train,y_train)\n",
    "clf1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "MidtermExam.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
