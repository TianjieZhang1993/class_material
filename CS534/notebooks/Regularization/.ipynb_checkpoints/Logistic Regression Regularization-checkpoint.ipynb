{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zLmd0j9dIftw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wv_DdxE3Ift1"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "X = X[y != 2]\n",
    "y = y[y != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4WsMQ0_Ift3",
    "outputId": "190cd5eb-ba92-4451-f5ef-53b414f05568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tvKW7sGiIft8"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5DPMmua5Ift_"
   },
   "outputs": [],
   "source": [
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mvZljPiYIfuC"
   },
   "outputs": [],
   "source": [
    "C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "# for c in C:\n",
    "#     clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     print('C:', c)\n",
    "#     print('Coefficient of each feature:', clf.coef_)\n",
    "#     print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "#     print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ciz-uxpPIfuH",
    "outputId": "31ff1733-072e-4e00-bc40-a3848902ae1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10000\n",
      "Coefficient of each feature: [[ 0.55502491 -0.48981406  2.69903546  0.70321633]]\n",
      "Training accuracy: 0.8714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 0.55384679 -0.48759777  2.68485237  0.70178913]]\n",
      "Training accuracy: 0.8714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 0.54380705 -0.46976786  2.56896349  0.68985965]]\n",
      "Training accuracy: 0.8714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[ 0.48214694 -0.37957613  1.96237454  0.61116034]]\n",
      "Training accuracy: 0.8857142857142857\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.30573504 -0.21960351  0.89593801  0.37313452]]\n",
      "Training accuracy: 0.9142857142857143\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.01175693 -0.00820143  0.02388473  0.01262396]]\n",
      "Training accuracy: 0.8857142857142857\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_cFSOnYbIfuK",
    "outputId": "536a3ad8-53f3-45a3-98fc-adcf8a69d563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMAWYxt4IfuN"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "X1 = np.random.normal(size=X.shape)\n",
    "X =np.hstack([X,X1])\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiL__BUPIfuP",
    "outputId": "78ae60b3-f08d-4708-81ea-cdd107ddf16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_un9emQBIfuS"
   },
   "outputs": [],
   "source": [
    "# C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "# for c in C:\n",
    "#     clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     print('C:', c)\n",
    "#     print('Coefficient of each feature:', clf.coef_)\n",
    "#     print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "#     print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kIZC7ttXIfuU",
    "outputId": "79711d1b-7f43-4c57-89c5-03f1e25ae003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1000\n",
      "Coefficient of each feature: [[-1.30722805 -3.75559727  6.1966111   3.01272284 -0.65322395 -0.55799615\n",
      "  -0.57285695 -0.1407535 ]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[-0.97727054 -2.84003724  4.65073415  2.26949282 -0.42440235 -0.31548629\n",
      "  -0.38334073 -0.09280937]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[-0.66265862 -2.03749546  3.26953162  1.53213584 -0.25282062 -0.16305184\n",
      "  -0.21980281 -0.04405374]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[-0.40625545 -1.2969303   2.06047425  0.92737682 -0.14512082 -0.0764008\n",
      "  -0.1058232  -0.01688487]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[-0.19323156 -0.64477479  1.02598325  0.44878706 -0.08107463 -0.03487832\n",
      "  -0.03934422 -0.00495642]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.00411183 -0.01670781  0.0417255   0.01710848 -0.00468201 -0.00143924\n",
      "  -0.00096736 -0.0001392 ]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [1000,100,10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6DcwzTQuIfuX"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "X1 = np.random.normal(size=X.shape)\n",
    "n=1\n",
    "X =X+n*X1\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Fd01836IfuZ",
    "outputId": "78b4f507-e557-4401-a87f-034a24e4e4ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10000\n",
      "Coefficient of each feature: [[ 0.47574394 -0.40789315  1.66454995  0.66520944]]\n",
      "Training accuracy: 0.5142857142857142\n",
      "Test accuracy: 0.5\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 0.46583733 -0.41015713  1.65722297  0.66518759]]\n",
      "Training accuracy: 0.5142857142857142\n",
      "Test accuracy: 0.5\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 0.37565016 -0.4328443   1.59519703  0.66623225]]\n",
      "Training accuracy: 0.5142857142857142\n",
      "Test accuracy: 0.5\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[-0.02342386 -0.60808065  1.2426675   0.61497865]]\n",
      "Training accuracy: 0.6714285714285714\n",
      "Test accuracy: 0.6666666666666666\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.         -0.34494962  0.49001891  0.        ]]\n",
      "Training accuracy: 0.7857142857142857\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[0. 0. 0. 0.]]\n",
      "Training accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "569nPu-wIfub",
    "outputId": "0ccdbcb3-7a83-4666-fa36-b4f5e344e765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10000\n",
      "Coefficient of each feature: [[ 0.55502491 -0.48981406  2.69903546  0.70321633]]\n",
      "Training accuracy: 0.8714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 0.55384679 -0.48759777  2.68485237  0.70178913]]\n",
      "Training accuracy: 0.8714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 0.54380705 -0.46976786  2.56896349  0.68985965]]\n",
      "Training accuracy: 0.8714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[ 0.48214694 -0.37957613  1.96237454  0.61116034]]\n",
      "Training accuracy: 0.8857142857142857\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.30573504 -0.21960351  0.89593801  0.37313452]]\n",
      "Training accuracy: 0.9142857142857143\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.01175693 -0.00820143  0.02388473  0.01262396]]\n",
      "Training accuracy: 0.8857142857142857\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BOHEya1fIfue"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a94DsgelIfuh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Logistic Regression Regularization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
