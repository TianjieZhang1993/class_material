{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zLmd0j9dIftw"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "wv_DdxE3Ift1"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "#print(iris)\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "X = X[y != 2]\n",
    "y = y[y != 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4WsMQ0_Ift3",
    "outputId": "190cd5eb-ba92-4451-f5ef-53b414f05568"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.1, 3.5, 1.4, 0.2],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [4.6, 3.4, 1.4, 0.3],\n",
       "       [5. , 3.4, 1.5, 0.2],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.8, 3.4, 1.6, 0.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.7, 4.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [5.1, 3.8, 1.5, 0.3],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.1, 3.3, 1.7, 0.5],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3. , 1.6, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.2, 4.1, 1.5, 0.1],\n",
       "       [5.5, 4.2, 1.4, 0.2],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [4.4, 3. , 1.3, 0.2],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.1, 3.8, 1.9, 0.4],\n",
       "       [4.8, 3. , 1.4, 0.3],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [7. , 3.2, 4.7, 1.4],\n",
       "       [6.4, 3.2, 4.5, 1.5],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [5.5, 2.3, 4. , 1.3],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.7, 2.8, 4.5, 1.3],\n",
       "       [6.3, 3.3, 4.7, 1.6],\n",
       "       [4.9, 2.4, 3.3, 1. ],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [5.2, 2.7, 3.9, 1.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [6.1, 2.8, 4.7, 1.2],\n",
       "       [6.4, 2.9, 4.3, 1.3],\n",
       "       [6.6, 3. , 4.4, 1.4],\n",
       "       [6.8, 2.8, 4.8, 1.4],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.7, 2.6, 3.5, 1. ],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [6. , 2.7, 5.1, 1.6],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [6.7, 3.1, 4.7, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.6, 3. , 4.1, 1.3],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.1, 3. , 4.6, 1.4],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5. , 2.3, 3.3, 1. ],\n",
       "       [5.6, 2.7, 4.2, 1.3],\n",
       "       [5.7, 3. , 4.2, 1.2],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6.2, 2.9, 4.3, 1.3],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [6.3, 3.3, 6. , 2.5],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [7.1, 3. , 5.9, 2.1],\n",
       "       [6.3, 2.9, 5.6, 1.8],\n",
       "       [6.5, 3. , 5.8, 2.2],\n",
       "       [7.6, 3. , 6.6, 2.1],\n",
       "       [4.9, 2.5, 4.5, 1.7],\n",
       "       [7.3, 2.9, 6.3, 1.8],\n",
       "       [6.7, 2.5, 5.8, 1.8],\n",
       "       [7.2, 3.6, 6.1, 2.5],\n",
       "       [6.5, 3.2, 5.1, 2. ],\n",
       "       [6.4, 2.7, 5.3, 1.9],\n",
       "       [6.8, 3. , 5.5, 2.1],\n",
       "       [5.7, 2.5, 5. , 2. ],\n",
       "       [5.8, 2.8, 5.1, 2.4],\n",
       "       [6.4, 3.2, 5.3, 2.3],\n",
       "       [6.5, 3. , 5.5, 1.8],\n",
       "       [7.7, 3.8, 6.7, 2.2],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.2, 5. , 1.5],\n",
       "       [6.9, 3.2, 5.7, 2.3],\n",
       "       [5.6, 2.8, 4.9, 2. ],\n",
       "       [7.7, 2.8, 6.7, 2. ],\n",
       "       [6.3, 2.7, 4.9, 1.8],\n",
       "       [6.7, 3.3, 5.7, 2.1],\n",
       "       [7.2, 3.2, 6. , 1.8],\n",
       "       [6.2, 2.8, 4.8, 1.8],\n",
       "       [6.1, 3. , 4.9, 1.8],\n",
       "       [6.4, 2.8, 5.6, 2.1],\n",
       "       [7.2, 3. , 5.8, 1.6],\n",
       "       [7.4, 2.8, 6.1, 1.9],\n",
       "       [7.9, 3.8, 6.4, 2. ],\n",
       "       [6.4, 2.8, 5.6, 2.2],\n",
       "       [6.3, 2.8, 5.1, 1.5],\n",
       "       [6.1, 2.6, 5.6, 1.4],\n",
       "       [7.7, 3. , 6.1, 2.3],\n",
       "       [6.3, 3.4, 5.6, 2.4],\n",
       "       [6.4, 3.1, 5.5, 1.8],\n",
       "       [6. , 3. , 4.8, 1.8],\n",
       "       [6.9, 3.1, 5.4, 2.1],\n",
       "       [6.7, 3.1, 5.6, 2.4],\n",
       "       [6.9, 3.1, 5.1, 2.3],\n",
       "       [5.8, 2.7, 5.1, 1.9],\n",
       "       [6.8, 3.2, 5.9, 2.3],\n",
       "       [6.7, 3.3, 5.7, 2.5],\n",
       "       [6.7, 3. , 5.2, 2.3],\n",
       "       [6.3, 2.5, 5. , 1.9],\n",
       "       [6.5, 3. , 5.2, 2. ],\n",
       "       [6.2, 3.4, 5.4, 2.3],\n",
       "       [5.9, 3. , 5.1, 1.8]])"
      ]
     },
     "execution_count": 20,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "tvKW7sGiIft8"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "5DPMmua5Ift_"
   },
   "outputs": [],
   "source": [
    "## preprocessing\n",
    "\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mvZljPiYIfuC"
   },
   "outputs": [],
   "source": [
    "C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "# for c in C:\n",
    "#     clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     print('C:', c)\n",
    "#     print('Coefficient of each feature:', clf.coef_)\n",
    "#     print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "#     print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Ciz-uxpPIfuH",
    "outputId": "31ff1733-072e-4e00-bc40-a3848902ae1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10000\n",
      "Coefficient of each feature: [[ 2.20695693 -3.47227876  5.11028695  5.30464006]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 1.29058946 -2.21037347  3.31440318  3.44408982]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 0.99714141 -1.65133484  2.296325    2.35666557]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[ 0.7090579  -1.08180421  1.43716459  1.45693216]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.42776865 -0.54933564  0.73734059  0.73824632]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.02283103 -0.02258008  0.03220453  0.03193855]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for c in C:\n",
    "    '''\n",
    "    We can see that large values of C give more freedom to the model. \n",
    "    Conversely, smaller values of C constrain the model more.\n",
    "    In the L1 penalty case, this leads to sparser solutions. \n",
    "    As expected, the Elastic-Net penalty sparsity is between that of L1 and L2.\n",
    "    '''\n",
    "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "_cFSOnYbIfuK",
    "outputId": "536a3ad8-53f3-45a3-98fc-adcf8a69d563"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 4)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "QMAWYxt4IfuN"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "X1 = np.random.normal(size=X.shape)\n",
    "X =np.hstack([X,X1])\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_std = sc.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "CiL__BUPIfuP",
    "outputId": "78ae60b3-f08d-4708-81ea-cdd107ddf16e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_un9emQBIfuS"
   },
   "outputs": [],
   "source": [
    "# C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "# for c in C:\n",
    "#     clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     print('C:', c)\n",
    "#     print('Coefficient of each feature:', clf.coef_)\n",
    "#     print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "#     print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "#     print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kIZC7ttXIfuU",
    "outputId": "79711d1b-7f43-4c57-89c5-03f1e25ae003"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 1000\n",
      "Coefficient of each feature: [[ 1.51065041 -3.140253    4.15663236  4.39712612  0.01678185  0.49796006\n",
      "   0.32843527 -0.90568536]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 1.22897194e+00 -2.38969754e+00  3.13954125e+00  3.30931590e+00\n",
      "  -1.02636048e-03  3.22062176e-01  2.94456760e-01 -6.00778385e-01]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 0.97275767 -1.70461343  2.21173264  2.30588152 -0.01305075  0.19831244\n",
      "   0.21854533 -0.34900815]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[ 0.70648993 -1.0865485   1.4121873   1.44517981 -0.0214021   0.12470613\n",
      "   0.13757168 -0.17447545]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.42812689 -0.54788787  0.73270408  0.73602396 -0.02591789  0.06702808\n",
      "   0.06475566 -0.05653826]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.02282016 -0.02257582  0.0321917   0.03192888 -0.00305418  0.00309039\n",
      "   0.0021257   0.00033094]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 1.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [1000,100,10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6DcwzTQuIfuX"
   },
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data\n",
    "y = iris.target \n",
    "X1 = np.random.normal(size=X.shape)\n",
    "n=1\n",
    "X =X+n*X1\n",
    "X = X[y != 2]\n",
    "y = y[y != 2]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
    "# Create a scaler object\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the training data and transform\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "\n",
    "# Apply the scaler to the test data\n",
    "X_test_std = sc.transform(X_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_Fd01836IfuZ",
    "outputId": "78b4f507-e557-4401-a87f-034a24e4e4ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10000\n",
      "Coefficient of each feature: [[12.93085061 -1.08566668 70.04917917 15.55244031]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 7.00928409 -0.47304794 37.11800828  8.61682046]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 2.84225513 -0.02011308 14.34491059  3.74648403]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[0.89460367 0.         4.57025002 0.82920505]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[0.         0.         1.45116642 0.        ]]\n",
      "Training accuracy: 0.9428571428571428\n",
      "Test accuracy: 0.8666666666666667\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[0. 0. 0. 0.]]\n",
      "Training accuracy: 0.5\n",
      "Test accuracy: 0.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "569nPu-wIfub",
    "outputId": "0ccdbcb3-7a83-4666-fa36-b4f5e344e765"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 10000\n",
      "Coefficient of each feature: [[ 9.03110662 -0.74751849 47.64320293 10.84977804]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 100\n",
      "Coefficient of each feature: [[ 2.85568516 -0.14864628 13.80068959  3.72780042]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 10\n",
      "Coefficient of each feature: [[ 1.51385661 -0.30136251  6.1201527   1.53085493]]\n",
      "Training accuracy: 1.0\n",
      "Test accuracy: 0.9\n",
      "\n",
      "C: 1\n",
      "Coefficient of each feature: [[ 0.85193297 -0.37406315  2.80461675  0.73466769]]\n",
      "Training accuracy: 0.9714285714285714\n",
      "Test accuracy: 0.9333333333333333\n",
      "\n",
      "C: 0.1\n",
      "Coefficient of each feature: [[ 0.40972106 -0.30210933  1.07989549  0.32899546]]\n",
      "Training accuracy: 0.9714285714285714\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n",
      "C: 0.001\n",
      "Coefficient of each feature: [[ 0.01291153 -0.01179913  0.02905101  0.01057185]]\n",
      "Training accuracy: 0.9428571428571428\n",
      "Test accuracy: 0.9666666666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "C = [10000,100,10, 1, .1, .001]\n",
    "\n",
    "for c in C:\n",
    "    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    print('C:', c)\n",
    "    print('Coefficient of each feature:', clf.coef_)\n",
    "    print('Training accuracy:', clf.score(X_train_std, y_train))\n",
    "    print('Test accuracy:', clf.score(X_test_std, y_test))\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOHEya1fIfue"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "a94DsgelIfuh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qebqtNJv5PH_"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Logistic Regression Regularization.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
