{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Logistic Regression Regularization.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"}},"cells":[{"cell_type":"code","metadata":{"id":"zLmd0j9dIftw"},"source":["import numpy as np\n","from sklearn.linear_model import LogisticRegression\n","from sklearn import datasets\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import StandardScaler"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wv_DdxE3Ift1"},"source":["iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target \n","X = X[y != 2]\n","y = y[y != 2]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"h4WsMQ0_Ift3","outputId":"190cd5eb-ba92-4451-f5ef-53b414f05568"},"source":["iris.data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[5.1, 3.5, 1.4, 0.2],\n","       [4.9, 3. , 1.4, 0.2],\n","       [4.7, 3.2, 1.3, 0.2],\n","       [4.6, 3.1, 1.5, 0.2],\n","       [5. , 3.6, 1.4, 0.2],\n","       [5.4, 3.9, 1.7, 0.4],\n","       [4.6, 3.4, 1.4, 0.3],\n","       [5. , 3.4, 1.5, 0.2],\n","       [4.4, 2.9, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.1],\n","       [5.4, 3.7, 1.5, 0.2],\n","       [4.8, 3.4, 1.6, 0.2],\n","       [4.8, 3. , 1.4, 0.1],\n","       [4.3, 3. , 1.1, 0.1],\n","       [5.8, 4. , 1.2, 0.2],\n","       [5.7, 4.4, 1.5, 0.4],\n","       [5.4, 3.9, 1.3, 0.4],\n","       [5.1, 3.5, 1.4, 0.3],\n","       [5.7, 3.8, 1.7, 0.3],\n","       [5.1, 3.8, 1.5, 0.3],\n","       [5.4, 3.4, 1.7, 0.2],\n","       [5.1, 3.7, 1.5, 0.4],\n","       [4.6, 3.6, 1. , 0.2],\n","       [5.1, 3.3, 1.7, 0.5],\n","       [4.8, 3.4, 1.9, 0.2],\n","       [5. , 3. , 1.6, 0.2],\n","       [5. , 3.4, 1.6, 0.4],\n","       [5.2, 3.5, 1.5, 0.2],\n","       [5.2, 3.4, 1.4, 0.2],\n","       [4.7, 3.2, 1.6, 0.2],\n","       [4.8, 3.1, 1.6, 0.2],\n","       [5.4, 3.4, 1.5, 0.4],\n","       [5.2, 4.1, 1.5, 0.1],\n","       [5.5, 4.2, 1.4, 0.2],\n","       [4.9, 3.1, 1.5, 0.2],\n","       [5. , 3.2, 1.2, 0.2],\n","       [5.5, 3.5, 1.3, 0.2],\n","       [4.9, 3.6, 1.4, 0.1],\n","       [4.4, 3. , 1.3, 0.2],\n","       [5.1, 3.4, 1.5, 0.2],\n","       [5. , 3.5, 1.3, 0.3],\n","       [4.5, 2.3, 1.3, 0.3],\n","       [4.4, 3.2, 1.3, 0.2],\n","       [5. , 3.5, 1.6, 0.6],\n","       [5.1, 3.8, 1.9, 0.4],\n","       [4.8, 3. , 1.4, 0.3],\n","       [5.1, 3.8, 1.6, 0.2],\n","       [4.6, 3.2, 1.4, 0.2],\n","       [5.3, 3.7, 1.5, 0.2],\n","       [5. , 3.3, 1.4, 0.2],\n","       [7. , 3.2, 4.7, 1.4],\n","       [6.4, 3.2, 4.5, 1.5],\n","       [6.9, 3.1, 4.9, 1.5],\n","       [5.5, 2.3, 4. , 1.3],\n","       [6.5, 2.8, 4.6, 1.5],\n","       [5.7, 2.8, 4.5, 1.3],\n","       [6.3, 3.3, 4.7, 1.6],\n","       [4.9, 2.4, 3.3, 1. ],\n","       [6.6, 2.9, 4.6, 1.3],\n","       [5.2, 2.7, 3.9, 1.4],\n","       [5. , 2. , 3.5, 1. ],\n","       [5.9, 3. , 4.2, 1.5],\n","       [6. , 2.2, 4. , 1. ],\n","       [6.1, 2.9, 4.7, 1.4],\n","       [5.6, 2.9, 3.6, 1.3],\n","       [6.7, 3.1, 4.4, 1.4],\n","       [5.6, 3. , 4.5, 1.5],\n","       [5.8, 2.7, 4.1, 1. ],\n","       [6.2, 2.2, 4.5, 1.5],\n","       [5.6, 2.5, 3.9, 1.1],\n","       [5.9, 3.2, 4.8, 1.8],\n","       [6.1, 2.8, 4. , 1.3],\n","       [6.3, 2.5, 4.9, 1.5],\n","       [6.1, 2.8, 4.7, 1.2],\n","       [6.4, 2.9, 4.3, 1.3],\n","       [6.6, 3. , 4.4, 1.4],\n","       [6.8, 2.8, 4.8, 1.4],\n","       [6.7, 3. , 5. , 1.7],\n","       [6. , 2.9, 4.5, 1.5],\n","       [5.7, 2.6, 3.5, 1. ],\n","       [5.5, 2.4, 3.8, 1.1],\n","       [5.5, 2.4, 3.7, 1. ],\n","       [5.8, 2.7, 3.9, 1.2],\n","       [6. , 2.7, 5.1, 1.6],\n","       [5.4, 3. , 4.5, 1.5],\n","       [6. , 3.4, 4.5, 1.6],\n","       [6.7, 3.1, 4.7, 1.5],\n","       [6.3, 2.3, 4.4, 1.3],\n","       [5.6, 3. , 4.1, 1.3],\n","       [5.5, 2.5, 4. , 1.3],\n","       [5.5, 2.6, 4.4, 1.2],\n","       [6.1, 3. , 4.6, 1.4],\n","       [5.8, 2.6, 4. , 1.2],\n","       [5. , 2.3, 3.3, 1. ],\n","       [5.6, 2.7, 4.2, 1.3],\n","       [5.7, 3. , 4.2, 1.2],\n","       [5.7, 2.9, 4.2, 1.3],\n","       [6.2, 2.9, 4.3, 1.3],\n","       [5.1, 2.5, 3. , 1.1],\n","       [5.7, 2.8, 4.1, 1.3],\n","       [6.3, 3.3, 6. , 2.5],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [7.1, 3. , 5.9, 2.1],\n","       [6.3, 2.9, 5.6, 1.8],\n","       [6.5, 3. , 5.8, 2.2],\n","       [7.6, 3. , 6.6, 2.1],\n","       [4.9, 2.5, 4.5, 1.7],\n","       [7.3, 2.9, 6.3, 1.8],\n","       [6.7, 2.5, 5.8, 1.8],\n","       [7.2, 3.6, 6.1, 2.5],\n","       [6.5, 3.2, 5.1, 2. ],\n","       [6.4, 2.7, 5.3, 1.9],\n","       [6.8, 3. , 5.5, 2.1],\n","       [5.7, 2.5, 5. , 2. ],\n","       [5.8, 2.8, 5.1, 2.4],\n","       [6.4, 3.2, 5.3, 2.3],\n","       [6.5, 3. , 5.5, 1.8],\n","       [7.7, 3.8, 6.7, 2.2],\n","       [7.7, 2.6, 6.9, 2.3],\n","       [6. , 2.2, 5. , 1.5],\n","       [6.9, 3.2, 5.7, 2.3],\n","       [5.6, 2.8, 4.9, 2. ],\n","       [7.7, 2.8, 6.7, 2. ],\n","       [6.3, 2.7, 4.9, 1.8],\n","       [6.7, 3.3, 5.7, 2.1],\n","       [7.2, 3.2, 6. , 1.8],\n","       [6.2, 2.8, 4.8, 1.8],\n","       [6.1, 3. , 4.9, 1.8],\n","       [6.4, 2.8, 5.6, 2.1],\n","       [7.2, 3. , 5.8, 1.6],\n","       [7.4, 2.8, 6.1, 1.9],\n","       [7.9, 3.8, 6.4, 2. ],\n","       [6.4, 2.8, 5.6, 2.2],\n","       [6.3, 2.8, 5.1, 1.5],\n","       [6.1, 2.6, 5.6, 1.4],\n","       [7.7, 3. , 6.1, 2.3],\n","       [6.3, 3.4, 5.6, 2.4],\n","       [6.4, 3.1, 5.5, 1.8],\n","       [6. , 3. , 4.8, 1.8],\n","       [6.9, 3.1, 5.4, 2.1],\n","       [6.7, 3.1, 5.6, 2.4],\n","       [6.9, 3.1, 5.1, 2.3],\n","       [5.8, 2.7, 5.1, 1.9],\n","       [6.8, 3.2, 5.9, 2.3],\n","       [6.7, 3.3, 5.7, 2.5],\n","       [6.7, 3. , 5.2, 2.3],\n","       [6.3, 2.5, 5. , 1.9],\n","       [6.5, 3. , 5.2, 2. ],\n","       [6.2, 3.4, 5.4, 2.3],\n","       [5.9, 3. , 5.1, 1.8]])"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"tvKW7sGiIft8"},"source":["X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5DPMmua5Ift_"},"source":["# Create a scaler object\n","sc = StandardScaler()\n","\n","# Fit the scaler to the training data and transform\n","X_train_std = sc.fit_transform(X_train)\n","\n","# Apply the scaler to the test data\n","X_test_std = sc.transform(X_test)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mvZljPiYIfuC"},"source":["C = [10000,100,10, 1, .1, .001]\n","\n","# for c in C:\n","#     clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n","#     clf.fit(X_train, y_train)\n","#     print('C:', c)\n","#     print('Coefficient of each feature:', clf.coef_)\n","#     print('Training accuracy:', clf.score(X_train_std, y_train))\n","#     print('Test accuracy:', clf.score(X_test_std, y_test))\n","#     print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ciz-uxpPIfuH","outputId":"31ff1733-072e-4e00-bc40-a3848902ae1d"},"source":["for c in C:\n","    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n","    clf.fit(X_train_std, y_train)\n","    print('C:', c)\n","    print('Coefficient of each feature:', clf.coef_)\n","    print('Training accuracy:', clf.score(X_train_std, y_train))\n","    print('Test accuracy:', clf.score(X_test_std, y_test))\n","    print('')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C: 10000\n","Coefficient of each feature: [[ 2.20695693 -3.47227876  5.11028695  5.30464006]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 100\n","Coefficient of each feature: [[ 1.29058946 -2.21037347  3.31440318  3.44408982]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 10\n","Coefficient of each feature: [[ 0.99714141 -1.65133484  2.296325    2.35666557]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 1\n","Coefficient of each feature: [[ 0.7090579  -1.08180421  1.43716459  1.45693216]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 0.1\n","Coefficient of each feature: [[ 0.42776865 -0.54933564  0.73734059  0.73824632]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 0.001\n","Coefficient of each feature: [[ 0.02283103 -0.02258008  0.03220453  0.03193855]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_cFSOnYbIfuK","outputId":"536a3ad8-53f3-45a3-98fc-adcf8a69d563"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 4)"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"QMAWYxt4IfuN"},"source":["iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target \n","X1 = np.random.normal(size=X.shape)\n","X =np.hstack([X,X1])\n","X = X[y != 2]\n","y = y[y != 2]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n","# Create a scaler object\n","sc = StandardScaler()\n","\n","# Fit the scaler to the training data and transform\n","X_train_std = sc.fit_transform(X_train)\n","\n","# Apply the scaler to the test data\n","X_test_std = sc.transform(X_test)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"CiL__BUPIfuP","outputId":"78ae60b3-f08d-4708-81ea-cdd107ddf16e"},"source":["X.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(100, 8)"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"_un9emQBIfuS"},"source":["# C = [10000,100,10, 1, .1, .001]\n","\n","# for c in C:\n","#     clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n","#     clf.fit(X_train, y_train)\n","#     print('C:', c)\n","#     print('Coefficient of each feature:', clf.coef_)\n","#     print('Training accuracy:', clf.score(X_train_std, y_train))\n","#     print('Test accuracy:', clf.score(X_test_std, y_test))\n","#     print('')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kIZC7ttXIfuU","outputId":"79711d1b-7f43-4c57-89c5-03f1e25ae003"},"source":["C = [1000,100,10, 1, .1, .001]\n","\n","for c in C:\n","    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n","    clf.fit(X_train_std, y_train)\n","    print('C:', c)\n","    print('Coefficient of each feature:', clf.coef_)\n","    print('Training accuracy:', clf.score(X_train_std, y_train))\n","    print('Test accuracy:', clf.score(X_test_std, y_test))\n","    print('')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C: 1000\n","Coefficient of each feature: [[ 1.51065041 -3.140253    4.15663236  4.39712612  0.01678185  0.49796006\n","   0.32843527 -0.90568536]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 100\n","Coefficient of each feature: [[ 1.22897194e+00 -2.38969754e+00  3.13954125e+00  3.30931590e+00\n","  -1.02636048e-03  3.22062176e-01  2.94456760e-01 -6.00778385e-01]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 10\n","Coefficient of each feature: [[ 0.97275767 -1.70461343  2.21173264  2.30588152 -0.01305075  0.19831244\n","   0.21854533 -0.34900815]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 1\n","Coefficient of each feature: [[ 0.70648993 -1.0865485   1.4121873   1.44517981 -0.0214021   0.12470613\n","   0.13757168 -0.17447545]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 0.1\n","Coefficient of each feature: [[ 0.42812689 -0.54788787  0.73270408  0.73602396 -0.02591789  0.06702808\n","   0.06475566 -0.05653826]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n","C: 0.001\n","Coefficient of each feature: [[ 0.02282016 -0.02257582  0.0321917   0.03192888 -0.00305418  0.00309039\n","   0.0021257   0.00033094]]\n","Training accuracy: 1.0\n","Test accuracy: 1.0\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6DcwzTQuIfuX"},"source":["iris = datasets.load_iris()\n","X = iris.data\n","y = iris.target \n","X1 = np.random.normal(size=X.shape)\n","n=1\n","X =X+n*X1\n","X = X[y != 2]\n","y = y[y != 2]\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n","# Create a scaler object\n","sc = StandardScaler()\n","\n","# Fit the scaler to the training data and transform\n","X_train_std = sc.fit_transform(X_train)\n","\n","# Apply the scaler to the test data\n","X_test_std = sc.transform(X_test)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_Fd01836IfuZ","outputId":"78b4f507-e557-4401-a87f-034a24e4e4ac"},"source":["C = [10000,100,10, 1, .1, .001]\n","\n","for c in C:\n","    clf = LogisticRegression(penalty='l1', C=c, solver='liblinear')\n","    clf.fit(X_train_std, y_train)\n","    print('C:', c)\n","    print('Coefficient of each feature:', clf.coef_)\n","    print('Training accuracy:', clf.score(X_train_std, y_train))\n","    print('Test accuracy:', clf.score(X_test_std, y_test))\n","    print('')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C: 10000\n","Coefficient of each feature: [[12.93085061 -1.08566668 70.04917917 15.55244031]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 100\n","Coefficient of each feature: [[ 7.00928409 -0.47304794 37.11800828  8.61682046]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 10\n","Coefficient of each feature: [[ 2.84225513 -0.02011308 14.34491059  3.74648403]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 1\n","Coefficient of each feature: [[0.89460367 0.         4.57025002 0.82920505]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 0.1\n","Coefficient of each feature: [[0.         0.         1.45116642 0.        ]]\n","Training accuracy: 0.9428571428571428\n","Test accuracy: 0.8666666666666667\n","\n","C: 0.001\n","Coefficient of each feature: [[0. 0. 0. 0.]]\n","Training accuracy: 0.5\n","Test accuracy: 0.5\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"569nPu-wIfub","outputId":"0ccdbcb3-7a83-4666-fa36-b4f5e344e765"},"source":["C = [10000,100,10, 1, .1, .001]\n","\n","for c in C:\n","    clf = LogisticRegression(penalty='l2', C=c, solver='liblinear')\n","    clf.fit(X_train_std, y_train)\n","    print('C:', c)\n","    print('Coefficient of each feature:', clf.coef_)\n","    print('Training accuracy:', clf.score(X_train_std, y_train))\n","    print('Test accuracy:', clf.score(X_test_std, y_test))\n","    print('')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["C: 10000\n","Coefficient of each feature: [[ 9.03110662 -0.74751849 47.64320293 10.84977804]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 100\n","Coefficient of each feature: [[ 2.85568516 -0.14864628 13.80068959  3.72780042]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 10\n","Coefficient of each feature: [[ 1.51385661 -0.30136251  6.1201527   1.53085493]]\n","Training accuracy: 1.0\n","Test accuracy: 0.9\n","\n","C: 1\n","Coefficient of each feature: [[ 0.85193297 -0.37406315  2.80461675  0.73466769]]\n","Training accuracy: 0.9714285714285714\n","Test accuracy: 0.9333333333333333\n","\n","C: 0.1\n","Coefficient of each feature: [[ 0.40972106 -0.30210933  1.07989549  0.32899546]]\n","Training accuracy: 0.9714285714285714\n","Test accuracy: 0.9666666666666667\n","\n","C: 0.001\n","Coefficient of each feature: [[ 0.01291153 -0.01179913  0.02905101  0.01057185]]\n","Training accuracy: 0.9428571428571428\n","Test accuracy: 0.9666666666666667\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"BOHEya1fIfue"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a94DsgelIfuh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qebqtNJv5PH_"},"source":[""],"execution_count":null,"outputs":[]}]}