{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pZB_ACT6h4C9"
   },
   "source": [
    "# Notes\n",
    "\n",
    "Put your homework in the directory with your name. Please mentionin this file the names of any students with whom you collaborated. If you didn't collaborate with anyone, mark your collaborators as \"None.\" \n",
    "Remember, your goal is to communicate. Full credit will be given only to correct solutions which are described clearly. Convoluted and obtuse descriptions will receive low marks. \n",
    "To complete your homework, you may ONLY consult the following material: \n",
    "1.\tlecture slides\n",
    "2.\tcourse notes you or others took during lecture.\n",
    "3.\tthe required text (CLRS)\n",
    "4.\twebsites that may clarify the concepts covered in the material but do not in any way provide complete solutions to the problems.\n",
    "\n",
    "Deadline 2/20/2019\n",
    "\n",
    "Please provide an answer to the following questions: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TZLIw9Tdh4C_"
   },
   "source": [
    "# Question 1 (10 pts)\n",
    "\n",
    "Create a script that: \n",
    "1. load the iris data.\n",
    "2. scale the indipendent features.\n",
    "3. compute the correlation coefficients and co-variance among all the pair of indipendent features.\n",
    "4. compute the PCA and show the principal components (their coefficients) \n",
    "5. compute the correlation coefficient between each original feature and the new features generated by the PCA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. load the iris data\n",
    "filename = \"iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "data_iris = pd.read_csv(filename, names=names)\n",
    "data_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. scale the independent features.\n",
    "X = data_iris.iloc[:,0:4]\n",
    "X_scaled = preprocessing.scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.10936925,  0.87175416,  0.81795363],\n",
       "       [-0.10936925,  1.        , -0.4205161 , -0.35654409],\n",
       "       [ 0.87175416, -0.4205161 ,  1.        ,  0.9627571 ],\n",
       "       [ 0.81795363, -0.35654409,  0.9627571 ,  1.        ]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. compute the correlation coefficients and co-variance among all the pair of independent features.\n",
    "np.corrcoef(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.68569351, -0.03926846,  1.27368233,  0.5169038 ],\n",
       "       [-0.03926846,  0.18800403, -0.32171275, -0.11798121],\n",
       "       [ 1.27368233, -0.32171275,  3.11317942,  1.29638747],\n",
       "       [ 0.5169038 , -0.11798121,  1.29638747,  0.58241432]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.cov(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.52237162, -0.26335492,  0.58125401,  0.56561105],\n",
       "       [ 0.37231836,  0.92555649,  0.02109478,  0.06541577],\n",
       "       [-0.72101681,  0.24203288,  0.14089226,  0.6338014 ],\n",
       "       [-0.26199559,  0.12413481,  0.80115427, -0.52354627]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. compute the PCA and show the principal components (their coefficients) \n",
    "PCA_model = PCA(n_components=4)\n",
    "PC_PCA = PCA_model.fit(X_scaled)\n",
    "PC_PCA.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PC1</th>\n",
       "      <td>0.891224</td>\n",
       "      <td>-0.449313</td>\n",
       "      <td>0.991684</td>\n",
       "      <td>0.964996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC2</th>\n",
       "      <td>0.357352</td>\n",
       "      <td>0.888351</td>\n",
       "      <td>0.020247</td>\n",
       "      <td>0.062786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC3</th>\n",
       "      <td>-0.276774</td>\n",
       "      <td>0.092908</td>\n",
       "      <td>0.054084</td>\n",
       "      <td>0.243295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PC4</th>\n",
       "      <td>-0.037610</td>\n",
       "      <td>0.017820</td>\n",
       "      <td>0.115009</td>\n",
       "      <td>-0.075157</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal-length  sepal-width  petal-length  petal-width\n",
       "PC1      0.891224    -0.449313      0.991684     0.964996\n",
       "PC2      0.357352     0.888351      0.020247     0.062786\n",
       "PC3     -0.276774     0.092908      0.054084     0.243295\n",
       "PC4     -0.037610     0.017820      0.115009    -0.075157"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5 compute the correlation coefficient between each original feature and the new features generated by the PCA \n",
    "X_PCA = PC_PCA.transform(X_scaled)\n",
    "new_old_comp = pd.DataFrame(np.corrcoef(X_PCA.T, X.T)).iloc[0:4,4:8]\n",
    "new_old_comp.columns = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width']\n",
    "new_old_comp.index = ['PC1', 'PC2', 'PC3', 'PC4']\n",
    "new_old_comp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RLAL65-Jh4C_"
   },
   "source": [
    "# Question 2 (5 pts + (5 pts Extra))\n",
    "\n",
    "#Edoardo you did not connect the correlation with the eigenvector coefficient. 3pts\n",
    "\n",
    "1. What you can observe by comparing the results in Question1 of the point 4 and 5?\n",
    "2. Can you define any property?\n",
    "3. If there is any property are you able to formally prove it? (5 extra pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sepal-length    15.006562\n",
       "sepal-width      4.114512\n",
       "petal-length    68.132654\n",
       "petal-width     12.746273\n",
       "dtype: float64"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proportion of variance from the original features\n",
    "vars = X.apply(lambda x : np.var(x))\n",
    "(vars/sum(vars)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    72.770452\n",
       "1    23.030523\n",
       "2     3.683832\n",
       "3     0.515193\n",
       "dtype: float64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The proportion of variance from the projected features from PCA\n",
    "vars = pd.DataFrame(X_PCA).apply(lambda x : np.var(x))\n",
    "(vars/sum(vars)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.93035378 0.92740362 0.14834223 0.02074601]\n",
      "[0.72770452 0.23030523 0.03683832 0.00515193]\n",
      "[0.72770452 0.95800975 0.99484807 1.        ]\n"
     ]
    }
   ],
   "source": [
    "print(PCA_model.explained_variance_)\n",
    "print(PCA_model.explained_variance_ratio_)\n",
    "print(PCA_model.explained_variance_ratio_.cumsum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* From point 3 in question 1, we can observe that the variables sepal-length, petal-length and petal-width are highly correlated with each other. \n",
    "* From point 5, we observe that these variables are highly correlated with the first projected feature from the PCA. \n",
    "* From the above computation, we observe that these 3 variables captures the most variability in the original feature space. \n",
    "* Hence, we can say that the first Principle Component is the linear combination of these variables since they capture the most variability of all possible linear combinations.\n",
    "* From point 4 we see that the variables sepal-length, petal-length and petal-width all load on the SAME Principal Component (Eigenvector) which is the first component. And the variable sepal-width loads on a different Principal Component (Eigenvector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 Can you define any property?\n",
    "\n",
    "* (i) Independent - (The new features are independent).\n",
    "* (ii) Communality - A measure of how well the principal components explain the variance of each of the variables. This is the square of the correlation of the original variable with the new feature, this gives the part of the variance accounted for by the new feature. The sum of these squares is the explained variance for the original features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If there is any property are you able to formally prove it? (5 extra pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qdjUk2m4h4DA"
   },
   "source": [
    "# Question 3 (10 pts)\n",
    "\n",
    "1) Write a code in pure python (Numpy and Scipy are allowed, do not use scikit) able to create a decision tree. In input, you should provide the independent features and the dependent feature (the class) separately.\n",
    "You can assume the dependent features and the independent feature binary. Please implements the Gini index and the entropy gain ratio. You can read the code available online, but you cannot plagiarize it.\n",
    "\n",
    "2) Create a toy example to run and test your code (please show the result).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "leaf_node_MIN = 5\n",
    "tree_depth_MAX = 10\n",
    "target_Attribute = 'class' # Should be updated for a new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def print_tree(tree, tree_depth = 0, node=\"\"):\n",
    "    if tree.isleafNode:\n",
    "        print(\"Tree Depth - \" + str(tree_depth), \"{{leaf}} label: %s, leaf-shape: %s\" % (tree.leafLabel, str(tree.train.shape)))\n",
    "        print(\"---------------\")\n",
    "        \n",
    "    else:\n",
    "       print( \"  \" * tree_depth + \"- \" + \"[[node]] shape %s, [[split_Attribute]]: %s, [[split_Break/value]]: %s\" % (str(tree.train.shape), tree.splitAttr, tree.splitBreak))\n",
    "       print_tree(tree.left_node, tree_depth + 1, \"left\")\n",
    "       print_tree(tree.right_node, tree_depth + 1, \"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for Gain Ratio, use measure = 2, for gini-index, measure = 1\n"
     ]
    }
   ],
   "source": [
    "class DecisionTree:\n",
    "    # Note: Dependent and Independent features are Binary\n",
    "    # Input 1 for Gini index\n",
    "    print(\"for Gain Ratio, use measure = 2, for gini-index, measure = 1\") \n",
    "    Node_count = 0\n",
    "    def __init__(self, train, target, tree_depth=0, measure = 1):\n",
    "        DecisionTree.Node_count += 1\n",
    "        self.isleafNode = False\n",
    "        self.Impurity_measue = measure\n",
    "        self.train = train\n",
    "        \n",
    "        self.leafLabel = train[target].value_counts().index[0]\n",
    "        # Stopping Criteria - Terminates the Tree growing process\n",
    "        # (1)-Check whether all the instances have identical class label or attribute values\n",
    "        if len(train[target].value_counts())==1:\n",
    "            self.isleafNode = True\n",
    "            return\n",
    "    \n",
    "        # (2)-Check if the thresholds for leaf node instances or Tree depth are reached(This prevents data fragmentation)\n",
    "        if len(train) <= leaf_node_MIN or tree_depth > tree_depth_MAX:\n",
    "            self.isleafNode = True\n",
    "            return\n",
    "        \n",
    "        self.objBestFit = self.find_best_split(train, target, measure)   # find_best split attribute and value\n",
    "        self.splitAttr = list(self.objBestFit.index)[0]   # get spliting attribute\n",
    "        self.splitBreak = list(self.objBestFit[0].keys())[0]   # get best break(value) of the spliting attribute\n",
    "        # Split tree node\n",
    "        idx = train[self.splitAttr]==self.splitBreak\n",
    "        self.left_split = train[idx]\n",
    "        self.right_split = train[~idx]\n",
    "        self.left_node = DecisionTree(self.left_split, target, tree_depth+1, measure)\n",
    "        self.right_node = DecisionTree(self.right_split, target, tree_depth+1, measure)\n",
    "        \n",
    "    # Compute the weighted impurity measure for the children nodes and calculate the gain\n",
    "    def impurity_measure(self, attribute,target,train,I_parent,measure):\n",
    "        N = len(attribute)  # Size of parent\n",
    "                \n",
    "        I_table = pd.crosstab(train.loc[:,target],attribute)\n",
    "        colnames = list(I_table.columns)\n",
    "        dict_Gain_val = dict()  # data structure to store the gain in purity \n",
    "\n",
    "        # Produce only binary splits \n",
    "        # To keep it simple, instead of considering all 2^(k-1)-1 ways of creating binary partition\n",
    "        # We consider k ways for test conditions that produce more than 2 way splits\n",
    "        # For example an attribute with 3 splits (A,B,C), we would consider A & BC; B & AC; C & AB\n",
    "        k = np.where(len(colnames)==2,1,len(colnames)).item()\n",
    "\n",
    "        if measure == 1: # Gini Index measure of impurity\n",
    "            Gini_vals = pd.Series()\n",
    "            for i in range(k):\n",
    "               n1class = sum(I_table.loc[:,colnames[i]])      # Total instances in class n1\n",
    "               node_1 = I_table.loc[:,colnames[i]]/n1class    # fraction of instances that belong to node-1(n1): pi=ni/N1class\n",
    "               p1 = node_1.iloc[0]\n",
    "               p2 = node_1.iloc[1]\n",
    "               I_node1 = 2*p1*p2   #calculate node 1 impurity: 2*p1*p2 = 1-p1^2-p2^2\n",
    "               n2class = sum(I_table.loc[:, ~I_table.columns.isin([colnames[i]])].sum(1))   # Total instances in class ~n1\n",
    "               \n",
    "               # Avoid division by zero\n",
    "               if n2class == 0:\n",
    "                     I_weight = (n1class/N * I_node1)\n",
    "                     Gini_vals = Gini_vals.append(pd.Series(I_weight, index=[colnames[i]]))\n",
    "                     continue\n",
    "    \n",
    "               node_2 = I_table.loc[:, ~I_table.columns.isin([colnames[i]])].sum(1)/n2class # fraction of instances in split ~n1: pi=ni/N2class\n",
    "               p1 = node_2.iloc[0]\n",
    "               p2 = node_2.iloc[1]\n",
    "               I_node2  = 2*p1*p2   #calculate node 2 impurity: 2*p1*p2 = 1-p1^2-p2^2\n",
    "               I_weight = (n1class/N * I_node1) + (n2class/N * I_node2)  #weighted sum of impurities of the child nodes(I_node1, I_node2)\n",
    "               Gini_vals = Gini_vals.append(pd.Series(I_weight, index=[colnames[i]])) #Store the weighted gini-index for all child node\n",
    "    \n",
    "            Gain = I_parent - Gini_vals.loc[Gini_vals.idxmin()]  #return the minimum weighted impurity measure (occurs if an attribute has more than 2 branches)\n",
    "                                                                                              #and subtract from the parent impurity measure   \n",
    "            dict_Gain_val[Gini_vals.idxmin()] = Gain  \n",
    "        else: #Entropy Gain Ratio\n",
    "            Entropy_vals = pd.Series()\n",
    "            for i in range(k):\n",
    "               n1class = sum(I_table.loc[:,colnames[i]])      # Total instances in class n1\n",
    "               node_1 = I_table.loc[:,colnames[i]]/n1class    # fraction of instances that belong to node-1(n1): pi=ni/N1class\n",
    "               p1 = node_1.iloc[0]\n",
    "               p2 = node_1.iloc[1]\n",
    "               \n",
    "               #Avoid taking the log of zero\n",
    "               p1 = np.nan if p1 == 0 else p1\n",
    "               p2 = np.nan if p2 == 0 else p2\n",
    "               \n",
    "               p1i = -p1*math.log2(p1)\n",
    "               p1i = 0 if np.isnan(p1i) else p1i\n",
    "               p2i = -p1*math.log2(p1)\n",
    "               p2i = 0 if np.isnan(p2i) else p2i\n",
    "               #I_node1 = -p1*math.log2(p1)-p2*math.log2(p2)   #calculate Entropy for node 1: -p1log(p1)-p2log(p2)\n",
    "               I_node1 = p1i + p2i\n",
    "               \n",
    "               n2class = sum(I_table.loc[:, ~I_table.columns.isin([colnames[i]])].sum(1))   # Total instances in class ~n1\n",
    "               # Avoid division by zero\n",
    "               if n2class == 0:\n",
    "                     I_weight = (n1class/N * I_node1)\n",
    "                     Gain_Ratio = (I_parent - I_weight)/-(n1class/N)*math.log2(n1class/N) \n",
    "                     Entropy_vals = Entropy_vals.append(pd.Series(Gain_Ratio, index=[colnames[i]]))\n",
    "                     continue\n",
    "            \n",
    "               node_2 = I_table.loc[:, ~I_table.columns.isin([colnames[i]])].sum(1)/n2class # fraction of instances in split ~n1: pi=ni/N2class\n",
    "               p1 = node_2.iloc[0]\n",
    "               p2 = node_2.iloc[1]\n",
    "               #Avoid taking the log of zero\n",
    "               p1 = np.nan if p1 == 0 else p1\n",
    "               p2 = np.nan if p2 == 0 else p2\n",
    " \n",
    "               p1i = -p1*math.log2(p1)\n",
    "               p1i = 0 if np.isnan(p1i) else p1i\n",
    "               p2i = -p1*math.log2(p1)\n",
    "               p2i = 0 if np.isnan(p2i) else p2i              \n",
    "               #I_node2  = -p1*math.log2(p1)-p2*math.log2(p2)   #calculate Entropy for node 2: -p1log(p1)-p2log(p2)\n",
    "               I_node2 = p1i + p2i\n",
    "               \n",
    "               I_weight = (n1class/N * I_node1) + (n2class/N * I_node2)  #weighted sum of impurities of the child nodes(I_node1, I_node2)\n",
    "               Gain_Ratio = (I_parent - I_weight)/-(n1class/N)*math.log2(n1class/N) - (n2class/N)*math.log2(n2class/N)\n",
    "               Entropy_vals = Entropy_vals.append(pd.Series(Gain_Ratio, index=[colnames[i]])) \n",
    "               \n",
    "            dict_Gain_val[Entropy_vals.idxmax()] = Gain_Ratio\n",
    "        return dict_Gain_val\n",
    "         \n",
    "    # Determine the attribute test condition for partitioning the training instances associated with a node\n",
    "    def find_best_split(self, train, target, measure):\n",
    "        # get the impurity measure for the parent node\n",
    "        class_count = train[target].value_counts()   # class distribution at parent node \n",
    "        p1 = class_count[0]/sum(class_count)\n",
    "        p2 = class_count[1]/sum(class_count)\n",
    "\n",
    "        if measure == 1: # Gini Index measure of impurity\n",
    "            # Gini index of parent node before splitting\n",
    "            I_parent  = 2*p1*p2   \n",
    "            # get the impurity measure for each child node\n",
    "            gini_indices = train.loc[:,~train.columns.isin([target])].apply(self.impurity_measure, axis=0, args=(target,train,I_parent,measure,))\n",
    "            optimal_val = max([ix for ix in gini_indices], key=lambda x:x[list(x.keys())[0]])\n",
    "            return gini_indices[gini_indices==optimal_val]            \n",
    "        else:  #Entropy Gain Ratio \n",
    "            # Parent Entropy before splitting \n",
    "            I_parent = -p1*math.log2(p1)-p2*math.log2(p2)\n",
    "            # get the impurity measure(gain ratio) for each attribute\n",
    "            gain_Ratios = train.loc[:,~train.columns.isin([target])].apply(self.impurity_measure, axis=0, args=(target,train,I_parent,measure,))\n",
    "            optimal_val = max([ix for ix in gain_Ratios], key=lambda x:x[list(x.keys())[0]])\n",
    "            return gain_Ratios[gain_Ratios==optimal_val]            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- [[node]] shape (286, 10), [[split_Attribute]]: age, [[split_Break/value]]: 20-29\n",
      "Tree Depth - 1 {{leaf}} label: no-recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "  - [[node]] shape (285, 10), [[split_Attribute]]: age, [[split_Break/value]]: 70-79\n",
      "    - [[node]] shape (6, 10), [[split_Attribute]]: node_caps, [[split_Break/value]]: ?\n",
      "Tree Depth - 3 {{leaf}} label: recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "Tree Depth - 3 {{leaf}} label: no-recurrence-events, leaf-shape: (5, 10)\n",
      "---------------\n",
      "    - [[node]] shape (279, 10), [[split_Attribute]]: tumor_size, [[split_Break/value]]: 45-49\n",
      "Tree Depth - 3 {{leaf}} label: no-recurrence-events, leaf-shape: (3, 10)\n",
      "---------------\n",
      "      - [[node]] shape (276, 10), [[split_Attribute]]: tumor_size, [[split_Break/value]]: 5-9\n",
      "Tree Depth - 4 {{leaf}} label: no-recurrence-events, leaf-shape: (4, 10)\n",
      "---------------\n",
      "        - [[node]] shape (272, 10), [[split_Attribute]]: tumor_size, [[split_Break/value]]: 0-4\n",
      "          - [[node]] shape (7, 10), [[split_Attribute]]: deg-malig, [[split_Break/value]]: 3\n",
      "Tree Depth - 6 {{leaf}} label: no-recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "            - [[node]] shape (6, 10), [[split_Attribute]]: breast_quad, [[split_Break/value]]: left_low\n",
      "Tree Depth - 7 {{leaf}} label: no-recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "Tree Depth - 7 {{leaf}} label: no-recurrence-events, leaf-shape: (5, 10)\n",
      "---------------\n",
      "          - [[node]] shape (265, 10), [[split_Attribute]]: tumor_size, [[split_Break/value]]: 50-54\n",
      "            - [[node]] shape (8, 10), [[split_Attribute]]: deg-malig, [[split_Break/value]]: 3\n",
      "Tree Depth - 7 {{leaf}} label: recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "              - [[node]] shape (7, 10), [[split_Attribute]]: deg-malig, [[split_Break/value]]: 1\n",
      "Tree Depth - 8 {{leaf}} label: no-recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "                - [[node]] shape (6, 10), [[split_Attribute]]: age, [[split_Break/value]]: 60-69\n",
      "Tree Depth - 9 {{leaf}} label: no-recurrence-events, leaf-shape: (2, 10)\n",
      "---------------\n",
      "Tree Depth - 9 {{leaf}} label: no-recurrence-events, leaf-shape: (4, 10)\n",
      "---------------\n",
      "            - [[node]] shape (257, 10), [[split_Attribute]]: inv_nodes, [[split_Break/value]]: 24-26\n",
      "Tree Depth - 7 {{leaf}} label: recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "              - [[node]] shape (256, 10), [[split_Attribute]]: inv_nodes, [[split_Break/value]]: 12-14\n",
      "Tree Depth - 8 {{leaf}} label: recurrence-events, leaf-shape: (3, 10)\n",
      "---------------\n",
      "                - [[node]] shape (253, 10), [[split_Attribute]]: inv_nodes, [[split_Break/value]]: 15-17\n",
      "                  - [[node]] shape (6, 10), [[split_Attribute]]: breast_quad, [[split_Break/value]]: right_up\n",
      "Tree Depth - 10 {{leaf}} label: recurrence-events, leaf-shape: (1, 10)\n",
      "---------------\n",
      "Tree Depth - 10 {{leaf}} label: no-recurrence-events, leaf-shape: (5, 10)\n",
      "---------------\n",
      "                  - [[node]] shape (247, 10), [[split_Attribute]]: inv_nodes, [[split_Break/value]]: 9-11\n",
      "                    - [[node]] shape (8, 10), [[split_Attribute]]: irradiat, [[split_Break/value]]: no\n",
      "Tree Depth - 11 {{leaf}} label: recurrence-events, leaf-shape: (2, 10)\n",
      "---------------\n",
      "Tree Depth - 11 {{leaf}} label: no-recurrence-events, leaf-shape: (6, 10)\n",
      "---------------\n",
      "                    - [[node]] shape (239, 10), [[split_Attribute]]: inv_nodes, [[split_Break/value]]: 6-8\n",
      "Tree Depth - 11 {{leaf}} label: recurrence-events, leaf-shape: (16, 10)\n",
      "---------------\n",
      "Tree Depth - 11 {{leaf}} label: no-recurrence-events, leaf-shape: (223, 10)\n",
      "---------------\n"
     ]
    }
   ],
   "source": [
    "filename = \"breast-cancer.data\"\n",
    "names = ['class','age','menopause','tumor_size','inv_nodes','node_caps','deg-malig','breast','breast_quad','irradiat']\n",
    "dataset = pd.read_csv(filename, names=names)\n",
    "tree = DecisionTree(dataset, target_Attribute,measure=2)\n",
    "print_tree(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Please Note: Trying to print the subset of the dataset at every node made the tree very unreadable. Hence, I removed it and displayed the shape of the node instead."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v0593DKRh4DB"
   },
   "source": [
    "#Edoardo Your total score is 23"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "PS1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
