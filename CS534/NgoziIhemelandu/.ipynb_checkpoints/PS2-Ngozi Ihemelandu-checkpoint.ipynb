{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ngozi Ihemelandu - Homework-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 (15 pts)\n",
    "Implement the fit and predict procedures for the logistic regression (scikit is not allowed).\n",
    "Use as the imput parameters of the gradient ascent the maximum number of iterations (just a constant e.g 100) and the learning factor (e.g. 0.01)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "===================================================================================================<br>\n",
    "We will be using the Newton Raphson optimization technique to estimate the parameters of interest instead of gradient ascent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability of the event of interest y=1 is:\n",
    "$P(y = 1|x; w,b) = \\dfrac{1}{1+e^-(w.x + b)}$. Also known as the logistic function<br><br>\n",
    "\n",
    "We would denote both the w and b parameters by $\\theta$ (theta) <br>\n",
    "For a d-dimensional dataset w = $[w_{1},w_{2}, ..., w_{d}]$ hence $\\theta$ will represent $[b, w_{1},w_{2}, ..., w_{d}]$ <br>\n",
    "\n",
    "To estimate $\\theta$, we use the Maximum Likelihood Estimate technique (MLE).<br>\n",
    "$L(\\theta) = \\prod_{i=1}^n(P(x))^{y_{i}}(1-p(x))^{1-y_{i}}$ <br>\n",
    "$logL(\\theta) = log\\prod_{i=1}^n(P(x))^{y_{i}}(1-p(x))^{1-y_{i}} = \\sum_{i=1}^n y_{i}log(P(x)) + (1-y_{i})log(1-P(x)$ <br><br>\n",
    "We obtain the gradient (first order partial derivatives)<br>\n",
    "In the context of this homework, it is a 5 X 5 matrix <br>\n",
    "[$\\frac{\\partial logL(\\theta)}{\\partial w_{1}}, \\frac{\\partial logL(\\theta)}{\\partial w_{2}}, \\frac{\\partial logL(\\theta)}{\\partial w_{3}}, \\frac{\\partial logL(\\theta)}{\\partial w_{4}}, \\frac{\\partial logL(\\theta)}{\\partial b}$]\n",
    "                                                                                                              \n",
    "Next, we obtain the Hessian matrix, which is the second order partial derivatives<br><br>\n",
    "[$\\frac{\\partial^2 logL(\\theta)}{\\partial w_{1}^2}, \\frac{\\partial^2 logL(\\theta)}{\\partial w_{1}w_{2}}, \\frac{\\partial^2 logL(\\theta)}{\\partial w_{1}w_{3}}, \\frac{\\partial^2 logL(\\theta)}{\\partial w_{1}w_{4}}, \\frac{\\partial^2 logL(\\theta)}{\\partial w_{1}b}$]<br>\n",
    "  . <br> . <br> . <br>\n",
    "[$\\frac{\\partial^2 logL(\\theta)}{\\partial bw_{1}}, \\frac{\\partial^2 logL(\\theta)}{\\partial bw_{2}}, \\frac{\\partial^2 logL(\\theta)}{\\partial bw_{3}}, \\frac{\\partial^2 logL(\\theta)}{\\partial bw_{4}}, \\frac{\\partial^2 logL(\\theta)}{\\partial b^2}$] <br><br>\n",
    "\n",
    "Newton Raphson:\n",
    "$ \\hat{\\theta} = \\theta - Hessian^{-1} * Gradient $\n",
    "\n",
    "==========================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy.linalg import inv\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logistic_Reg:\n",
    "    \"Expected data structure - 2 or 1-dimensional array \"\n",
    "    def __init__(self, initial_value):\n",
    "        self.num_parameters = 0\n",
    "        self.data = 0\n",
    "        self.gradient = 0\n",
    "        self.hessian = 0\n",
    "        self.theta_est = 0\n",
    "        self.init_val = initial_value\n",
    "        \n",
    "    #Sigmoid/Logistic function\n",
    "    def P_y(self, theta, X):\n",
    "        z = np.dot(X, theta)\n",
    "        return(1/(1 + np.exp(-z)))\n",
    "    \n",
    "    def fit(self, X_data, Y_data):\n",
    "        if len(X_data.shape)== 2:\n",
    "            self.num_parameters = X_data.shape[1] + 1\n",
    "        else:\n",
    "            self.num_parameters = 2\n",
    "        \n",
    "        #Append a column of 1 to the X_data array. This will be an initial coefficient for the parameter b\n",
    "        X_size = len(X_data)\n",
    "        coeff = np.repeat(1, X_size)\n",
    "        X_data = np.concatenate((coeff[:,None], X_data), axis=1) #change shape from (nrow,) to (nrow,1) and thern concatenate\n",
    "        \n",
    "        #Set initial values of our parameters\n",
    "        theta = np.array(self.init_val)\n",
    "        theta_new = np.array(self.init_val)\n",
    "         \n",
    "        #stores first-order derivatives of the log likelihood with respect to theta = [b, w1, w2, w3, w4]\n",
    "        self.gradient = np.zeros([1, self.num_parameters])\n",
    "        #stores second-order derivatives of the log likelihood with respect to theta = [b, w1, w2, w3, w4]\n",
    "        self.hessian = np.zeros([self.num_parameters, self.num_parameters])\n",
    "        \n",
    "        iterate = 0\n",
    "        while np.sum(abs(theta_new-theta)) > 10^(-10) or iterate < 25:\n",
    "            #first-order derivatives of the log likelihood with respect to theta\n",
    "            for i in range(self.num_parameters):\n",
    "                self.gradient[0,i] = sum(Y_data * X_data[:,i]) - sum(self.P_y(theta, X_data) * X_data[:,i])\n",
    "                \n",
    "            #second-order derivatives of the log likelihood with respect to theta\n",
    "            for i in range(self.num_parameters):\n",
    "                self.hessian[i,i] = - sum(X_data[:,i]* X_data[:,i] * self.P_y(theta, X_data) * (1-self.P_y(theta, X_data)))\n",
    "                for j in range(i):\n",
    "                    self.hessian[i,j] = - sum(X_data[:,i]* X_data[:,j] * self.P_y(theta, X_data) * (1-self.P_y(theta, X_data)))\n",
    "                    self.hessian[j,i] = self.hessian[i,j]\n",
    "\n",
    "            theta_new = theta - np.dot(self.gradient, inv(self.hessian)).reshape(self.num_parameters,)\n",
    "\n",
    "            if np.sum(abs(theta_new-theta)) < 10^(-10) or iterate >= 25: \n",
    "                self.theta_est = theta_new\n",
    "                break\n",
    "\n",
    "            theta = theta_new\n",
    "            iterate = iterate + 1  \n",
    "\n",
    "    #predict set of observations\n",
    "    def predict(self, X_data, threshold = 0.5):\n",
    "        #Append a column of 1 to the X_data array. Just as it was done in the fit procedure\n",
    "        X_size = len(X_data)\n",
    "        coeff = np.repeat(1, X_size)\n",
    "        X_data = np.concatenate((coeff[:,None], X_data), axis=1) #change shape from (nrow,) to (nrow,1) and thern concatenate\n",
    "\n",
    "        y_prob = self.P_y(self.theta_est, X_data)\n",
    "        y_pred = np.array([1 if prob > threshold else 0 for prob in y_prob])\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2 (20 pts)\n",
    "Use the iris dataset (just the binary class Iris Setosa vs others), the K-fold cross validation, metrics(accuracy, precision, recall, F1-score) and your implementation of the logistic regression (Question1).\n",
    "You can use scikit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal-length</th>\n",
       "      <th>sepal-width</th>\n",
       "      <th>petal-length</th>\n",
       "      <th>petal-width</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal-length  sepal-width  petal-length  petal-width        class\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the iris data\n",
    "filename = \"iris.csv\"\n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "data_iris = pd.read_csv(filename, names=names)\n",
    "success = 'Iris-setosa'  #event of interest\n",
    "target = 'class'  #response variable\n",
    "data_iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put the independent and dependent variables into numpy arrays\n",
    "indp_var = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width']\n",
    "X = data_iris[indp_var].values\n",
    "data_iris[\"success_class\"] = data_iris[target]==success\n",
    "Y = data_iris[\"success_class\"].values.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into train and test(This test set held out for final evaluation)\n",
    "X_train, X_test,y_train,y_test = train_test_split(X, Y, test_size=0.3, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Train 1.0\n"
     ]
    }
   ],
   "source": [
    "#Use the Stratified Cross Validation to estimate the parameters - theta\n",
    "initial_vals = [[0,0,0,0,0], [0.0001,0.0001,0.0001,0.0001,0.0001],[0.001,0.001,0.001,0.001,0.001]]\n",
    "n_splits=5\n",
    "best=-1\n",
    "bestval=-1\n",
    "\n",
    "for init_val in initial_vals:\n",
    "    skf = StratifiedKFold(n_splits=n_splits, random_state=123, shuffle=True)\n",
    "    c=0\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        #print(\"TRAIN:\", len(train_index), \"TEST:\", len(test_index))\n",
    "        cvX_train, cvX_test = X_train[train_index], X_train[test_index]\n",
    "        cvy_train, cvy_test = y_train[train_index], y_train[test_index]\n",
    "        model = logistic_Reg(initial_value = init_val)\n",
    "        model.fit(cvX_train, cvy_train)\n",
    "        pred = model.predict(cvX_test)\n",
    "        c+=accuracy_score(cvy_test, pred)\n",
    "    accuracyavg = c/n_splits\n",
    "    if bestval < accuracyavg:\n",
    "        bestval = accuracyavg\n",
    "        best = init_val\n",
    "\n",
    "model = logistic_Reg(initial_value = best)\n",
    "model.fit(X_train, y_train) \n",
    "pred_y_train = model.predict(X_train)\n",
    "\n",
    "print('Accuracy of Train',accuracy_score(y_train, pred_y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of Test 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        29\n",
      "           1       1.00      1.00      1.00        16\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        45\n",
      "   macro avg       1.00      1.00      1.00        45\n",
      "weighted avg       1.00      1.00      1.00        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Final evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy of Test', accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
