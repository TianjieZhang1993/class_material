{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Iris data\n",
    "data = pd.read_csv(\"iris.csv\",header=None)\n",
    "data.columns=['sepal_length', 'sepal_width', 'petal_length', 'petal_width', 'class']\n",
    "data_val=data.values\n",
    "\n",
    "def classify_One_One(s):\n",
    "    if s=='Iris-versicolor':\n",
    "        return 1\n",
    "    elif  s=='Iris-setosa':\n",
    "        return 0\n",
    "    elif s=='Iris-virginica' :\n",
    "        return 2\n",
    "\n",
    "data['num_class'] = data['class'].apply(lambda x: classify_One_One(x))\n",
    "data =data.drop(columns=['class'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.\t(20 points) Design and implement a gradient approach to determine the first dimension of the PCA transformation (compute derivatives). Suggestion minimize the Lagrange function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.40824782  0.40824378  0.81649907] 2.99993823872\n"
     ]
    }
   ],
   "source": [
    "def gen_eigen_power(A, num_simulations):\n",
    "    #A_def=A_def.reshape((A.shape[0], 1))\n",
    "    est_eigen = np.random.rand(A.shape[1])\n",
    "    lambd=0\n",
    "    for iter in range(num_simulations):\n",
    "        est_eigen_n = np.dot(A, est_eigen)\n",
    "        est_eigen_n_norm = np.linalg.norm(est_eigen_n)\n",
    "        est_eigen = est_eigen_n / est_eigen_n_norm\n",
    "        lambd=est_eigen_n_norm\n",
    "    return est_eigen,lambd\n",
    "\n",
    "eig_vec,lambd = gen_eigen_power(np.array([[1.0, 2, 0], [-2, 1, 2], [1, 3, 1]]), 10)\n",
    "print(eig_vec,lambd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gradient descent-- Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Variance= V\\Sigma V^T $\n",
    "\n",
    "The goal is to maximize variance with the constraint that the new vector be a unit vector.\n",
    "$ VV^T =1 $\n",
    "\n",
    "Using Lagrange multipliers to maximize with constraints\n",
    "\n",
    "$ L= V\\Sigma V^T  -\\lambda(VV^T - 1) $\n",
    "\n",
    "Maximizing the Lagrange function.\n",
    "\n",
    "$ \\displaystyle \\frac{\\partial}{\\partial{\\lambda}} = -1* (VV^T - 1) $\n",
    "\n",
    "$ \\displaystyle \\frac{\\partial}{\\partial{V}} = 2* (\\Sigma V - \\lambda V) $\n",
    "\n",
    "Maximizing , implies gradient ascent\n",
    "\n",
    "$\\displaystyle V= V + \\frac{\\partial}{\\partial{V}} \\eta $\n",
    "\n",
    "$\\displaystyle \\lambda= \\lambda + \\frac{\\partial}{\\partial{\\lambda}} \\eta $\n",
    "\n",
    "The above equations are implemented in the code below\n",
    "\n",
    "Iterate till \n",
    "\n",
    "$ \\displaystyle \\frac{\\partial}{\\partial{V}} = 0 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "A=np.array([[1.0, 2, 3], [3, 4, 5], [2, 6, -2]])\n",
    "A=A - np.mean(A, axis=0) # center the mean\n",
    "A\n",
    "\n",
    "# Gen covariance\n",
    "Cov = np.cov(A)\n",
    "Cov\n",
    "\n",
    "# seed vector is 3X1 in this case\n",
    "#seed_vec_trans = np.matrix(np.random.random(A.shape[1]))\n",
    "seed_vec_trans = np.matrix([0.8,0.8,0.8])\n",
    "seed_vec = np.transpose(seed_vec_trans)\n",
    "\n",
    "seed_lambda = 10\n",
    "\n",
    "eta =0.001 # learning rate\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.784]\n",
      " [ 0.784]\n",
      " [ 0.784]] 9.99908 -0.9200000000000004 [[-16.]\n",
      " [-16.]\n",
      " [-16.]]\n"
     ]
    }
   ],
   "source": [
    "del_L_lambda = -1*(np.asscalar(seed_vec_trans* seed_vec -1))\n",
    "del_L_vec = 2*(Cov*seed_vec - seed_lambda * seed_vec)\n",
    "\n",
    "seed_vec = seed_vec + eta *del_L_vec\n",
    "seed_lambda = seed_lambda + del_L_lambda*eta\n",
    "\n",
    "print(seed_vec, seed_lambda,del_L_lambda, del_L_vec )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. (20 points) Design and implement Design a gradient approach to determine the second dimension of the PCA transformation (compute derivatives). Suggestion minimize the Lagrange function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculation of the second eigen value/vector involves deflation where the first eigen value is reduced to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eigen Vector1 =[ 0.40824829  0.40824829  0.81649658], lambda1=3.0\n",
      "Deflated Matrix = [[-0.22474487  0.77525513 -2.44948974]\n",
      " [-3.22474487 -0.22474487 -0.44948974]\n",
      " [-0.22474487  1.77525513 -1.44948974]]\n",
      "Eigen Vector2 =[ 0.37147564  0.92795256 -0.03016444], lambda2=2.65979665742\n"
     ]
    }
   ],
   "source": [
    "import numpy.linalg as la\n",
    "#eig_vec,lambd = gen_eigen_power(np.array([[1.0, 2, 0], [-2, 1, 2], [1, 3, 1]]), 10)\n",
    "eig_vec,lambd = gen_eigen_power(np.array([[1.0, 2, 0], [-2, 1, 2], [1, 3, 1]]), 100)\n",
    "print(\"Eigen Vector1 =%s, lambda1=%s\" %(eig_vec,lambd))\n",
    "\n",
    "\n",
    "def deflate(A,eig_vec,lambd):\n",
    "    vec=eig_vec/la.norm(eig_vec)\n",
    "    sub=vec*np.transpose(vec)\n",
    "    sub=lambd*vec\n",
    "    A= A - sub\n",
    "    return A\n",
    "\n",
    "A_def = deflate(np.array([[1.0, 2, 0], [-2, 1, 2], [1, 3, 1]]),eig_vec,lambd)\n",
    "print(\"Deflated Matrix = %s\" %(A_def))\n",
    "\n",
    "\n",
    "# Calculate second Eigen-vector \n",
    "eig_vec2,lambd2 = gen_eigen_power(A_def, 100)\n",
    "print(\"Eigen Vector2 =%s, lambda2=%s\" %(eig_vec2,lambd2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 8.77899701, -0.51981411, -5.2591829 ]),\n",
       " array([[ 0.39181166,  0.90738715, -0.29996185],\n",
       "        [ 0.77108192, -0.35713048, -0.37620055],\n",
       "        [ 0.50191264, -0.22159961,  0.87663906]]))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w, v = la.eig(np.array([[1.0, 2, 3], [3, 4, 5], [2, 6, -2]]))\n",
    "w,v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Gradient descent for calculating the second principal component-- Theory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Variance= V\\Sigma V^T $\n",
    "\n",
    "The first eigen vector is already claculated and is\n",
    "\n",
    "$ V_1 $\n",
    "\n",
    "The goal is to maximize variance with the constraint that the new vector be a unit vector.\n",
    "\n",
    "An additional constraint is imposed which is that the second PC is orthogonal to the first \n",
    "$ VV^T =1 $\n",
    "\n",
    "Using Lagrange multipliers to maximize with constraints\n",
    "\n",
    "$ L= V\\Sigma V^T  -\\lambda(VV^T - 1) - \\mu (VV_1) $\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.\t(10 points) Describe the benefit of a gradient approach w.r.t. the SVD approach for the PCA transformation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ A= U\\Sigma V^T $\n",
    "\n",
    "The SVD decomposition is shown above. The algorithm calls for calculation of three matrices which is very expensive. Furthermore the SVD approach generates all the eigen values as opposed to generation of required eigen values for the power method or the gradient approach. In the power method, the calculations are based off on matrix multiplication and not matrix generation. This makes the iterative methods cheaper computationally.\n",
    "\n",
    "The gradient descent is an iterative method and only involves incremental calculations as opposed to decomposition."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.\t(20 points) By using a binary classifier (logistic regression or SVM) please implement in python the 2 different procedure (one vs. one, one vs. other) to handle the problem of more than two different classes (use the iris dataset). For reference use the following link .\n",
    "https://en.wikipedia.org/wiki/Multiclass_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "X_train, X_test = train_test_split(data, test_size=0.2, stratify=data['num_class'])\n",
    "t=pd.DataFrame(X_train['num_class'])\n",
    "t=t.reset_index(drop=True)\n",
    "\n",
    "tst=pd.DataFrame(X_test['num_class'])\n",
    "tst=tst.reset_index(drop=True)\n",
    "\n",
    "#Scale data\n",
    "scaler = StandardScaler()\n",
    "XS_train=pd.DataFrame(scaler.fit_transform(X_train.iloc[:,0:4])) \n",
    "XS_train=XS_train.assign(num_class= t)\n",
    "\n",
    "#Split train data into 3 groups. 1-0n-1\n",
    "XS_01=(XS_train.loc[(XS_train['num_class']==0) | (XS_train['num_class']==1)]).values\n",
    "XS_12=(XS_train.loc[(XS_train['num_class']==1) | (XS_train['num_class']==2)]).values\n",
    "XS_02=(XS_train.loc[(XS_train['num_class']==0) | (XS_train['num_class']==2)]).values\n",
    "\n",
    "\n",
    "\n",
    "#Scale Test data and divide into 3 groups\n",
    "XS_test=pd.DataFrame(scaler.transform(X_test.iloc[:,0:4]))\n",
    "XS_test=XS_test.assign(num_class= tst)\n",
    "\n",
    "# Gen 3 train groups\n",
    "XS_train_01=XS_01[:,0:4]\n",
    "yS_train_01=XS_01[:,4]\n",
    "XS_train_12=XS_12[:,0:4]\n",
    "yS_train_12=XS_12[:,4]\n",
    "XS_train_02=XS_02[:,0:4]\n",
    "yS_train_02=XS_02[:,4]\n",
    "\n",
    "# Gen  test groups\n",
    "XS_test_val =XS_test.values\n",
    "XS_test_data=XS_test_val[:,0:4]\n",
    "yS_test_data=XS_test_val[:,4]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1-on-1= 0.966666666667\n"
     ]
    }
   ],
   "source": [
    "# one vs one\n",
    "# K=3 for Iris dataset, implying 3 classifiers need to be created.\n",
    "\n",
    "clf_01 = LogisticRegression(random_state=0, solver='lbfgs').fit(XS_train_01,yS_train_01)\n",
    "clf_12 = LogisticRegression(random_state=0, solver='lbfgs').fit(XS_train_12,yS_train_12)\n",
    "clf_02 = LogisticRegression(random_state=0, solver='lbfgs').fit(XS_train_02,yS_train_02)\n",
    "\n",
    "\n",
    "y_pred_01=clf_01.predict(XS_test_data) \n",
    "y_pred_12=clf_12.predict(XS_test_data)\n",
    "y_pred_02=clf_02.predict(XS_test_data)\n",
    "\n",
    "#pd.DataFrame(y_pred_01,y_pred_12,y_pred_02)\n",
    "df = pd.DataFrame({'y_pred_01':y_pred_01, 'y_pred_12':y_pred_12, 'y_pred_02':y_pred_02})\n",
    "df['pred']=df.mode(axis=1)\n",
    "y_pred = df['pred'].values\n",
    "\n",
    "\n",
    "#acc=accuracy_score(yS_test, y_pred)\n",
    "print(\"Accuracy of 1-on-1=\", accuracy_score(yS_test_data, y_pred) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one vs rest data preparation\n",
    "\n",
    "# Data for One-on-many\n",
    "XS_train_setosa=XS_train.copy()\n",
    "XS_train_versicolor=XS_train.copy()\n",
    "XS_train_virginica=XS_train.copy()\n",
    "\n",
    "def classify_One_Rest(c1,c2): # c1=Target Class, c2=Actual Class\n",
    "    if c1==c2:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "# setosa=0,versicolor=1,virginica=2\n",
    "\n",
    "XS_train_setosa['class'] = XS_train_setosa['num_class'].apply(lambda x:classify_One_Rest(x,0))\n",
    "XS_train_versicolor['class'] = XS_train_versicolor['num_class'].apply(lambda x:classify_One_Rest1(x,1))\n",
    "XS_train_virginica['class'] = XS_train_virginica['num_class'].apply(lambda x:classify_One_Rest2(x,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of 1-on-rest= 0.933333333333\n"
     ]
    }
   ],
   "source": [
    "# one vs rest\n",
    "# K=3 for Iris dataset, implying 3 classifiers need to be created.\n",
    "\n",
    "clf_setosa = LogisticRegression(random_state=0, solver='lbfgs').fit(XS_train_setosa.iloc[:,0:4].values,XS_train_setosa.iloc[:,5].values)\n",
    "clf_versicolor = LogisticRegression(random_state=0, solver='lbfgs').fit(XS_train_versicolor.iloc[:,0:4].values,XS_train_versicolor.iloc[:,5].values)\n",
    "clf_virginica = LogisticRegression(random_state=0, solver='lbfgs').fit(XS_train_virginica.iloc[:,0:4].values,XS_train_virginica.iloc[:,5].values)\n",
    "\n",
    "#Predict values\n",
    "y_pred_setosa=clf_setosa.predict_proba(XS_test_data) \n",
    "y_pred_versicolor=clf_versicolor.predict_proba(XS_test_data) \n",
    "y_pred_virginica=clf_virginica.predict_proba(XS_test_data) \n",
    "\n",
    "df_one_rest = pd.DataFrame({'0':y_pred_setosa[:,1], '1':y_pred_versicolor[:,1], '2':y_pred_virginica[:,1]})\n",
    "y_argmax=df_one_rest.idxmax(axis=1).values\n",
    "print(\"Accuracy of 1-on-rest=\", accuracy_score(yS_test_data.astype(int), y_argmax.astype(int)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy using 1-on-1 is 0.966 while accuracy using 1-on-rest is 0.933"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.\t(20 points) Extensively describe the overfitting and underfitting problem. Use execution examples with decision tree and SVM (with or without kernel). Use the scikit implementations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Overfitting refers to the phenemon where the model learns the data very well, resulting in also learning noise. When the model is exposed to newer data, where the noise is not present, the model fails to perform adequately. This is known as overfitting. In other words the model is memorizing the data, as opposed to learning from it.\n",
    "\n",
    " Underfitting refers to the inability of the model to learn from the data. The parameters of the model are not suited to learn from the provided data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "      <th>53</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>Class1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.0428</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.1539</td>\n",
       "      <td>0.1601</td>\n",
       "      <td>0.3109</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.0159</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0090</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.0523</td>\n",
       "      <td>0.0843</td>\n",
       "      <td>0.0689</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.2583</td>\n",
       "      <td>0.2156</td>\n",
       "      <td>0.3481</td>\n",
       "      <td>0.3337</td>\n",
       "      <td>0.2872</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0089</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0094</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.0049</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.1099</td>\n",
       "      <td>0.1083</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.2280</td>\n",
       "      <td>0.2431</td>\n",
       "      <td>0.3771</td>\n",
       "      <td>0.5598</td>\n",
       "      <td>0.6194</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.0166</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0180</td>\n",
       "      <td>0.0244</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0164</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0       1       2       3       4       5       6       7       8  \\\n",
       "0  0.0200  0.0371  0.0428  0.0207  0.0954  0.0986  0.1539  0.1601  0.3109   \n",
       "1  0.0453  0.0523  0.0843  0.0689  0.1183  0.2583  0.2156  0.3481  0.3337   \n",
       "2  0.0262  0.0582  0.1099  0.1083  0.0974  0.2280  0.2431  0.3771  0.5598   \n",
       "\n",
       "        9   ...        51      52      53      54      55      56      57  \\\n",
       "0  0.2111   ...    0.0027  0.0065  0.0159  0.0072  0.0167  0.0180  0.0084   \n",
       "1  0.2872   ...    0.0084  0.0089  0.0048  0.0094  0.0191  0.0140  0.0049   \n",
       "2  0.6194   ...    0.0232  0.0166  0.0095  0.0180  0.0244  0.0316  0.0164   \n",
       "\n",
       "       58      59  Class1  \n",
       "0  0.0090  0.0032       R  \n",
       "1  0.0052  0.0044       R  \n",
       "2  0.0095  0.0078       R  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('sonar.csv',header=None)\n",
    "data.columns=[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "            51, 52, 53, 54, 55, 56, 57, 58, 59, 'Class1']\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-4cd7cb9628ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sonar.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m data.columns=[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n\u001b[1;32m      6\u001b[0m             \u001b[0;36m17\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m19\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m21\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m23\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m27\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m31\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m33\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv('sonar.csv',header=None)\n",
    "data.columns=[ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
    "            17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
    "            34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50,\n",
    "            51, 52, 53, 54, 55, 56, 57, 58, 59, 'Class1']\n",
    "data.sample(4)\n",
    "\n",
    "def classify(x):\n",
    "    if x=='R':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "data['Class']=data['Class1'].apply(classify)\n",
    "data = data.drop(columns=['Class1'])\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "Y = data['Class']\n",
    "X = data.drop(['Class'],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "#########################################\n",
    "# Training and Test set creation\n",
    "#########################################\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.1, random_state=1)\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "#########################################\n",
    "# Model fitting and evaluation\n",
    "#########################################\n",
    "\n",
    "maxdepths = [2,3,4,5,6,7,8,9,10,15,20,25,30,35,40,45,50]\n",
    "\n",
    "trainAcc = np.zeros(len(maxdepths))\n",
    "testAcc = np.zeros(len(maxdepths))\n",
    "\n",
    "index = 0\n",
    "for depth in maxdepths:\n",
    "    clf = tree.DecisionTreeClassifier(max_depth=depth)\n",
    "    clf = clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    trainAcc[index] = accuracy_score(Y_train, Y_predTrain)\n",
    "    testAcc[index] = accuracy_score(Y_test, Y_predTest)\n",
    "    index += 1\n",
    "    \n",
    "#########################################\n",
    "# Plot of training and test accuracies\n",
    "#########################################\n",
    "    \n",
    "plt.plot(maxdepths,trainAcc,'ro-',maxdepths,testAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('Max depth')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usnig SVM with RBF kernel\n",
    "\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.metrics.pairwise import rbf_kernel\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics.pairwise import polynomial_kernel\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "gamma_rbf = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,\n",
    "             2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,4,5,6,7,8,9,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x173da709550>"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x173da7b9e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "gamma_rbf = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0]\n",
    "SVMtrainAcc = []\n",
    "SVMtestAcc = []\n",
    "\n",
    "for param in gamma_rbf:\n",
    "    clf = SVC(C=param,kernel='rbf',gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "plt.plot(gamma_rbf, SVMtrainAcc, 'ro-', gamma_rbf, SVMtestAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The plot above illustrates underfitting, where the model is not complicated enough to be expressive. Both the train and test accuracy are very low. The baseline accuracy of the above data set is 53%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x173da9c7240>"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x173da8f4dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "gamma_rbf = [4,5,6,7,8,9,10]\n",
    "SVMtrainAcc = []\n",
    "SVMtestAcc = []\n",
    "\n",
    "for param in gamma_rbf:\n",
    "    clf = SVC(C=param,kernel='rbf',gamma='auto')\n",
    "    clf.fit(X_train, Y_train)\n",
    "    Y_predTrain = clf.predict(X_train)\n",
    "    Y_predTest = clf.predict(X_test)\n",
    "    SVMtrainAcc.append(accuracy_score(Y_train, Y_predTrain))\n",
    "    SVMtestAcc.append(accuracy_score(Y_test, Y_predTest))\n",
    "\n",
    "plt.plot(gamma_rbf, SVMtrainAcc, 'ro-', gamma_rbf, SVMtestAcc,'bv--')\n",
    "plt.legend(['Training Accuracy','Test Accuracy'])\n",
    "plt.xlabel('C')\n",
    "plt.xscale('log')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The above model illustrates a case of overfit where the hyperparametrs are too large for the model resulting in the models learning not being genralised enough and causing the test accuracy to plunge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.\t(10 points) Show examples or situations when the using kernel procedure is more efficient in terms of training and prediction computational time w.r.t. polynomial features transformation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training, the computational complexity of a kernel proceedure is given by O(N^3), as the space transformation takes about N^2 nd the inner dot product uses N (or number of features), resulting in N^3.\n",
    "\n",
    " On the other hand , use of polynomial features results in the enumeration of the all possible combinations of the features upto the desired degree. For example, if we have degree =3, and two features X,Y, then the combinations are  X,Y,XY,X^2Y,Y^2X,X^3 and Y^3. \n",
    "\n",
    "Once we exceed degree =4, the number of combinations quicky multiply resulting in greatr time complexity than a Kernel proceedure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.\t(10 points) Write a procedure to estimate in the SVC classifier (in Scikit) the best kernel (RBF, Polynomial, sigmoid), the best gamma & degree, and the best C. Use the grid search without implement it. Use the following reference: \n",
    "a.\thttps://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html#sklearn.model_selection.GridSearchCV\n",
    "\n",
    "b.\thttps://scikit-learn.org/stable/modules/grid_search.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 1\n",
      "best _params {'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      1.00      0.73        12\n",
      "        1.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.33      0.57      0.42        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 2\n",
      "best _params {'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.67      1.00      0.80        14\n",
      "        1.0       0.00      0.00      0.00         7\n",
      "\n",
      "avg / total       0.44      0.67      0.53        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 3\n",
      "best _params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.43      1.00      0.60         9\n",
      "        1.0       0.00      0.00      0.00        12\n",
      "\n",
      "avg / total       0.18      0.43      0.26        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 4\n",
      "best _params {'C': 100, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      1.00      0.73        12\n",
      "        1.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.33      0.57      0.42        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 5\n",
      "best _params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      1.00      0.65        10\n",
      "        1.0       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.23      0.48      0.31        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 6\n",
      "best _params {'degree': 1, 'gamma': 0.001, 'kernel': 'poly'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.48      1.00      0.65        10\n",
      "        1.0       0.00      0.00      0.00        11\n",
      "\n",
      "avg / total       0.23      0.48      0.31        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 7\n",
      "best _params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.57      1.00      0.73        12\n",
      "        1.0       0.00      0.00      0.00         9\n",
      "\n",
      "avg / total       0.33      0.57      0.42        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 8\n",
      "best _params {'C': 1000, 'gamma': 0.0001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.29      1.00      0.44         6\n",
      "        1.0       0.00      0.00      0.00        15\n",
      "\n",
      "avg / total       0.08      0.29      0.13        21\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 9\n",
      "best _params {'C': 10, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.70      1.00      0.82        14\n",
      "        1.0       0.00      0.00      0.00         6\n",
      "\n",
      "avg / total       0.49      0.70      0.58        20\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold # 10\n",
      "best _params {'C': 100, 'gamma': 0.001, 'kernel': 'sigmoid'}\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.60      1.00      0.75        12\n",
      "        1.0       0.00      0.00      0.00         8\n",
      "\n",
      "avg / total       0.36      0.60      0.45        20\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sayyapureddi\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import svm\n",
    "\n",
    "X=data.values[:,0:60]\n",
    "y=data.values[:,60]\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)\n",
    "\n",
    "n_splits=10\n",
    "skf = KFold(n_splits=n_splits,shuffle=True)\n",
    "\n",
    "parameter_candidates = [\n",
    "  {'gamma': [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,4,5,6,7,8,9,10], 'kernel': ['rbf']},\n",
    "  {'degree': [1,2,3,4,5,6,7,8, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['poly']},\n",
    "  {'C': [0.1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['sigmoid']}\n",
    "]\n",
    "\n",
    "#gamma_rbf = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1.0,1.1,1.2,1.3,1.4,1.5,1.6,1.7,1.8,1.9,2.0,2.1,2.2,2.3,2.4,2.5,2.6,2.7,2.8,2.9,3.0,4,5,6,7,8,9,10]\n",
    "clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, n_jobs=-1)\n",
    "fold=0\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    fold+=1\n",
    "    X_train1=X[train_index]\n",
    "    X_test=X[test_index]\n",
    "    y_train=y[train_index]\n",
    "    y_test=y[test_index]\n",
    "    scaler = StandardScaler()\n",
    "    XS_train=scaler.fit_transform(X_train1) \n",
    "    XS_test=scaler.transform(X_test)\n",
    "    \n",
    "    clf = GridSearchCV(estimator=svm.SVC(), param_grid=parameter_candidates, cv=5,scoring='accuracy')\n",
    "    clf.fit(XS_train, y_train)\n",
    "    print(\"fold #\", fold)\n",
    "    print(\"best _params\", clf.best_params_)\n",
    "    \n",
    "    y_true, y_pred = y_test, clf.predict(X_test)\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.\t(20 points) Create examples to explain the property and the importance of the following kernels:\n",
    "a.\thttps://en.wikipedia.org/wiki/Graph_kernel\n",
    "\n",
    "b.\thttps://en.wikipedia.org/wiki/String_kernel\n",
    "\n",
    "c.\thttps://scikit-learn.org/stable/modules/generated/sklearn.metrics.pairwise.sigmoid_kernel.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graph Kernel\n",
    "\n",
    "An example of a Graph Kernel is the Shortest Path kernel. This kernel finds the similarity of two graphs based on the similarity of the shortest paths in the two graphs.\n",
    "\n",
    "As an example given G and G`, the kernel can be defined as \n",
    "\n",
    "$$ K(G,G^`) =  \\sum_{v_i,v_j \\in G} \\sum_{v_k,v_l \\in G^`} k_length(d(v_i,v_j),d(v^`_k,v^`_l)) $$\n",
    "\n",
    "where $$ k_length = \\displaystyle 1 $$ if shortest path distances are equal, else $$ \\displaystyle 0 $$\n",
    "\n",
    "This is useful when comparing protein structures."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### String Kernel\n",
    "\n",
    "Any Kernel is a function which measures the similarity of two vectors or data points. When a Kernel measures the similarity of two strings, it is said to be a string Kernel. \n",
    "\n",
    "As an example consider two strings s and t. s= \"strawberry\", t= \"rawstberry\".\n",
    "\n",
    "$$ S=\\{\"st\", \"tr\", \"ra\", \"aw\", \"wb\", \"be\", \"er\", \"rr\", \"ry\"\\} $$\n",
    "$$ T=\\{\"ra\", \"aw\", \"ws\", \"st\", \"tb\", \"be\", \"er\", \"rr\", \"ry\"\\} $$\n",
    "\n",
    "A string kernel which looks for the similar 2-grams in both the strings can generate a similarity coefficient or number.\n",
    "\n",
    "$$ k_{2} (s, t) = \\sum_{v \\in \\sum^2} num_v(s).num_v(t) $$\n",
    "\n",
    "where $$ \\sum^2 = S \\cup T $$\n",
    "\n",
    "In such a case, $$ k_2(S,T)=7 $$\n",
    "\n",
    "The attractiveness of string kernels is that they enable you to do string operations without having to do feature extraction to compare similarity. As an example string kernels can be used to detect plaigirism by detecting similarities in writing or sentence construction.\n",
    "\n",
    "Is also useful to compare genomic sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sigmoid Kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid kernel is another name for the Hyperbolic tangent kernel. This function is also an activation function used in Neural networks. Under certain conditions this function approximates the performance of the RBH kernel. A kernel function essentially calculates the similarity of two vectors in space. This helps in making non-linear data linear.\n",
    "\n",
    "In the sigmoid kernel, the tanh(xy + C) does not normalize the transformation. \n",
    "\n",
    "I am not sure why this kernel even exists as this seems like a subset of the RBF. The RBF does normalize with the \n",
    "$ \\sigma $ whic is not present in the sigmoid.\n",
    "\n",
    "Mathematically I am not sure how this is more advantageous than the RBF or if there is a subset of data which makes the sigmoid kernel more useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
