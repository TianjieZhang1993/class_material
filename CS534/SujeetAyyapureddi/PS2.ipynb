{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "czVETi-U8I0h"
   },
   "source": [
    "# CS534 Homework 2\n",
    "\n",
    "Put your homework in the directory with your name. Please mentionin this file the names of any students with whom you collaborated. If you didn't collaborate with anyone, mark your collaborators as \"None.\" Remember, your goal is to communicate. Full credit will be given only to correct solutions which are described clearly. Convoluted and obtuse descriptions will receive low marks. To complete your homework, you may ONLY consult the following material:\n",
    "\n",
    "lecture slides\n",
    "course notes you or others took during lecture.\n",
    "the required text (CLRS)\n",
    "websites that may clarify the concepts covered in the material but do not in any way provide complete solutions to the problems.\n",
    "Deadline 2/20/2019\n",
    "\n",
    "Please provide an answer to the following question: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byP0-Jsv8I0i"
   },
   "source": [
    "# Question 1 (15 pts)\n",
    "Implement the fit and predict procedures for the logistic regression (scikit is not allowed).\n",
    "Use as the imput parameters of the gradient ascent the maximum number of iterations (just a constant e.g 100) and the learning factor (e.g. 0.01).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1541,
     "status": "ok",
     "timestamp": 1551824422727,
     "user": {
      "displayName": "Oghenemaro Anuyah",
      "photoUrl": "https://lh3.googleusercontent.com/-aTogxnURc28/AAAAAAAAAAI/AAAAAAAAAAs/eZdkQxssXhk/s64/photo.jpg",
      "userId": "10208576858792423227"
     },
     "user_tz": 420
    },
    "id": "zdKTz3TD8I0j",
    "outputId": "9cc49e94-08cb-4ce3-87b1-5ef840250d74"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class logisticRegression :\n",
    "    \n",
    "    # All methods in this class are private\n",
    "    \n",
    "    def __init__(self, max_iter=1000, lr=0.01):\n",
    "        self.max_iter=max_iter\n",
    "        self.lr=lr\n",
    "        #self.theta=np.zeros\n",
    "    \n",
    "       \n",
    "    def __sigmoid__(self, X, theta):\n",
    "        z=np.dot(X.astype(float), theta)\n",
    "        return 1/(1+np.e**(-z))\n",
    "    \n",
    "    \n",
    "    def __loss__(self, X, theta, y):\n",
    "        return (-y * np.log(self.__sigmoid__(X, theta)) - (1 - y) * np.log(1 - self.__sigmoid__(X, theta)))\n",
    "    \n",
    "    def __fit__(self, X, y):\n",
    "        # Adding in the constant\n",
    "        constant = np.ones((X.shape[0],1))\n",
    "        X = np.hstack((X, constant))\n",
    "        \n",
    "        #print(X)\n",
    "        \n",
    "        self.theta = np.zeros(X.shape[1])\n",
    "        #print(\"Inside Fit\")\n",
    "        for iter in range(self.max_iter):\n",
    "            sig=self.__sigmoid__(X, self.theta)\n",
    "            gradient = np.dot(X.T, (sig - y)) \n",
    "            #print(gradient)\n",
    "            #print(\"Done\")\n",
    "            #print(self.lr)\n",
    "            self.theta = self.theta - self.lr * gradient\n",
    "            \n",
    "            '''if(iter % 10000 == 0):\n",
    "                print(\"Loss= \", self.__loss__(X, self.theta, y))'''\n",
    "                \n",
    "    def __predict__(self, X):\n",
    "        constant = np.ones((X.shape[0],1))\n",
    "        X = np.hstack((X, constant))\n",
    "        pred =[]\n",
    "        for x in X:\n",
    "            if self.__sigmoid__(x, self.theta) >= 0.5:\n",
    "                pred.append(1)\n",
    "            else:\n",
    "                pred.append(0)\n",
    "        return pred\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lyWdLh3B8I0l"
   },
   "source": [
    "# Question 2 (20 pts)\n",
    "Use the iris dataset (just the binary class Iris Setosa vs others), the K-fold cross validation, metrics(accuracy, precision, recall, F1-score) and your implementation of the logistic regression (Question1).\n",
    "You can use scikit.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,precision_recall_fscore_support,accuracy_score\n",
    "from sklearn.model_selection import StratifiedKFold,KFold\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "d=pd.read_csv(\"iris.csv\").values\n",
    "X=d[:,:4]\n",
    "y=d[:,4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6ADdiV3C8I0m"
   },
   "outputs": [],
   "source": [
    "def clasb(s):\n",
    "    if s=='Iris-setosa':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1=np.array([clasb(x) for x in y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold = 0\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3478002027630813 4.229785785654747 -6.9445532254798 -3.329176931433549\n",
      " 0.820948597679764]\n",
      "\n",
      "Fold = 1\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3634371469321798 4.0658048811432375 -6.890996089243137\n",
      " -3.2822608589747664 0.8738434900805775]\n",
      "\n",
      "Fold = 2\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.101752354005028 4.381255375407357 -6.666316199563102 -3.330095151389967\n",
      " 0.7322798119201123]\n",
      "\n",
      "Fold = 3\n",
      "Accuracy 1.0\n",
      "confusion matrix [[11  0]\n",
      " [ 0  4]]\n",
      "precision recall fscore support (array([ 1.,  1.]), array([ 1.,  1.]), array([ 1.,  1.]), array([11,  4], dtype=int64))\n",
      "Weights= [1.3040360638681825 4.324416342898543 -6.898885146682342\n",
      " -3.3914962298923443 0.8243982898576255]\n",
      "\n",
      "Fold = 4\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3352686293065301 4.305499849438446 -6.924879709108135\n",
      " -3.3938774437640227 0.8016367363741407]\n",
      "\n",
      "Fold = 5\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3616568007149106 4.249315896572418 -6.889815819563407 -3.445949646878725\n",
      " 0.8076161889967374]\n",
      "\n",
      "Fold = 6\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3586319672160485 4.160566814815592 -6.706158276963646 -3.071735878552535\n",
      " 0.8917036185258872]\n",
      "\n",
      "Fold = 7\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3261112287661605 4.348160989518959 -6.985235535977347 -3.38421817302045\n",
      " 0.8213489538555555]\n",
      "\n",
      "Fold = 8\n",
      "Accuracy 1.0\n",
      "confusion matrix [[15]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([15], dtype=int64))\n",
      "Weights= [1.3355531743281532 4.334627930151672 -6.977970300725914 -3.413275721106802\n",
      " 0.8141887217419387]\n",
      "\n",
      "Fold = 9\n",
      "Accuracy 1.0\n",
      "confusion matrix [[14]]\n",
      "precision recall fscore support (array([ 1.]), array([ 1.]), array([ 1.]), array([14], dtype=int64))\n",
      "Weights= [1.3175820156745597 4.363348120512177 -6.995679277354789 -3.350631482264697\n",
      " 0.8237933560627994]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "split=0\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y1[train_index], y1[test_index]\n",
    "    \n",
    "    print(\"Fold =\", split)\n",
    "    split+=1\n",
    "    clf=logisticRegression(max_iter=20000, lr=0.01)\n",
    "    clf.__fit__(X_train,y_train)\n",
    "    y_pred=clf.__predict__(X_test)\n",
    "    print('Accuracy', accuracy_score(y_test, y_pred))\n",
    "    print('confusion matrix',confusion_matrix(y_test, y_pred))\n",
    "    print('precision recall fscore support',precision_recall_fscore_support(y_test, y_pred))\n",
    "    print(\"Weights=\",clf.theta)\n",
    "    print() # For formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "PS2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
